INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.1, lr_decay_epoch='80,160', lr_decay_period=0, mode='hybrid', model='cifar_resnet56_v2', momentum=0.9, num_epochs=240, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0001)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[09:14:00] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.346034 val=0.428200 loss=1.760435 time: 19.218791
INFO:root:[Epoch 1] train=0.487360 val=0.489900 loss=1.421299 time: 18.171370
INFO:root:[Epoch 2] train=0.544551 val=0.544900 loss=1.270371 time: 18.391115
INFO:root:[Epoch 3] train=0.582412 val=0.585800 loss=1.168763 time: 18.223655
INFO:root:[Epoch 4] train=0.613341 val=0.704100 loss=1.091278 time: 18.302612
INFO:root:[Epoch 5] train=0.639203 val=0.725900 loss=1.028585 time: 18.415848
INFO:root:[Epoch 6] train=0.654387 val=0.672000 loss=0.986767 time: 18.433359
INFO:root:[Epoch 7] train=0.666406 val=0.721100 loss=0.945826 time: 18.413524
INFO:root:[Epoch 8] train=0.678405 val=0.751100 loss=0.920216 time: 18.331370
INFO:root:[Epoch 9] train=0.685737 val=0.751000 loss=0.895713 time: 18.258851
INFO:root:[Epoch 10] train=0.692027 val=0.757800 loss=0.875658 time: 18.305008
INFO:root:[Epoch 11] train=0.701242 val=0.763000 loss=0.858879 time: 18.383546
INFO:root:[Epoch 12] train=0.709135 val=0.769200 loss=0.836529 time: 18.172786
INFO:root:[Epoch 13] train=0.711298 val=0.793300 loss=0.823683 time: 18.353344
INFO:root:[Epoch 14] train=0.717989 val=0.795900 loss=0.803672 time: 18.230629
INFO:root:[Epoch 15] train=0.720313 val=0.783100 loss=0.802272 time: 18.407477
INFO:root:[Epoch 16] train=0.725160 val=0.774500 loss=0.784886 time: 18.334378
INFO:root:[Epoch 17] train=0.731270 val=0.787800 loss=0.771732 time: 18.353776
INFO:root:[Epoch 18] train=0.731430 val=0.796600 loss=0.765668 time: 18.224269
INFO:root:[Epoch 19] train=0.738301 val=0.816400 loss=0.752706 time: 18.332946
INFO:root:[Epoch 20] train=0.739423 val=0.814600 loss=0.744917 time: 18.169595
INFO:root:[Epoch 21] train=0.744511 val=0.828500 loss=0.735969 time: 18.330411
INFO:root:[Epoch 22] train=0.745753 val=0.810600 loss=0.726530 time: 18.271860
INFO:root:[Epoch 23] train=0.745853 val=0.818700 loss=0.723681 time: 18.452689
INFO:root:[Epoch 24] train=0.746514 val=0.811600 loss=0.725648 time: 17.984712
INFO:root:[Epoch 25] train=0.747957 val=0.790000 loss=0.716229 time: 18.452906
INFO:root:[Epoch 26] train=0.753025 val=0.830200 loss=0.702283 time: 18.441614
INFO:root:[Epoch 27] train=0.754307 val=0.823600 loss=0.703159 time: 18.419213
INFO:root:[Epoch 28] train=0.757051 val=0.827800 loss=0.696227 time: 18.159513
INFO:root:[Epoch 29] train=0.759235 val=0.832700 loss=0.692468 time: 18.398370
INFO:root:[Epoch 30] train=0.760256 val=0.843700 loss=0.686043 time: 18.190114
INFO:root:[Epoch 31] train=0.761278 val=0.843600 loss=0.683179 time: 18.469890
INFO:root:[Epoch 32] train=0.764323 val=0.851900 loss=0.678351 time: 18.262331
INFO:root:[Epoch 33] train=0.763221 val=0.841200 loss=0.678556 time: 18.413877
INFO:root:[Epoch 34] train=0.767748 val=0.825900 loss=0.668163 time: 18.257836
INFO:root:[Epoch 35] train=0.766827 val=0.818000 loss=0.668068 time: 18.527920
INFO:root:[Epoch 36] train=0.766506 val=0.845700 loss=0.663850 time: 18.189196
INFO:root:[Epoch 37] train=0.767929 val=0.846000 loss=0.666401 time: 18.249597
INFO:root:[Epoch 38] train=0.770112 val=0.855300 loss=0.658536 time: 18.335595
INFO:root:[Epoch 39] train=0.772756 val=0.842600 loss=0.653221 time: 18.522819
INFO:root:[Epoch 40] train=0.771074 val=0.832500 loss=0.656903 time: 18.417199
INFO:root:[Epoch 41] train=0.772536 val=0.825300 loss=0.652562 time: 18.187487
INFO:root:[Epoch 42] train=0.773658 val=0.856000 loss=0.649082 time: 18.302530
INFO:root:[Epoch 43] train=0.776222 val=0.852500 loss=0.646434 time: 18.306192
INFO:root:[Epoch 44] train=0.775601 val=0.854300 loss=0.644776 time: 18.343342
INFO:root:[Epoch 45] train=0.775361 val=0.859800 loss=0.643251 time: 18.439439
INFO:root:[Epoch 46] train=0.775521 val=0.829700 loss=0.640941 time: 18.413340
INFO:root:[Epoch 47] train=0.780869 val=0.865000 loss=0.631663 time: 18.406832
INFO:root:[Epoch 48] train=0.777143 val=0.826100 loss=0.638256 time: 18.298937
INFO:root:[Epoch 49] train=0.780729 val=0.835000 loss=0.629427 time: 18.216320
INFO:root:[Epoch 50] train=0.780268 val=0.860000 loss=0.633172 time: 18.383135
INFO:root:[Epoch 51] train=0.782752 val=0.857800 loss=0.625696 time: 18.304688
INFO:root:[Epoch 52] train=0.780649 val=0.855100 loss=0.628295 time: 18.505966
INFO:root:[Epoch 53] train=0.778385 val=0.852200 loss=0.629914 time: 18.262913
INFO:root:[Epoch 54] train=0.785998 val=0.847700 loss=0.617960 time: 18.431653
INFO:root:[Epoch 55] train=0.782051 val=0.827300 loss=0.623562 time: 18.508172
INFO:root:[Epoch 56] train=0.783474 val=0.851500 loss=0.620950 time: 18.492361
INFO:root:[Epoch 57] train=0.782893 val=0.857700 loss=0.620351 time: 18.174182
INFO:root:[Epoch 58] train=0.785677 val=0.850500 loss=0.618649 time: 18.393293
INFO:root:[Epoch 59] train=0.784936 val=0.858900 loss=0.614499 time: 18.431260
INFO:root:[Epoch 60] train=0.786158 val=0.857700 loss=0.612258 time: 18.448177
INFO:root:[Epoch 61] train=0.784395 val=0.853200 loss=0.616124 time: 18.331196
INFO:root:[Epoch 62] train=0.784816 val=0.850200 loss=0.616963 time: 18.463952
INFO:root:[Epoch 63] train=0.787660 val=0.863500 loss=0.611209 time: 18.365843
INFO:root:[Epoch 64] train=0.784535 val=0.871500 loss=0.614141 time: 18.605153
INFO:root:[Epoch 65] train=0.784535 val=0.856800 loss=0.614847 time: 18.204026
INFO:root:[Epoch 66] train=0.786719 val=0.838500 loss=0.608321 time: 18.220516
INFO:root:[Epoch 67] train=0.788001 val=0.868200 loss=0.608127 time: 18.289776
INFO:root:[Epoch 68] train=0.788822 val=0.861600 loss=0.607180 time: 18.528988
INFO:root:[Epoch 69] train=0.789563 val=0.843000 loss=0.606067 time: 18.189574
INFO:root:[Epoch 70] train=0.790084 val=0.834600 loss=0.598024 time: 18.397278
INFO:root:[Epoch 71] train=0.787640 val=0.860900 loss=0.604672 time: 18.287880
INFO:root:[Epoch 72] train=0.791446 val=0.854800 loss=0.603756 time: 18.657856
INFO:root:[Epoch 73] train=0.788482 val=0.851700 loss=0.604115 time: 18.132312
INFO:root:[Epoch 74] train=0.793249 val=0.852700 loss=0.600639 time: 18.406883
INFO:root:[Epoch 75] train=0.793650 val=0.867500 loss=0.595062 time: 18.372967
INFO:root:[Epoch 76] train=0.792708 val=0.851900 loss=0.589973 time: 18.425703
INFO:root:[Epoch 77] train=0.791486 val=0.871700 loss=0.603901 time: 18.373643
INFO:root:[Epoch 78] train=0.792909 val=0.858700 loss=0.599800 time: 18.408683
INFO:root:[Epoch 79] train=0.792047 val=0.865800 loss=0.595165 time: 18.353222
INFO:root:[Epoch 80] train=0.826843 val=0.909900 loss=0.500505 time: 18.490660
INFO:root:[Epoch 81] train=0.842929 val=0.911700 loss=0.452700 time: 18.465936
INFO:root:[Epoch 82] train=0.849279 val=0.915700 loss=0.435361 time: 18.267090
INFO:root:[Epoch 83] train=0.849419 val=0.918100 loss=0.431298 time: 18.276699
INFO:root:[Epoch 84] train=0.851883 val=0.917900 loss=0.423476 time: 18.640174
INFO:root:[Epoch 85] train=0.855809 val=0.919400 loss=0.416732 time: 18.325065
INFO:root:[Epoch 86] train=0.856190 val=0.917500 loss=0.409028 time: 18.151894
INFO:root:[Epoch 87] train=0.857873 val=0.920700 loss=0.410193 time: 18.491914
INFO:root:[Epoch 88] train=0.858053 val=0.921800 loss=0.408876 time: 18.409749
INFO:root:[Epoch 89] train=0.858814 val=0.920200 loss=0.405274 time: 18.618386
INFO:root:[Epoch 90] train=0.861959 val=0.919500 loss=0.396176 time: 18.186280
INFO:root:[Epoch 91] train=0.858774 val=0.918700 loss=0.399839 time: 18.368165
INFO:root:[Epoch 92] train=0.862340 val=0.919200 loss=0.396360 time: 18.389809
INFO:root:[Epoch 93] train=0.864283 val=0.921900 loss=0.391303 time: 18.241608
INFO:root:[Epoch 94] train=0.862480 val=0.920500 loss=0.390216 time: 18.485668
INFO:root:[Epoch 95] train=0.863141 val=0.920300 loss=0.391774 time: 18.537922
INFO:root:[Epoch 96] train=0.863922 val=0.921300 loss=0.389027 time: 18.452954
INFO:root:[Epoch 97] train=0.866907 val=0.919300 loss=0.383238 time: 18.599129
INFO:root:[Epoch 98] train=0.867107 val=0.923100 loss=0.381970 time: 18.252142
INFO:root:[Epoch 99] train=0.867188 val=0.921100 loss=0.380553 time: 18.362371
INFO:root:[Epoch 100] train=0.867548 val=0.922100 loss=0.380652 time: 18.366938
INFO:root:[Epoch 101] train=0.868349 val=0.922600 loss=0.376689 time: 18.481887
INFO:root:[Epoch 102] train=0.869111 val=0.921400 loss=0.377533 time: 18.387154
INFO:root:[Epoch 103] train=0.868369 val=0.918000 loss=0.376710 time: 18.365007
INFO:root:[Epoch 104] train=0.870653 val=0.920900 loss=0.372928 time: 18.367672
INFO:root:[Epoch 105] train=0.869251 val=0.922600 loss=0.374770 time: 18.554672
INFO:root:[Epoch 106] train=0.870393 val=0.919600 loss=0.370795 time: 18.303115
INFO:root:[Epoch 107] train=0.868470 val=0.922900 loss=0.376132 time: 18.536293
INFO:root:[Epoch 108] train=0.869050 val=0.924600 loss=0.372084 time: 18.336204
INFO:root:[Epoch 109] train=0.873317 val=0.919700 loss=0.362035 time: 18.614678
INFO:root:[Epoch 110] train=0.872296 val=0.920800 loss=0.367543 time: 18.379197
INFO:root:[Epoch 111] train=0.872736 val=0.918400 loss=0.366479 time: 18.442345
INFO:root:[Epoch 112] train=0.872857 val=0.922200 loss=0.359161 time: 18.387096
INFO:root:[Epoch 113] train=0.873437 val=0.923200 loss=0.363482 time: 18.489175
INFO:root:[Epoch 114] train=0.871254 val=0.921100 loss=0.366911 time: 18.315375
INFO:root:[Epoch 115] train=0.875781 val=0.920100 loss=0.353888 time: 18.436524
INFO:root:[Epoch 116] train=0.873878 val=0.923700 loss=0.363512 time: 18.467027
INFO:root:[Epoch 117] train=0.872756 val=0.922300 loss=0.360597 time: 18.693713
INFO:root:[Epoch 118] train=0.877163 val=0.922900 loss=0.355202 time: 18.476579
INFO:root:[Epoch 119] train=0.873017 val=0.921100 loss=0.364680 time: 18.376299
INFO:root:[Epoch 120] train=0.872696 val=0.919300 loss=0.364334 time: 18.489664
INFO:root:[Epoch 121] train=0.876723 val=0.920600 loss=0.354091 time: 18.568472
INFO:root:[Epoch 122] train=0.873538 val=0.923200 loss=0.358908 time: 18.513753
INFO:root:[Epoch 123] train=0.876242 val=0.921700 loss=0.349727 time: 18.369649
INFO:root:[Epoch 124] train=0.877183 val=0.920800 loss=0.354545 time: 18.407387
INFO:root:[Epoch 125] train=0.877324 val=0.922900 loss=0.351690 time: 18.611809
INFO:root:[Epoch 126] train=0.874740 val=0.922500 loss=0.352700 time: 18.647510
INFO:root:[Epoch 127] train=0.879667 val=0.922400 loss=0.349362 time: 18.368382
INFO:root:[Epoch 128] train=0.876362 val=0.923800 loss=0.352846 time: 18.455334
INFO:root:[Epoch 129] train=0.877544 val=0.923600 loss=0.354265 time: 18.629268
INFO:root:[Epoch 130] train=0.879347 val=0.922700 loss=0.347100 time: 18.577619
INFO:root:[Epoch 131] train=0.875280 val=0.924900 loss=0.353792 time: 18.373190
INFO:root:[Epoch 132] train=0.876302 val=0.923300 loss=0.356304 time: 18.505069
INFO:root:[Epoch 133] train=0.877624 val=0.925900 loss=0.350503 time: 18.585524
INFO:root:[Epoch 134] train=0.880809 val=0.921800 loss=0.344163 time: 18.600140
INFO:root:[Epoch 135] train=0.876042 val=0.922300 loss=0.352986 time: 18.425828
INFO:root:[Epoch 136] train=0.879828 val=0.915600 loss=0.346910 time: 18.582558
INFO:root:[Epoch 137] train=0.877965 val=0.925600 loss=0.349548 time: 18.397139
INFO:root:[Epoch 138] train=0.880349 val=0.920700 loss=0.343853 time: 18.538408
INFO:root:[Epoch 139] train=0.877143 val=0.920000 loss=0.346659 time: 18.599995
INFO:root:[Epoch 140] train=0.876182 val=0.922300 loss=0.353389 time: 18.478919
INFO:root:[Epoch 141] train=0.877784 val=0.922600 loss=0.349103 time: 18.528870
INFO:root:[Epoch 142] train=0.879708 val=0.918900 loss=0.347243 time: 18.512223
INFO:root:[Epoch 143] train=0.878265 val=0.923400 loss=0.345708 time: 18.454742
INFO:root:[Epoch 144] train=0.880389 val=0.921100 loss=0.343610 time: 18.415285
INFO:root:[Epoch 145] train=0.882071 val=0.922200 loss=0.340380 time: 18.401190
INFO:root:[Epoch 146] train=0.878746 val=0.913800 loss=0.345729 time: 18.484838
INFO:root:[Epoch 147] train=0.879067 val=0.917400 loss=0.344212 time: 18.610638
INFO:root:[Epoch 148] train=0.879387 val=0.922400 loss=0.342548 time: 18.399417
INFO:root:[Epoch 149] train=0.878726 val=0.921100 loss=0.347417 time: 18.565103
INFO:root:[Epoch 150] train=0.880469 val=0.922500 loss=0.341544 time: 18.308435
INFO:root:[Epoch 151] train=0.879067 val=0.922000 loss=0.347303 time: 18.604376
INFO:root:[Epoch 152] train=0.881310 val=0.919600 loss=0.342136 time: 18.523106
INFO:root:[Epoch 153] train=0.876943 val=0.919600 loss=0.347038 time: 18.504055
INFO:root:[Epoch 154] train=0.879127 val=0.918500 loss=0.346485 time: 18.310374
INFO:root:[Epoch 155] train=0.880950 val=0.920500 loss=0.341000 time: 18.744547
INFO:root:[Epoch 156] train=0.879507 val=0.921800 loss=0.343755 time: 18.420887
INFO:root:[Epoch 157] train=0.882592 val=0.919300 loss=0.338587 time: 18.598308
INFO:root:[Epoch 158] train=0.881390 val=0.923600 loss=0.339452 time: 18.425174
INFO:root:[Epoch 159] train=0.881611 val=0.918500 loss=0.337435 time: 18.656113
INFO:root:[Epoch 160] train=0.887340 val=0.926200 loss=0.324232 time: 18.291863
INFO:root:[Epoch 161] train=0.893049 val=0.925600 loss=0.305165 time: 18.462382
INFO:root:[Epoch 162] train=0.894852 val=0.927600 loss=0.305509 time: 18.426360
INFO:root:[Epoch 163] train=0.898017 val=0.928000 loss=0.293923 time: 18.542494
INFO:root:[Epoch 164] train=0.896374 val=0.927700 loss=0.299215 time: 18.359434
INFO:root:[Epoch 165] train=0.898257 val=0.929400 loss=0.296287 time: 18.549009
INFO:root:[Epoch 166] train=0.896835 val=0.928100 loss=0.299930 time: 18.415503
INFO:root:[Epoch 167] train=0.897756 val=0.930300 loss=0.295487 time: 18.604613
INFO:root:[Epoch 168] train=0.896134 val=0.931000 loss=0.299051 time: 18.398147
INFO:root:[Epoch 169] train=0.897316 val=0.930900 loss=0.297379 time: 18.636411
INFO:root:[Epoch 170] train=0.897796 val=0.931300 loss=0.297206 time: 18.537891
INFO:root:[Epoch 171] train=0.897256 val=0.931100 loss=0.294764 time: 18.592426
INFO:root:[Epoch 172] train=0.897776 val=0.929800 loss=0.294069 time: 18.632086
INFO:root:[Epoch 173] train=0.898197 val=0.929700 loss=0.290454 time: 18.454107
INFO:root:[Epoch 174] train=0.898357 val=0.931100 loss=0.292352 time: 18.645068
INFO:root:[Epoch 175] train=0.900381 val=0.929400 loss=0.291132 time: 18.488559
INFO:root:[Epoch 176] train=0.900601 val=0.929800 loss=0.288754 time: 18.539748
INFO:root:[Epoch 177] train=0.899519 val=0.930200 loss=0.289701 time: 18.672889
INFO:root:[Epoch 178] train=0.899740 val=0.929500 loss=0.289665 time: 18.741625
INFO:root:[Epoch 179] train=0.901282 val=0.930100 loss=0.284873 time: 18.471205
INFO:root:[Epoch 180] train=0.900060 val=0.929200 loss=0.288667 time: 18.673140
INFO:root:[Epoch 181] train=0.899219 val=0.930400 loss=0.292225 time: 18.475061
INFO:root:[Epoch 182] train=0.900621 val=0.929700 loss=0.289109 time: 18.694257
INFO:root:[Epoch 183] train=0.900901 val=0.930300 loss=0.286988 time: 18.482275
INFO:root:[Epoch 184] train=0.898578 val=0.930100 loss=0.293175 time: 18.718661
INFO:root:[Epoch 185] train=0.900641 val=0.930300 loss=0.286923 time: 18.341879
INFO:root:[Epoch 186] train=0.898738 val=0.929900 loss=0.289466 time: 18.702683
INFO:root:[Epoch 187] train=0.900881 val=0.930600 loss=0.288244 time: 18.583775
INFO:root:[Epoch 188] train=0.900260 val=0.929700 loss=0.287172 time: 18.724531
INFO:root:[Epoch 189] train=0.901442 val=0.928900 loss=0.283572 time: 18.529246
INFO:root:[Epoch 190] train=0.900641 val=0.930100 loss=0.285685 time: 18.724636
INFO:root:[Epoch 191] train=0.900942 val=0.930700 loss=0.282920 time: 18.343345
INFO:root:[Epoch 192] train=0.901683 val=0.931000 loss=0.282852 time: 18.634026
INFO:root:[Epoch 193] train=0.902324 val=0.930300 loss=0.280471 time: 18.577893
INFO:root:[Epoch 194] train=0.901563 val=0.930700 loss=0.285298 time: 18.708966
INFO:root:[Epoch 195] train=0.901242 val=0.930700 loss=0.285628 time: 18.524368
INFO:root:[Epoch 196] train=0.900361 val=0.929700 loss=0.288289 time: 18.606613
INFO:root:[Epoch 197] train=0.901462 val=0.931000 loss=0.285920 time: 18.457845
INFO:root:[Epoch 198] train=0.899700 val=0.931200 loss=0.287228 time: 18.605948
INFO:root:[Epoch 199] train=0.902103 val=0.930100 loss=0.282366 time: 18.568958
INFO:root:[Epoch 200] train=0.901022 val=0.927500 loss=0.285372 time: 18.691512
INFO:root:[Epoch 201] train=0.901743 val=0.930100 loss=0.281131 time: 18.667967
INFO:root:[Epoch 202] train=0.901322 val=0.929100 loss=0.281033 time: 18.665800
INFO:root:[Epoch 203] train=0.900962 val=0.929400 loss=0.284873 time: 18.599515
INFO:root:[Epoch 204] train=0.903446 val=0.930400 loss=0.279352 time: 18.582474
INFO:root:[Epoch 205] train=0.902404 val=0.929200 loss=0.283985 time: 18.635055
INFO:root:[Epoch 206] train=0.901022 val=0.929800 loss=0.282566 time: 18.743963
INFO:root:[Epoch 207] train=0.903045 val=0.931000 loss=0.278901 time: 18.641778
INFO:root:[Epoch 208] train=0.902003 val=0.930500 loss=0.280676 time: 18.605063
INFO:root:[Epoch 209] train=0.902063 val=0.931200 loss=0.283326 time: 18.797378
INFO:root:[Epoch 210] train=0.904327 val=0.931300 loss=0.279936 time: 18.649371
INFO:root:[Epoch 211] train=0.902885 val=0.929000 loss=0.283353 time: 18.599611
INFO:root:[Epoch 212] train=0.903606 val=0.929500 loss=0.281292 time: 18.357751
INFO:root:[Epoch 213] train=0.902404 val=0.930400 loss=0.279928 time: 18.798724
INFO:root:[Epoch 214] train=0.901763 val=0.930000 loss=0.281391 time: 18.597725
INFO:root:[Epoch 215] train=0.903385 val=0.931000 loss=0.279519 time: 18.463168
INFO:root:[Epoch 216] train=0.903365 val=0.930100 loss=0.281246 time: 18.400074
INFO:root:[Epoch 217] train=0.902804 val=0.932200 loss=0.279300 time: 18.681640
INFO:root:[Epoch 218] train=0.903145 val=0.929800 loss=0.279335 time: 18.538643
INFO:root:[Epoch 219] train=0.900160 val=0.931600 loss=0.283559 time: 18.683597
INFO:root:[Epoch 220] train=0.904287 val=0.930900 loss=0.277690 time: 18.637873
INFO:root:[Epoch 221] train=0.902404 val=0.930300 loss=0.283370 time: 18.625172
INFO:root:[Epoch 222] train=0.905869 val=0.929800 loss=0.269702 time: 18.642817
INFO:root:[Epoch 223] train=0.903185 val=0.929500 loss=0.276274 time: 18.630909
INFO:root:[Epoch 224] train=0.903365 val=0.930600 loss=0.280230 time: 18.525759
INFO:root:[Epoch 225] train=0.901983 val=0.928200 loss=0.277582 time: 18.667045
INFO:root:[Epoch 226] train=0.903365 val=0.929400 loss=0.277374 time: 18.570292
INFO:root:[Epoch 227] train=0.904087 val=0.930500 loss=0.275667 time: 18.479468
INFO:root:[Epoch 228] train=0.904347 val=0.930500 loss=0.278014 time: 18.496252
INFO:root:[Epoch 229] train=0.904127 val=0.931000 loss=0.277484 time: 18.522431
INFO:root:[Epoch 230] train=0.903185 val=0.930700 loss=0.277901 time: 18.754065
INFO:root:[Epoch 231] train=0.905429 val=0.933200 loss=0.274103 time: 18.513530
INFO:root:[Epoch 232] train=0.903846 val=0.931000 loss=0.274501 time: 18.699143
INFO:root:[Epoch 233] train=0.902504 val=0.930000 loss=0.278870 time: 18.608551
INFO:root:[Epoch 234] train=0.903425 val=0.929700 loss=0.276526 time: 18.788644
INFO:root:[Epoch 235] train=0.900942 val=0.931100 loss=0.284150 time: 18.696515
INFO:root:[Epoch 236] train=0.902424 val=0.929500 loss=0.281249 time: 18.792148
INFO:root:[Epoch 237] train=0.902564 val=0.929700 loss=0.277197 time: 18.455758
INFO:root:[Epoch 238] train=0.902504 val=0.931700 loss=0.284140 time: 18.804272
INFO:root:[Epoch 239] train=0.903926 val=0.929600 loss=0.274958 time: 18.592082
