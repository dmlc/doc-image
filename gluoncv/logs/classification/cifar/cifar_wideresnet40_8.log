INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.2, lr_decay_epoch='60,120,160', lr_decay_period=0, mode='hybrid', model='cifar_wideresnet40_8', momentum=0.9, num_epochs=200, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0005)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[02:13:34] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.285457 val=0.381300 loss=1.945294 time: 71.515621
INFO:root:[Epoch 1] train=0.420092 val=0.511100 loss=1.591118 time: 70.526001
INFO:root:[Epoch 2] train=0.511498 val=0.529800 loss=1.360284 time: 70.535332
INFO:root:[Epoch 3] train=0.573157 val=0.614900 loss=1.201958 time: 70.562880
INFO:root:[Epoch 4] train=0.614904 val=0.682100 loss=1.092317 time: 70.635047
INFO:root:[Epoch 5] train=0.637400 val=0.741500 loss=1.033738 time: 70.532034
INFO:root:[Epoch 6] train=0.658474 val=0.716500 loss=0.979345 time: 70.496041
INFO:root:[Epoch 7] train=0.669712 val=0.727300 loss=0.947440 time: 70.582847
INFO:root:[Epoch 8] train=0.681230 val=0.702800 loss=0.917145 time: 70.574946
INFO:root:[Epoch 9] train=0.690044 val=0.747900 loss=0.890011 time: 70.506537
INFO:root:[Epoch 10] train=0.693590 val=0.755000 loss=0.873431 time: 70.538251
INFO:root:[Epoch 11] train=0.702784 val=0.775100 loss=0.858323 time: 70.521811
INFO:root:[Epoch 12] train=0.706571 val=0.793700 loss=0.841070 time: 70.584091
INFO:root:[Epoch 13] train=0.715144 val=0.782500 loss=0.818752 time: 70.604503
INFO:root:[Epoch 14] train=0.716627 val=0.725000 loss=0.811963 time: 70.555575
INFO:root:[Epoch 15] train=0.719411 val=0.785400 loss=0.802348 time: 70.534216
INFO:root:[Epoch 16] train=0.727945 val=0.817500 loss=0.782533 time: 70.475897
INFO:root:[Epoch 17] train=0.727865 val=0.720200 loss=0.781379 time: 70.490299
INFO:root:[Epoch 18] train=0.730950 val=0.802700 loss=0.771187 time: 70.604498
INFO:root:[Epoch 19] train=0.729688 val=0.797600 loss=0.776682 time: 70.598950
INFO:root:[Epoch 20] train=0.739423 val=0.814500 loss=0.752774 time: 70.678581
INFO:root:[Epoch 21] train=0.738001 val=0.809100 loss=0.751114 time: 70.542654
INFO:root:[Epoch 22] train=0.740905 val=0.801600 loss=0.748255 time: 70.627717
INFO:root:[Epoch 23] train=0.743309 val=0.811000 loss=0.737640 time: 70.529172
INFO:root:[Epoch 24] train=0.745853 val=0.814700 loss=0.734509 time: 70.488116
INFO:root:[Epoch 25] train=0.744752 val=0.828300 loss=0.733241 time: 70.519048
INFO:root:[Epoch 26] train=0.748037 val=0.770300 loss=0.725839 time: 70.517547
INFO:root:[Epoch 27] train=0.751943 val=0.784900 loss=0.714755 time: 70.530765
INFO:root:[Epoch 28] train=0.751462 val=0.807000 loss=0.717152 time: 70.614418
INFO:root:[Epoch 29] train=0.750341 val=0.810100 loss=0.719385 time: 70.663901
INFO:root:[Epoch 30] train=0.752664 val=0.806000 loss=0.711784 time: 70.624403
INFO:root:[Epoch 31] train=0.753005 val=0.787400 loss=0.710217 time: 70.660093
INFO:root:[Epoch 32] train=0.756410 val=0.768600 loss=0.705057 time: 70.652999
INFO:root:[Epoch 33] train=0.756811 val=0.819400 loss=0.699013 time: 70.628328
INFO:root:[Epoch 34] train=0.757752 val=0.772000 loss=0.697728 time: 70.541480
INFO:root:[Epoch 35] train=0.756991 val=0.840000 loss=0.697817 time: 70.584596
INFO:root:[Epoch 36] train=0.753766 val=0.793100 loss=0.701686 time: 70.717456
INFO:root:[Epoch 37] train=0.756550 val=0.811100 loss=0.701135 time: 70.674740
INFO:root:[Epoch 38] train=0.757893 val=0.820700 loss=0.699612 time: 70.621004
INFO:root:[Epoch 39] train=0.757692 val=0.840200 loss=0.699286 time: 70.565278
INFO:root:[Epoch 40] train=0.762540 val=0.798000 loss=0.685195 time: 70.724655
INFO:root:[Epoch 41] train=0.758754 val=0.832700 loss=0.693507 time: 70.574824
INFO:root:[Epoch 42] train=0.758373 val=0.829500 loss=0.689355 time: 70.656497
INFO:root:[Epoch 43] train=0.759375 val=0.839500 loss=0.690437 time: 70.591164
INFO:root:[Epoch 44] train=0.761058 val=0.831400 loss=0.683445 time: 70.557040
INFO:root:[Epoch 45] train=0.761138 val=0.839100 loss=0.685017 time: 70.619283
INFO:root:[Epoch 46] train=0.761759 val=0.840700 loss=0.684479 time: 70.700729
INFO:root:[Epoch 47] train=0.765865 val=0.813700 loss=0.680106 time: 70.593322
INFO:root:[Epoch 48] train=0.759876 val=0.812200 loss=0.685920 time: 70.681721
INFO:root:[Epoch 49] train=0.763462 val=0.848900 loss=0.680137 time: 70.694442
INFO:root:[Epoch 50] train=0.763261 val=0.839300 loss=0.678552 time: 70.697646
INFO:root:[Epoch 51] train=0.765865 val=0.853300 loss=0.679737 time: 70.678112
INFO:root:[Epoch 52] train=0.763241 val=0.825200 loss=0.682644 time: 70.683427
INFO:root:[Epoch 53] train=0.762720 val=0.828400 loss=0.681129 time: 70.674760
INFO:root:[Epoch 54] train=0.765184 val=0.836300 loss=0.676463 time: 70.702811
INFO:root:[Epoch 55] train=0.765665 val=0.851000 loss=0.679183 time: 70.716366
INFO:root:[Epoch 56] train=0.768129 val=0.800000 loss=0.673485 time: 70.692604
INFO:root:[Epoch 57] train=0.763822 val=0.839300 loss=0.680651 time: 70.703063
INFO:root:[Epoch 58] train=0.769571 val=0.844000 loss=0.665174 time: 70.683261
INFO:root:[Epoch 59] train=0.763381 val=0.838800 loss=0.676312 time: 70.700847
INFO:root:[Epoch 60] train=0.826783 val=0.908500 loss=0.501545 time: 70.651675
INFO:root:[Epoch 61] train=0.849639 val=0.917400 loss=0.440157 time: 70.714522
INFO:root:[Epoch 62] train=0.852103 val=0.918500 loss=0.428871 time: 70.674545
INFO:root:[Epoch 63] train=0.856010 val=0.926100 loss=0.416321 time: 70.659256
INFO:root:[Epoch 64] train=0.855789 val=0.924100 loss=0.417734 time: 70.712172
INFO:root:[Epoch 65] train=0.858273 val=0.924800 loss=0.411649 time: 70.621690
INFO:root:[Epoch 66] train=0.858654 val=0.915100 loss=0.405429 time: 70.741695
INFO:root:[Epoch 67] train=0.857632 val=0.918000 loss=0.409236 time: 70.638080
INFO:root:[Epoch 68] train=0.859475 val=0.918400 loss=0.402648 time: 70.685125
INFO:root:[Epoch 69] train=0.859776 val=0.922400 loss=0.406436 time: 70.691103
INFO:root:[Epoch 70] train=0.859355 val=0.923800 loss=0.408217 time: 70.619200
INFO:root:[Epoch 71] train=0.859155 val=0.916400 loss=0.411505 time: 70.641701
INFO:root:[Epoch 72] train=0.857632 val=0.914400 loss=0.411433 time: 70.712850
INFO:root:[Epoch 73] train=0.857091 val=0.920200 loss=0.409360 time: 70.705350
INFO:root:[Epoch 74] train=0.858413 val=0.920200 loss=0.409041 time: 70.725117
INFO:root:[Epoch 75] train=0.859936 val=0.910600 loss=0.405759 time: 70.748203
INFO:root:[Epoch 76] train=0.856931 val=0.916000 loss=0.409804 time: 70.632597
INFO:root:[Epoch 77] train=0.859335 val=0.922300 loss=0.403746 time: 70.701035
INFO:root:[Epoch 78] train=0.860276 val=0.919700 loss=0.404472 time: 70.736891
INFO:root:[Epoch 79] train=0.860617 val=0.909800 loss=0.407341 time: 70.625756
INFO:root:[Epoch 80] train=0.859876 val=0.903700 loss=0.403055 time: 70.727971
INFO:root:[Epoch 81] train=0.858313 val=0.911800 loss=0.409255 time: 70.754943
INFO:root:[Epoch 82] train=0.860797 val=0.913400 loss=0.401366 time: 70.675984
INFO:root:[Epoch 83] train=0.857011 val=0.917600 loss=0.412482 time: 70.761450
INFO:root:[Epoch 84] train=0.859195 val=0.919600 loss=0.411248 time: 70.677994
INFO:root:[Epoch 85] train=0.863301 val=0.915200 loss=0.397847 time: 70.664454
INFO:root:[Epoch 86] train=0.858033 val=0.922400 loss=0.412108 time: 70.724436
INFO:root:[Epoch 87] train=0.860176 val=0.897300 loss=0.401790 time: 70.793744
INFO:root:[Epoch 88] train=0.862540 val=0.907700 loss=0.397873 time: 70.658283
INFO:root:[Epoch 89] train=0.863401 val=0.915200 loss=0.395092 time: 70.860930
INFO:root:[Epoch 90] train=0.861839 val=0.914500 loss=0.402118 time: 70.747183
INFO:root:[Epoch 91] train=0.863181 val=0.905000 loss=0.397753 time: 70.736294
INFO:root:[Epoch 92] train=0.863161 val=0.907500 loss=0.392789 time: 70.760188
INFO:root:[Epoch 93] train=0.863722 val=0.918000 loss=0.393142 time: 70.760258
INFO:root:[Epoch 94] train=0.862200 val=0.913800 loss=0.399924 time: 70.765726
INFO:root:[Epoch 95] train=0.864523 val=0.921200 loss=0.393759 time: 70.786943
INFO:root:[Epoch 96] train=0.865325 val=0.918900 loss=0.391549 time: 70.658623
INFO:root:[Epoch 97] train=0.863301 val=0.895400 loss=0.396883 time: 70.800472
INFO:root:[Epoch 98] train=0.865124 val=0.919100 loss=0.388790 time: 70.743236
INFO:root:[Epoch 99] train=0.864643 val=0.884300 loss=0.390762 time: 70.709729
INFO:root:[Epoch 100] train=0.864483 val=0.911100 loss=0.393093 time: 70.695792
INFO:root:[Epoch 101] train=0.865605 val=0.917400 loss=0.388712 time: 70.679671
INFO:root:[Epoch 102] train=0.864343 val=0.918400 loss=0.391351 time: 70.766772
INFO:root:[Epoch 103] train=0.863902 val=0.921200 loss=0.395380 time: 70.679701
INFO:root:[Epoch 104] train=0.867768 val=0.917100 loss=0.382576 time: 70.677517
INFO:root:[Epoch 105] train=0.863361 val=0.918500 loss=0.394060 time: 70.740079
INFO:root:[Epoch 106] train=0.865204 val=0.917600 loss=0.387668 time: 70.679895
INFO:root:[Epoch 107] train=0.866807 val=0.918100 loss=0.385651 time: 70.777365
INFO:root:[Epoch 108] train=0.865004 val=0.910900 loss=0.391395 time: 70.685588
INFO:root:[Epoch 109] train=0.867428 val=0.918300 loss=0.381328 time: 70.747489
INFO:root:[Epoch 110] train=0.866907 val=0.913500 loss=0.383122 time: 70.702919
INFO:root:[Epoch 111] train=0.865946 val=0.912800 loss=0.390824 time: 70.839889
INFO:root:[Epoch 112] train=0.869511 val=0.919000 loss=0.382275 time: 70.821871
INFO:root:[Epoch 113] train=0.867748 val=0.906700 loss=0.381946 time: 70.708018
INFO:root:[Epoch 114] train=0.866246 val=0.911400 loss=0.386081 time: 70.686658
INFO:root:[Epoch 115] train=0.870873 val=0.908600 loss=0.376556 time: 70.748954
INFO:root:[Epoch 116] train=0.866286 val=0.890500 loss=0.386464 time: 70.912667
INFO:root:[Epoch 117] train=0.869071 val=0.925600 loss=0.380724 time: 70.710097
INFO:root:[Epoch 118] train=0.866426 val=0.906600 loss=0.383772 time: 70.700826
INFO:root:[Epoch 119] train=0.869651 val=0.919200 loss=0.379316 time: 70.766969
INFO:root:[Epoch 120] train=0.900321 val=0.944700 loss=0.293990 time: 70.670701
INFO:root:[Epoch 121] train=0.912019 val=0.947900 loss=0.259328 time: 70.817900
INFO:root:[Epoch 122] train=0.913161 val=0.948000 loss=0.253401 time: 70.819214
INFO:root:[Epoch 123] train=0.916947 val=0.949200 loss=0.241636 time: 70.854442
INFO:root:[Epoch 124] train=0.919091 val=0.949900 loss=0.237849 time: 70.745104
INFO:root:[Epoch 125] train=0.918830 val=0.949200 loss=0.236298 time: 70.807039
INFO:root:[Epoch 126] train=0.920473 val=0.947600 loss=0.233319 time: 70.888488
INFO:root:[Epoch 127] train=0.921695 val=0.947400 loss=0.229098 time: 70.775567
INFO:root:[Epoch 128] train=0.923878 val=0.952300 loss=0.224566 time: 70.684931
INFO:root:[Epoch 129] train=0.921595 val=0.950200 loss=0.229134 time: 70.722226
INFO:root:[Epoch 130] train=0.922416 val=0.950100 loss=0.225696 time: 70.739827
INFO:root:[Epoch 131] train=0.921454 val=0.950600 loss=0.228759 time: 70.808769
INFO:root:[Epoch 132] train=0.921935 val=0.949100 loss=0.225002 time: 70.680002
INFO:root:[Epoch 133] train=0.924018 val=0.949200 loss=0.221293 time: 70.811776
INFO:root:[Epoch 134] train=0.923998 val=0.948900 loss=0.222799 time: 70.689925
INFO:root:[Epoch 135] train=0.924900 val=0.950100 loss=0.221216 time: 70.742583
INFO:root:[Epoch 136] train=0.926803 val=0.948600 loss=0.216162 time: 70.806850
INFO:root:[Epoch 137] train=0.924940 val=0.948000 loss=0.219382 time: 70.750535
INFO:root:[Epoch 138] train=0.927043 val=0.953400 loss=0.215230 time: 70.653239
INFO:root:[Epoch 139] train=0.926863 val=0.951000 loss=0.216919 time: 70.726556
INFO:root:[Epoch 140] train=0.927664 val=0.950100 loss=0.212207 time: 70.760286
INFO:root:[Epoch 141] train=0.926402 val=0.945700 loss=0.214226 time: 70.859404
INFO:root:[Epoch 142] train=0.925881 val=0.949500 loss=0.216295 time: 70.766663
INFO:root:[Epoch 143] train=0.927965 val=0.950300 loss=0.211377 time: 70.767615
INFO:root:[Epoch 144] train=0.927003 val=0.952200 loss=0.215284 time: 70.944467
INFO:root:[Epoch 145] train=0.925641 val=0.948100 loss=0.216303 time: 70.872449
INFO:root:[Epoch 146] train=0.927043 val=0.949700 loss=0.213040 time: 70.797297
INFO:root:[Epoch 147] train=0.924980 val=0.946700 loss=0.219756 time: 70.773695
INFO:root:[Epoch 148] train=0.927544 val=0.946900 loss=0.214674 time: 70.873243
INFO:root:[Epoch 149] train=0.926222 val=0.947400 loss=0.213179 time: 70.849644
INFO:root:[Epoch 150] train=0.927244 val=0.948600 loss=0.213643 time: 70.780207
INFO:root:[Epoch 151] train=0.927003 val=0.949500 loss=0.214669 time: 70.754851
INFO:root:[Epoch 152] train=0.927945 val=0.946100 loss=0.211703 time: 70.757508
INFO:root:[Epoch 153] train=0.925000 val=0.948600 loss=0.219052 time: 70.794105
INFO:root:[Epoch 154] train=0.926002 val=0.948400 loss=0.216382 time: 70.723508
INFO:root:[Epoch 155] train=0.926723 val=0.947600 loss=0.214520 time: 70.850483
INFO:root:[Epoch 156] train=0.927724 val=0.948700 loss=0.213137 time: 70.827176
INFO:root:[Epoch 157] train=0.927985 val=0.951700 loss=0.210378 time: 70.902818
INFO:root:[Epoch 158] train=0.927083 val=0.947700 loss=0.212692 time: 70.826833
INFO:root:[Epoch 159] train=0.925481 val=0.946200 loss=0.216494 time: 70.819528
INFO:root:[Epoch 160] train=0.933974 val=0.954100 loss=0.194427 time: 70.867681
INFO:root:[Epoch 161] train=0.938942 val=0.956600 loss=0.179480 time: 70.812788
INFO:root:[Epoch 162] train=0.940565 val=0.956300 loss=0.176941 time: 70.912207
INFO:root:[Epoch 163] train=0.941046 val=0.958000 loss=0.171100 time: 70.813864
INFO:root:[Epoch 164] train=0.940785 val=0.958000 loss=0.174245 time: 70.849566
INFO:root:[Epoch 165] train=0.942368 val=0.957100 loss=0.168795 time: 70.843847
INFO:root:[Epoch 166] train=0.942768 val=0.956800 loss=0.167301 time: 70.817615
INFO:root:[Epoch 167] train=0.941486 val=0.957800 loss=0.171575 time: 70.832619
INFO:root:[Epoch 168] train=0.945252 val=0.958600 loss=0.162119 time: 70.992560
INFO:root:[Epoch 169] train=0.942508 val=0.958200 loss=0.165822 time: 70.795496
INFO:root:[Epoch 170] train=0.943229 val=0.956900 loss=0.165074 time: 70.839435
INFO:root:[Epoch 171] train=0.944531 val=0.957400 loss=0.162541 time: 70.977389
INFO:root:[Epoch 172] train=0.944291 val=0.959600 loss=0.163460 time: 70.974840
INFO:root:[Epoch 173] train=0.943169 val=0.957100 loss=0.165142 time: 70.849586
INFO:root:[Epoch 174] train=0.944211 val=0.955200 loss=0.162811 time: 70.841978
INFO:root:[Epoch 175] train=0.946875 val=0.957000 loss=0.158154 time: 70.853475
INFO:root:[Epoch 176] train=0.944311 val=0.956900 loss=0.160966 time: 70.905709
INFO:root:[Epoch 177] train=0.944651 val=0.956900 loss=0.162907 time: 70.895517
INFO:root:[Epoch 178] train=0.945513 val=0.958200 loss=0.162061 time: 70.809416
INFO:root:[Epoch 179] train=0.947636 val=0.958200 loss=0.153738 time: 70.854425
INFO:root:[Epoch 180] train=0.947336 val=0.956200 loss=0.155733 time: 70.843422
INFO:root:[Epoch 181] train=0.946414 val=0.958200 loss=0.154829 time: 70.916869
INFO:root:[Epoch 182] train=0.944772 val=0.957500 loss=0.160075 time: 70.787084
INFO:root:[Epoch 183] train=0.947256 val=0.957700 loss=0.156795 time: 70.820180
INFO:root:[Epoch 184] train=0.946695 val=0.957000 loss=0.158081 time: 70.973075
INFO:root:[Epoch 185] train=0.946534 val=0.956700 loss=0.157458 time: 70.880373
INFO:root:[Epoch 186] train=0.946154 val=0.956900 loss=0.159579 time: 70.996863
INFO:root:[Epoch 187] train=0.946895 val=0.956700 loss=0.156351 time: 70.871530
INFO:root:[Epoch 188] train=0.946394 val=0.956300 loss=0.156389 time: 70.922631
INFO:root:[Epoch 189] train=0.947376 val=0.955400 loss=0.155897 time: 70.863001
INFO:root:[Epoch 190] train=0.947155 val=0.956900 loss=0.156689 time: 70.910774
INFO:root:[Epoch 191] train=0.946735 val=0.957100 loss=0.157248 time: 70.977274
INFO:root:[Epoch 192] train=0.947857 val=0.957800 loss=0.153927 time: 70.881696
INFO:root:[Epoch 193] train=0.948618 val=0.955500 loss=0.151641 time: 70.848214
INFO:root:[Epoch 194] train=0.948017 val=0.956900 loss=0.156152 time: 70.817559
INFO:root:[Epoch 195] train=0.948397 val=0.956600 loss=0.152062 time: 70.938042
INFO:root:[Epoch 196] train=0.948077 val=0.956000 loss=0.153370 time: 70.930197
INFO:root:[Epoch 197] train=0.948357 val=0.957300 loss=0.152812 time: 70.985672
INFO:root:[Epoch 198] train=0.948558 val=0.955500 loss=0.151954 time: 70.918157
INFO:root:[Epoch 199] train=0.947997 val=0.956300 loss=0.153340 time: 70.812325
