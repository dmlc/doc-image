INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.2, lr_decay_epoch='60,120,160', lr_decay_period=0, mode='hybrid', model='cifar_wideresnet16_10', momentum=0.9, num_epochs=200, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0005)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[04:52:34] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.308854 val=0.430300 loss=1.900840 time: 40.957713
INFO:root:[Epoch 1] train=0.437760 val=0.508300 loss=1.547278 time: 39.918373
INFO:root:[Epoch 2] train=0.525421 val=0.512600 loss=1.321552 time: 39.845009
INFO:root:[Epoch 3] train=0.581931 val=0.607300 loss=1.178311 time: 39.821115
INFO:root:[Epoch 4] train=0.616947 val=0.703400 loss=1.089078 time: 46.127493
INFO:root:[Epoch 5] train=0.641006 val=0.725600 loss=1.020197 time: 87.193475
INFO:root:[Epoch 6] train=0.659075 val=0.729000 loss=0.969500 time: 68.079619
INFO:root:[Epoch 7] train=0.672897 val=0.747300 loss=0.936556 time: 40.022208
INFO:root:[Epoch 8] train=0.683794 val=0.754300 loss=0.906864 time: 39.790031
INFO:root:[Epoch 9] train=0.691046 val=0.728900 loss=0.884808 time: 39.806961
INFO:root:[Epoch 10] train=0.698237 val=0.720800 loss=0.863939 time: 40.073883
INFO:root:[Epoch 11] train=0.701542 val=0.774500 loss=0.852537 time: 40.085333
INFO:root:[Epoch 12] train=0.711198 val=0.723400 loss=0.830570 time: 40.166586
INFO:root:[Epoch 13] train=0.714864 val=0.793900 loss=0.816152 time: 40.356322
INFO:root:[Epoch 14] train=0.720413 val=0.785000 loss=0.803581 time: 40.376902
INFO:root:[Epoch 15] train=0.726863 val=0.754000 loss=0.787176 time: 40.456289
INFO:root:[Epoch 16] train=0.726723 val=0.778900 loss=0.780192 time: 40.265345
INFO:root:[Epoch 17] train=0.725361 val=0.805600 loss=0.781975 time: 40.299774
INFO:root:[Epoch 18] train=0.730248 val=0.768300 loss=0.774157 time: 40.027609
INFO:root:[Epoch 19] train=0.735317 val=0.816400 loss=0.762613 time: 39.989824
INFO:root:[Epoch 20] train=0.735677 val=0.792300 loss=0.760112 time: 40.055634
INFO:root:[Epoch 21] train=0.737841 val=0.815600 loss=0.756851 time: 39.969961
INFO:root:[Epoch 22] train=0.741006 val=0.790700 loss=0.744801 time: 39.943405
INFO:root:[Epoch 23] train=0.740765 val=0.828600 loss=0.743429 time: 39.988455
INFO:root:[Epoch 24] train=0.741106 val=0.804200 loss=0.743165 time: 40.119716
INFO:root:[Epoch 25] train=0.746835 val=0.808700 loss=0.725941 time: 40.053950
INFO:root:[Epoch 26] train=0.746554 val=0.771100 loss=0.725388 time: 40.095810
INFO:root:[Epoch 27] train=0.746094 val=0.808100 loss=0.726673 time: 39.972144
INFO:root:[Epoch 28] train=0.745954 val=0.730100 loss=0.730425 time: 40.123408
INFO:root:[Epoch 29] train=0.750260 val=0.828100 loss=0.719075 time: 40.018733
INFO:root:[Epoch 30] train=0.749179 val=0.837300 loss=0.719097 time: 40.090513
INFO:root:[Epoch 31] train=0.751843 val=0.811000 loss=0.717274 time: 39.981453
INFO:root:[Epoch 32] train=0.749099 val=0.835200 loss=0.720724 time: 40.010751
INFO:root:[Epoch 33] train=0.754006 val=0.805700 loss=0.711017 time: 40.009301
INFO:root:[Epoch 34] train=0.752083 val=0.795900 loss=0.710030 time: 39.971305
INFO:root:[Epoch 35] train=0.755649 val=0.793400 loss=0.706787 time: 39.990038
INFO:root:[Epoch 36] train=0.753265 val=0.735300 loss=0.708576 time: 40.053268
INFO:root:[Epoch 37] train=0.755228 val=0.782800 loss=0.704385 time: 39.993706
INFO:root:[Epoch 38] train=0.755489 val=0.820700 loss=0.701670 time: 40.107415
INFO:root:[Epoch 39] train=0.753626 val=0.831900 loss=0.709415 time: 40.147584
INFO:root:[Epoch 40] train=0.757171 val=0.754200 loss=0.700959 time: 39.984248
INFO:root:[Epoch 41] train=0.754768 val=0.793600 loss=0.702304 time: 40.023634
INFO:root:[Epoch 42] train=0.755128 val=0.821800 loss=0.701919 time: 40.040645
INFO:root:[Epoch 43] train=0.758474 val=0.831100 loss=0.697569 time: 40.005488
INFO:root:[Epoch 44] train=0.758554 val=0.808000 loss=0.698038 time: 39.896690
INFO:root:[Epoch 45] train=0.760437 val=0.814800 loss=0.692780 time: 39.974876
INFO:root:[Epoch 46] train=0.757752 val=0.836100 loss=0.693632 time: 40.080415
INFO:root:[Epoch 47] train=0.757252 val=0.813700 loss=0.703492 time: 40.073338
INFO:root:[Epoch 48] train=0.756791 val=0.834400 loss=0.700235 time: 40.037672
INFO:root:[Epoch 49] train=0.758914 val=0.825900 loss=0.692547 time: 40.062573
INFO:root:[Epoch 50] train=0.757692 val=0.846800 loss=0.692416 time: 39.968089
INFO:root:[Epoch 51] train=0.758934 val=0.837900 loss=0.693348 time: 40.043240
INFO:root:[Epoch 52] train=0.761258 val=0.688600 loss=0.690368 time: 40.082865
INFO:root:[Epoch 53] train=0.758173 val=0.812000 loss=0.697714 time: 39.858499
INFO:root:[Epoch 54] train=0.759716 val=0.825300 loss=0.690654 time: 39.895981
INFO:root:[Epoch 55] train=0.764303 val=0.794300 loss=0.682304 time: 39.813275
INFO:root:[Epoch 56] train=0.757272 val=0.829800 loss=0.692804 time: 39.819797
INFO:root:[Epoch 57] train=0.761478 val=0.818000 loss=0.690308 time: 39.830828
INFO:root:[Epoch 58] train=0.761579 val=0.805700 loss=0.681826 time: 39.866527
INFO:root:[Epoch 59] train=0.761338 val=0.812500 loss=0.680764 time: 39.814913
INFO:root:[Epoch 60] train=0.821134 val=0.914000 loss=0.516340 time: 39.729521
INFO:root:[Epoch 61] train=0.842348 val=0.916500 loss=0.458832 time: 39.811654
INFO:root:[Epoch 62] train=0.846895 val=0.921400 loss=0.440086 time: 39.776836
INFO:root:[Epoch 63] train=0.850381 val=0.921500 loss=0.431016 time: 39.791850
INFO:root:[Epoch 64] train=0.851462 val=0.916400 loss=0.426609 time: 39.827633
INFO:root:[Epoch 65] train=0.852544 val=0.909800 loss=0.424562 time: 39.833045
INFO:root:[Epoch 66] train=0.851462 val=0.922100 loss=0.426184 time: 39.839710
INFO:root:[Epoch 67] train=0.853486 val=0.903100 loss=0.423940 time: 39.785578
INFO:root:[Epoch 68] train=0.854868 val=0.907400 loss=0.422980 time: 39.772833
INFO:root:[Epoch 69] train=0.854567 val=0.913900 loss=0.415686 time: 39.856023
INFO:root:[Epoch 70] train=0.854107 val=0.916300 loss=0.418063 time: 39.833681
INFO:root:[Epoch 71] train=0.857933 val=0.911900 loss=0.412396 time: 39.841264
INFO:root:[Epoch 72] train=0.853285 val=0.907900 loss=0.424280 time: 39.791868
INFO:root:[Epoch 73] train=0.853446 val=0.913300 loss=0.425164 time: 39.779209
INFO:root:[Epoch 74] train=0.854507 val=0.899400 loss=0.421006 time: 39.796246
INFO:root:[Epoch 75] train=0.857492 val=0.899500 loss=0.412011 time: 39.873314
INFO:root:[Epoch 76] train=0.857352 val=0.913700 loss=0.418357 time: 39.781758
INFO:root:[Epoch 77] train=0.851202 val=0.907800 loss=0.428674 time: 39.909370
INFO:root:[Epoch 78] train=0.852063 val=0.917700 loss=0.427925 time: 39.773837
INFO:root:[Epoch 79] train=0.854667 val=0.913400 loss=0.423459 time: 39.797373
INFO:root:[Epoch 80] train=0.854006 val=0.913600 loss=0.420554 time: 39.884735
INFO:root:[Epoch 81] train=0.856110 val=0.907400 loss=0.421738 time: 39.805176
INFO:root:[Epoch 82] train=0.852264 val=0.919900 loss=0.422460 time: 39.837818
INFO:root:[Epoch 83] train=0.851663 val=0.898500 loss=0.427512 time: 39.847563
INFO:root:[Epoch 84] train=0.856110 val=0.904900 loss=0.418673 time: 39.849704
INFO:root:[Epoch 85] train=0.856911 val=0.910300 loss=0.414803 time: 39.900617
INFO:root:[Epoch 86] train=0.857212 val=0.910900 loss=0.415562 time: 39.770633
INFO:root:[Epoch 87] train=0.857452 val=0.897400 loss=0.410264 time: 39.824481
INFO:root:[Epoch 88] train=0.857051 val=0.908100 loss=0.414818 time: 39.920430
INFO:root:[Epoch 89] train=0.859896 val=0.914800 loss=0.409558 time: 39.827833
INFO:root:[Epoch 90] train=0.858073 val=0.904000 loss=0.414993 time: 39.849528
INFO:root:[Epoch 91] train=0.858754 val=0.911500 loss=0.411163 time: 39.861778
INFO:root:[Epoch 92] train=0.858554 val=0.915800 loss=0.408031 time: 39.871713
INFO:root:[Epoch 93] train=0.858734 val=0.916000 loss=0.408591 time: 39.851343
INFO:root:[Epoch 94] train=0.856510 val=0.906900 loss=0.414684 time: 39.822587
INFO:root:[Epoch 95] train=0.860036 val=0.907500 loss=0.404053 time: 39.887094
INFO:root:[Epoch 96] train=0.859696 val=0.898600 loss=0.409964 time: 39.811444
INFO:root:[Epoch 97] train=0.858874 val=0.908700 loss=0.407513 time: 39.872659
INFO:root:[Epoch 98] train=0.860637 val=0.895600 loss=0.403894 time: 39.912910
INFO:root:[Epoch 99] train=0.859315 val=0.915600 loss=0.406457 time: 39.951841
INFO:root:[Epoch 100] train=0.862540 val=0.921000 loss=0.399887 time: 39.868497
INFO:root:[Epoch 101] train=0.859295 val=0.895700 loss=0.405268 time: 40.059152
INFO:root:[Epoch 102] train=0.860096 val=0.920000 loss=0.404095 time: 39.935850
INFO:root:[Epoch 103] train=0.861679 val=0.916900 loss=0.402317 time: 39.880929
INFO:root:[Epoch 104] train=0.860777 val=0.905300 loss=0.400993 time: 39.868361
INFO:root:[Epoch 105] train=0.862901 val=0.917400 loss=0.397952 time: 39.954714
INFO:root:[Epoch 106] train=0.859014 val=0.916700 loss=0.406321 time: 39.898843
INFO:root:[Epoch 107] train=0.862480 val=0.904500 loss=0.396689 time: 39.941849
INFO:root:[Epoch 108] train=0.863041 val=0.910600 loss=0.394308 time: 39.869237
INFO:root:[Epoch 109] train=0.863201 val=0.920800 loss=0.395212 time: 39.912566
INFO:root:[Epoch 110] train=0.862440 val=0.904700 loss=0.401607 time: 39.876551
INFO:root:[Epoch 111] train=0.862600 val=0.910800 loss=0.401153 time: 39.860777
INFO:root:[Epoch 112] train=0.862800 val=0.919400 loss=0.399150 time: 39.844690
INFO:root:[Epoch 113] train=0.862099 val=0.914800 loss=0.399105 time: 39.923101
INFO:root:[Epoch 114] train=0.865064 val=0.919100 loss=0.394641 time: 39.951015
INFO:root:[Epoch 115] train=0.865645 val=0.914500 loss=0.389248 time: 39.998131
INFO:root:[Epoch 116] train=0.863361 val=0.909600 loss=0.394590 time: 39.997859
INFO:root:[Epoch 117] train=0.863542 val=0.913500 loss=0.393440 time: 39.963259
INFO:root:[Epoch 118] train=0.866907 val=0.912600 loss=0.384648 time: 40.046005
INFO:root:[Epoch 119] train=0.864663 val=0.910300 loss=0.392128 time: 39.930689
INFO:root:[Epoch 120] train=0.894551 val=0.943000 loss=0.310722 time: 39.905567
INFO:root:[Epoch 121] train=0.907752 val=0.942800 loss=0.271532 time: 39.832788
INFO:root:[Epoch 122] train=0.913061 val=0.944100 loss=0.260743 time: 39.916822
INFO:root:[Epoch 123] train=0.914964 val=0.945000 loss=0.252476 time: 39.946153
INFO:root:[Epoch 124] train=0.915665 val=0.942400 loss=0.248499 time: 39.888234
INFO:root:[Epoch 125] train=0.918129 val=0.943900 loss=0.243881 time: 39.929018
INFO:root:[Epoch 126] train=0.917308 val=0.944300 loss=0.245150 time: 39.952145
INFO:root:[Epoch 127] train=0.920252 val=0.942600 loss=0.235161 time: 39.932863
INFO:root:[Epoch 128] train=0.919391 val=0.945200 loss=0.239037 time: 40.014818
INFO:root:[Epoch 129] train=0.920353 val=0.945400 loss=0.237275 time: 39.939393
INFO:root:[Epoch 130] train=0.920974 val=0.942900 loss=0.232033 time: 39.969805
INFO:root:[Epoch 131] train=0.921434 val=0.945300 loss=0.232120 time: 40.075248
INFO:root:[Epoch 132] train=0.921434 val=0.943100 loss=0.231710 time: 39.948957
INFO:root:[Epoch 133] train=0.921134 val=0.942400 loss=0.236025 time: 39.913458
INFO:root:[Epoch 134] train=0.922656 val=0.940600 loss=0.231696 time: 39.830519
INFO:root:[Epoch 135] train=0.921875 val=0.941600 loss=0.230640 time: 39.984144
INFO:root:[Epoch 136] train=0.922857 val=0.943300 loss=0.227257 time: 40.003623
INFO:root:[Epoch 137] train=0.923357 val=0.942700 loss=0.227659 time: 39.906514
INFO:root:[Epoch 138] train=0.924199 val=0.944700 loss=0.224790 time: 39.883627
INFO:root:[Epoch 139] train=0.923618 val=0.941300 loss=0.224154 time: 39.887437
INFO:root:[Epoch 140] train=0.924760 val=0.945500 loss=0.223600 time: 39.941653
INFO:root:[Epoch 141] train=0.923077 val=0.944800 loss=0.225882 time: 39.987157
INFO:root:[Epoch 142] train=0.926042 val=0.945000 loss=0.219942 time: 39.920203
INFO:root:[Epoch 143] train=0.924159 val=0.943300 loss=0.224277 time: 39.943829
INFO:root:[Epoch 144] train=0.923858 val=0.942400 loss=0.225345 time: 39.906485
INFO:root:[Epoch 145] train=0.922015 val=0.943000 loss=0.230572 time: 39.953102
INFO:root:[Epoch 146] train=0.925641 val=0.940600 loss=0.222919 time: 39.978985
INFO:root:[Epoch 147] train=0.925761 val=0.942200 loss=0.221450 time: 39.859160
INFO:root:[Epoch 148] train=0.925381 val=0.938900 loss=0.221820 time: 39.924920
INFO:root:[Epoch 149] train=0.924279 val=0.940400 loss=0.223607 time: 39.908517
INFO:root:[Epoch 150] train=0.924379 val=0.939400 loss=0.224708 time: 39.944048
INFO:root:[Epoch 151] train=0.923618 val=0.942700 loss=0.226100 time: 39.909683
INFO:root:[Epoch 152] train=0.922596 val=0.939400 loss=0.228542 time: 39.848375
INFO:root:[Epoch 153] train=0.924539 val=0.942200 loss=0.223751 time: 39.937882
INFO:root:[Epoch 154] train=0.926562 val=0.940000 loss=0.218716 time: 39.887737
INFO:root:[Epoch 155] train=0.927183 val=0.939600 loss=0.217801 time: 39.813377
INFO:root:[Epoch 156] train=0.927324 val=0.939700 loss=0.215933 time: 39.993235
INFO:root:[Epoch 157] train=0.924299 val=0.940200 loss=0.224300 time: 39.912914
INFO:root:[Epoch 158] train=0.927063 val=0.943800 loss=0.219274 time: 39.954365
INFO:root:[Epoch 159] train=0.925240 val=0.942200 loss=0.223724 time: 39.871061
INFO:root:[Epoch 160] train=0.934455 val=0.947300 loss=0.196639 time: 39.995145
INFO:root:[Epoch 161] train=0.935497 val=0.949100 loss=0.190857 time: 39.929317
INFO:root:[Epoch 162] train=0.938121 val=0.948500 loss=0.184330 time: 39.957375
INFO:root:[Epoch 163] train=0.942067 val=0.949900 loss=0.175926 time: 39.864906
INFO:root:[Epoch 164] train=0.939824 val=0.947100 loss=0.181568 time: 39.892420
INFO:root:[Epoch 165] train=0.941927 val=0.949000 loss=0.174189 time: 39.857025
INFO:root:[Epoch 166] train=0.941186 val=0.949300 loss=0.175598 time: 39.889998
INFO:root:[Epoch 167] train=0.942268 val=0.948200 loss=0.173309 time: 39.997606
INFO:root:[Epoch 168] train=0.941106 val=0.950500 loss=0.174353 time: 40.016865
INFO:root:[Epoch 169] train=0.942268 val=0.949300 loss=0.173178 time: 39.886315
INFO:root:[Epoch 170] train=0.942167 val=0.951300 loss=0.172847 time: 39.865127
INFO:root:[Epoch 171] train=0.944311 val=0.949600 loss=0.167612 time: 39.939744
INFO:root:[Epoch 172] train=0.943049 val=0.949600 loss=0.170528 time: 40.036398
INFO:root:[Epoch 173] train=0.944511 val=0.949200 loss=0.169585 time: 40.026447
INFO:root:[Epoch 174] train=0.943450 val=0.949500 loss=0.167453 time: 39.931673
INFO:root:[Epoch 175] train=0.943630 val=0.950000 loss=0.167426 time: 40.027325
INFO:root:[Epoch 176] train=0.944912 val=0.949100 loss=0.165604 time: 39.913910
INFO:root:[Epoch 177] train=0.943610 val=0.949400 loss=0.169777 time: 39.948683
INFO:root:[Epoch 178] train=0.942568 val=0.948100 loss=0.166457 time: 40.078898
INFO:root:[Epoch 179] train=0.943610 val=0.949800 loss=0.168057 time: 39.879781
INFO:root:[Epoch 180] train=0.945573 val=0.947200 loss=0.164862 time: 39.955472
INFO:root:[Epoch 181] train=0.944752 val=0.949800 loss=0.166103 time: 39.918956
INFO:root:[Epoch 182] train=0.943750 val=0.949300 loss=0.164468 time: 39.957617
INFO:root:[Epoch 183] train=0.945252 val=0.948400 loss=0.164285 time: 40.032137
INFO:root:[Epoch 184] train=0.943630 val=0.949900 loss=0.165323 time: 39.963066
INFO:root:[Epoch 185] train=0.944952 val=0.949600 loss=0.165847 time: 40.027601
INFO:root:[Epoch 186] train=0.946354 val=0.947700 loss=0.163016 time: 39.920783
INFO:root:[Epoch 187] train=0.947035 val=0.949200 loss=0.160781 time: 39.938245
INFO:root:[Epoch 188] train=0.946675 val=0.949800 loss=0.162143 time: 39.936847
INFO:root:[Epoch 189] train=0.946414 val=0.949000 loss=0.160592 time: 39.903898
INFO:root:[Epoch 190] train=0.947696 val=0.949300 loss=0.156971 time: 39.995063
INFO:root:[Epoch 191] train=0.945493 val=0.948600 loss=0.163641 time: 39.952992
INFO:root:[Epoch 192] train=0.944992 val=0.948100 loss=0.164635 time: 39.981383
INFO:root:[Epoch 193] train=0.946074 val=0.947200 loss=0.158988 time: 39.926449
INFO:root:[Epoch 194] train=0.946374 val=0.949100 loss=0.160179 time: 39.963294
INFO:root:[Epoch 195] train=0.945833 val=0.946200 loss=0.162022 time: 39.927041
INFO:root:[Epoch 196] train=0.944932 val=0.947400 loss=0.162062 time: 39.984121
INFO:root:[Epoch 197] train=0.944692 val=0.948300 loss=0.162815 time: 39.989228
INFO:root:[Epoch 198] train=0.946835 val=0.947300 loss=0.159591 time: 39.985768
INFO:root:[Epoch 199] train=0.946214 val=0.947100 loss=0.159616 time: 39.959171
