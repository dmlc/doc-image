INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.1, lr_decay_epoch='80,160', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v2', momentum=0.9, num_epochs=240, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0001)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[08:41:39] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.354387 val=0.446800 loss=1.750611 time: 8.434618
INFO:root:[Epoch 1] train=0.485657 val=0.510300 loss=1.430388 time: 7.891170
INFO:root:[Epoch 2] train=0.539183 val=0.592900 loss=1.287301 time: 7.833339
INFO:root:[Epoch 3] train=0.573037 val=0.635300 loss=1.199727 time: 8.058254
INFO:root:[Epoch 4] train=0.594952 val=0.564300 loss=1.134455 time: 7.869810
INFO:root:[Epoch 5] train=0.622416 val=0.660300 loss=1.066909 time: 7.917036
INFO:root:[Epoch 6] train=0.632272 val=0.714700 loss=1.036288 time: 7.900385
INFO:root:[Epoch 7] train=0.650561 val=0.708600 loss=0.994221 time: 7.779933
INFO:root:[Epoch 8] train=0.659836 val=0.738900 loss=0.966692 time: 7.971196
INFO:root:[Epoch 9] train=0.665645 val=0.731600 loss=0.950535 time: 7.811097
INFO:root:[Epoch 10] train=0.678506 val=0.752600 loss=0.919803 time: 8.074412
INFO:root:[Epoch 11] train=0.682151 val=0.728400 loss=0.905859 time: 7.844872
INFO:root:[Epoch 12] train=0.687460 val=0.748200 loss=0.892833 time: 8.111305
INFO:root:[Epoch 13] train=0.693910 val=0.748300 loss=0.874403 time: 8.004747
INFO:root:[Epoch 14] train=0.694491 val=0.761600 loss=0.866519 time: 7.818332
INFO:root:[Epoch 15] train=0.700541 val=0.745200 loss=0.857355 time: 7.871221
INFO:root:[Epoch 16] train=0.706410 val=0.761800 loss=0.836699 time: 7.892990
INFO:root:[Epoch 17] train=0.708173 val=0.769800 loss=0.835134 time: 7.924705
INFO:root:[Epoch 18] train=0.715024 val=0.723000 loss=0.817180 time: 7.907673
INFO:root:[Epoch 19] train=0.715845 val=0.772700 loss=0.817727 time: 7.900901
INFO:root:[Epoch 20] train=0.720573 val=0.804100 loss=0.804511 time: 7.866921
INFO:root:[Epoch 21] train=0.718269 val=0.778200 loss=0.805098 time: 8.016886
INFO:root:[Epoch 22] train=0.724920 val=0.813500 loss=0.786767 time: 8.058447
INFO:root:[Epoch 23] train=0.724639 val=0.797400 loss=0.781711 time: 7.939630
INFO:root:[Epoch 24] train=0.728425 val=0.806100 loss=0.778096 time: 7.913171
INFO:root:[Epoch 25] train=0.726322 val=0.775700 loss=0.775574 time: 7.926299
INFO:root:[Epoch 26] train=0.730990 val=0.775100 loss=0.772817 time: 8.044165
INFO:root:[Epoch 27] train=0.732272 val=0.776600 loss=0.765177 time: 7.923709
INFO:root:[Epoch 28] train=0.736178 val=0.796000 loss=0.757605 time: 7.971223
INFO:root:[Epoch 29] train=0.734155 val=0.823600 loss=0.759770 time: 7.935196
INFO:root:[Epoch 30] train=0.739303 val=0.804800 loss=0.748300 time: 7.898057
INFO:root:[Epoch 31] train=0.741326 val=0.796200 loss=0.744441 time: 8.135788
INFO:root:[Epoch 32] train=0.738722 val=0.788200 loss=0.747024 time: 7.977941
INFO:root:[Epoch 33] train=0.744171 val=0.815000 loss=0.734661 time: 7.999985
INFO:root:[Epoch 34] train=0.739744 val=0.816000 loss=0.743120 time: 7.942174
INFO:root:[Epoch 35] train=0.746595 val=0.807200 loss=0.726540 time: 7.947810
INFO:root:[Epoch 36] train=0.743750 val=0.812200 loss=0.731815 time: 7.969975
INFO:root:[Epoch 37] train=0.743089 val=0.808400 loss=0.733513 time: 8.015917
INFO:root:[Epoch 38] train=0.746134 val=0.824400 loss=0.727243 time: 8.031905
INFO:root:[Epoch 39] train=0.746735 val=0.806000 loss=0.723657 time: 7.928215
INFO:root:[Epoch 40] train=0.744271 val=0.817100 loss=0.725791 time: 8.084753
INFO:root:[Epoch 41] train=0.749179 val=0.820200 loss=0.715077 time: 8.002013
INFO:root:[Epoch 42] train=0.748918 val=0.779500 loss=0.719819 time: 7.982557
INFO:root:[Epoch 43] train=0.747516 val=0.816500 loss=0.718038 time: 7.913001
INFO:root:[Epoch 44] train=0.750601 val=0.838000 loss=0.712759 time: 7.954991
INFO:root:[Epoch 45] train=0.753245 val=0.829500 loss=0.706685 time: 8.054813
INFO:root:[Epoch 46] train=0.753165 val=0.770400 loss=0.707836 time: 7.900597
INFO:root:[Epoch 47] train=0.753285 val=0.836600 loss=0.705968 time: 7.902435
INFO:root:[Epoch 48] train=0.751522 val=0.822100 loss=0.709741 time: 7.896986
INFO:root:[Epoch 49] train=0.751082 val=0.820600 loss=0.708170 time: 7.989918
INFO:root:[Epoch 50] train=0.756230 val=0.815100 loss=0.700349 time: 8.046201
INFO:root:[Epoch 51] train=0.753065 val=0.841700 loss=0.700038 time: 7.988416
INFO:root:[Epoch 52] train=0.755489 val=0.810800 loss=0.697075 time: 7.902893
INFO:root:[Epoch 53] train=0.760477 val=0.817700 loss=0.687348 time: 7.970611
INFO:root:[Epoch 54] train=0.759716 val=0.823200 loss=0.691146 time: 8.086196
INFO:root:[Epoch 55] train=0.757812 val=0.827200 loss=0.698132 time: 7.905975
INFO:root:[Epoch 56] train=0.761298 val=0.818100 loss=0.690356 time: 7.911487
INFO:root:[Epoch 57] train=0.756190 val=0.824800 loss=0.693098 time: 8.060641
INFO:root:[Epoch 58] train=0.755929 val=0.819000 loss=0.698537 time: 8.009697
INFO:root:[Epoch 59] train=0.759175 val=0.838100 loss=0.685154 time: 7.971065
INFO:root:[Epoch 60] train=0.762179 val=0.814200 loss=0.684741 time: 8.047203
INFO:root:[Epoch 61] train=0.760837 val=0.826700 loss=0.689265 time: 7.955836
INFO:root:[Epoch 62] train=0.762119 val=0.842700 loss=0.685048 time: 7.922108
INFO:root:[Epoch 63] train=0.759435 val=0.822400 loss=0.685223 time: 8.209026
INFO:root:[Epoch 64] train=0.760537 val=0.840300 loss=0.685968 time: 7.987570
INFO:root:[Epoch 65] train=0.764844 val=0.823600 loss=0.676646 time: 7.983469
INFO:root:[Epoch 66] train=0.763101 val=0.845800 loss=0.679566 time: 7.947907
INFO:root:[Epoch 67] train=0.763682 val=0.822900 loss=0.676210 time: 7.937652
INFO:root:[Epoch 68] train=0.761739 val=0.850000 loss=0.679029 time: 8.100591
INFO:root:[Epoch 69] train=0.764583 val=0.792600 loss=0.673094 time: 8.055228
INFO:root:[Epoch 70] train=0.768289 val=0.829800 loss=0.667869 time: 7.990318
INFO:root:[Epoch 71] train=0.764483 val=0.810500 loss=0.677019 time: 7.936101
INFO:root:[Epoch 72] train=0.761679 val=0.839600 loss=0.680925 time: 7.973771
INFO:root:[Epoch 73] train=0.762380 val=0.819400 loss=0.679871 time: 7.952274
INFO:root:[Epoch 74] train=0.764563 val=0.831000 loss=0.676033 time: 8.075350
INFO:root:[Epoch 75] train=0.767167 val=0.848200 loss=0.671563 time: 7.865387
INFO:root:[Epoch 76] train=0.766987 val=0.850400 loss=0.673910 time: 8.017220
INFO:root:[Epoch 77] train=0.764062 val=0.831600 loss=0.672924 time: 8.149701
INFO:root:[Epoch 78] train=0.770693 val=0.833100 loss=0.662048 time: 8.064324
INFO:root:[Epoch 79] train=0.765545 val=0.853400 loss=0.672227 time: 8.036738
INFO:root:[Epoch 80] train=0.799279 val=0.885300 loss=0.584901 time: 7.917793
INFO:root:[Epoch 81] train=0.813562 val=0.890700 loss=0.535240 time: 8.027812
INFO:root:[Epoch 82] train=0.815024 val=0.891800 loss=0.525639 time: 7.988517
INFO:root:[Epoch 83] train=0.822436 val=0.887900 loss=0.514219 time: 7.930388
INFO:root:[Epoch 84] train=0.823738 val=0.893600 loss=0.509555 time: 8.032193
INFO:root:[Epoch 85] train=0.826042 val=0.894300 loss=0.500747 time: 7.919500
INFO:root:[Epoch 86] train=0.825821 val=0.895600 loss=0.499635 time: 8.026159
INFO:root:[Epoch 87] train=0.828005 val=0.893800 loss=0.497199 time: 7.921520
INFO:root:[Epoch 88] train=0.825761 val=0.897400 loss=0.498822 time: 8.051002
INFO:root:[Epoch 89] train=0.825501 val=0.897600 loss=0.500259 time: 8.072327
INFO:root:[Epoch 90] train=0.831210 val=0.896900 loss=0.486338 time: 7.983436
INFO:root:[Epoch 91] train=0.830689 val=0.897300 loss=0.487367 time: 8.138220
INFO:root:[Epoch 92] train=0.831951 val=0.897000 loss=0.483122 time: 8.072982
INFO:root:[Epoch 93] train=0.830889 val=0.898300 loss=0.490266 time: 8.018219
INFO:root:[Epoch 94] train=0.829287 val=0.897300 loss=0.487231 time: 8.098640
INFO:root:[Epoch 95] train=0.833253 val=0.897500 loss=0.480755 time: 7.979690
INFO:root:[Epoch 96] train=0.833433 val=0.896800 loss=0.480131 time: 8.077522
INFO:root:[Epoch 97] train=0.833273 val=0.897800 loss=0.476600 time: 7.973343
INFO:root:[Epoch 98] train=0.833153 val=0.896700 loss=0.477838 time: 7.962533
INFO:root:[Epoch 99] train=0.833934 val=0.898300 loss=0.476836 time: 8.075553
INFO:root:[Epoch 100] train=0.833253 val=0.895800 loss=0.475636 time: 8.097817
INFO:root:[Epoch 101] train=0.833373 val=0.898100 loss=0.477661 time: 8.103270
INFO:root:[Epoch 102] train=0.836258 val=0.894100 loss=0.472146 time: 7.998785
INFO:root:[Epoch 103] train=0.835357 val=0.896200 loss=0.474662 time: 7.923023
INFO:root:[Epoch 104] train=0.835216 val=0.899300 loss=0.470207 time: 8.077076
INFO:root:[Epoch 105] train=0.838041 val=0.897600 loss=0.464549 time: 8.219613
INFO:root:[Epoch 106] train=0.835377 val=0.896900 loss=0.471738 time: 8.051122
INFO:root:[Epoch 107] train=0.837139 val=0.897500 loss=0.468709 time: 8.132331
INFO:root:[Epoch 108] train=0.838141 val=0.898400 loss=0.459903 time: 8.081732
INFO:root:[Epoch 109] train=0.838702 val=0.897900 loss=0.468559 time: 8.050051
INFO:root:[Epoch 110] train=0.838041 val=0.897000 loss=0.462519 time: 8.111269
INFO:root:[Epoch 111] train=0.840545 val=0.895100 loss=0.461252 time: 7.955463
INFO:root:[Epoch 112] train=0.839002 val=0.894100 loss=0.461995 time: 7.975994
INFO:root:[Epoch 113] train=0.839063 val=0.894400 loss=0.465619 time: 8.095031
INFO:root:[Epoch 114] train=0.837220 val=0.895900 loss=0.467186 time: 8.038023
INFO:root:[Epoch 115] train=0.839603 val=0.899000 loss=0.459304 time: 8.020855
INFO:root:[Epoch 116] train=0.837580 val=0.896700 loss=0.467696 time: 8.053946
INFO:root:[Epoch 117] train=0.840284 val=0.897000 loss=0.455071 time: 8.045201
INFO:root:[Epoch 118] train=0.837600 val=0.898900 loss=0.463843 time: 7.954326
INFO:root:[Epoch 119] train=0.840325 val=0.899200 loss=0.455034 time: 7.983176
INFO:root:[Epoch 120] train=0.837740 val=0.899900 loss=0.465053 time: 8.115052
INFO:root:[Epoch 121] train=0.840365 val=0.902100 loss=0.460549 time: 8.003867
INFO:root:[Epoch 122] train=0.840605 val=0.896700 loss=0.458479 time: 8.105994
INFO:root:[Epoch 123] train=0.842728 val=0.896900 loss=0.450277 time: 8.150656
INFO:root:[Epoch 124] train=0.839343 val=0.895300 loss=0.461258 time: 8.064684
INFO:root:[Epoch 125] train=0.842949 val=0.903300 loss=0.449444 time: 8.026346
INFO:root:[Epoch 126] train=0.840144 val=0.898700 loss=0.454203 time: 8.139153
INFO:root:[Epoch 127] train=0.843670 val=0.897300 loss=0.449151 time: 8.004378
INFO:root:[Epoch 128] train=0.840765 val=0.898700 loss=0.454955 time: 8.228822
INFO:root:[Epoch 129] train=0.842508 val=0.897200 loss=0.453166 time: 8.039248
INFO:root:[Epoch 130] train=0.841086 val=0.899900 loss=0.450318 time: 8.079987
INFO:root:[Epoch 131] train=0.843510 val=0.899100 loss=0.448653 time: 8.049695
INFO:root:[Epoch 132] train=0.841266 val=0.895900 loss=0.455833 time: 8.114383
INFO:root:[Epoch 133] train=0.840465 val=0.901000 loss=0.456652 time: 7.991938
INFO:root:[Epoch 134] train=0.843970 val=0.900700 loss=0.447373 time: 7.987903
INFO:root:[Epoch 135] train=0.839864 val=0.892700 loss=0.452205 time: 8.121584
INFO:root:[Epoch 136] train=0.842268 val=0.897400 loss=0.450687 time: 8.182797
INFO:root:[Epoch 137] train=0.841066 val=0.902100 loss=0.456479 time: 8.116914
INFO:root:[Epoch 138] train=0.842468 val=0.895600 loss=0.454868 time: 8.135531
INFO:root:[Epoch 139] train=0.843850 val=0.898300 loss=0.448042 time: 8.028077
INFO:root:[Epoch 140] train=0.842408 val=0.895500 loss=0.451919 time: 8.112131
INFO:root:[Epoch 141] train=0.845793 val=0.895700 loss=0.444889 time: 8.258924
INFO:root:[Epoch 142] train=0.842468 val=0.896300 loss=0.451683 time: 8.146434
INFO:root:[Epoch 143] train=0.842328 val=0.896600 loss=0.446581 time: 8.031785
INFO:root:[Epoch 144] train=0.845192 val=0.899100 loss=0.445541 time: 8.165191
INFO:root:[Epoch 145] train=0.842127 val=0.894200 loss=0.453104 time: 8.144727
INFO:root:[Epoch 146] train=0.844872 val=0.898500 loss=0.447957 time: 8.249551
INFO:root:[Epoch 147] train=0.843169 val=0.901000 loss=0.448551 time: 8.174293
INFO:root:[Epoch 148] train=0.843329 val=0.898600 loss=0.448582 time: 7.984698
INFO:root:[Epoch 149] train=0.844431 val=0.899300 loss=0.446784 time: 8.168340
INFO:root:[Epoch 150] train=0.843950 val=0.899700 loss=0.445023 time: 8.045912
INFO:root:[Epoch 151] train=0.846474 val=0.898200 loss=0.442361 time: 8.188659
INFO:root:[Epoch 152] train=0.842929 val=0.898000 loss=0.446997 time: 8.056187
INFO:root:[Epoch 153] train=0.841747 val=0.895500 loss=0.452591 time: 8.111293
INFO:root:[Epoch 154] train=0.843790 val=0.894500 loss=0.446847 time: 8.229962
INFO:root:[Epoch 155] train=0.844892 val=0.898900 loss=0.444578 time: 8.252144
INFO:root:[Epoch 156] train=0.844311 val=0.893300 loss=0.447047 time: 8.103321
INFO:root:[Epoch 157] train=0.846014 val=0.898300 loss=0.443532 time: 8.126531
INFO:root:[Epoch 158] train=0.844772 val=0.900000 loss=0.443685 time: 8.034197
INFO:root:[Epoch 159] train=0.844692 val=0.899800 loss=0.446952 time: 8.125019
INFO:root:[Epoch 160] train=0.852845 val=0.904600 loss=0.426850 time: 8.051096
INFO:root:[Epoch 161] train=0.855469 val=0.905100 loss=0.418512 time: 8.173052
INFO:root:[Epoch 162] train=0.856711 val=0.906500 loss=0.414170 time: 8.080614
INFO:root:[Epoch 163] train=0.856030 val=0.905000 loss=0.412424 time: 8.116413
INFO:root:[Epoch 164] train=0.859335 val=0.907100 loss=0.405389 time: 8.138275
INFO:root:[Epoch 165] train=0.857192 val=0.905800 loss=0.406107 time: 8.140368
INFO:root:[Epoch 166] train=0.857612 val=0.907000 loss=0.411553 time: 8.072091
INFO:root:[Epoch 167] train=0.858313 val=0.907100 loss=0.405581 time: 8.258482
INFO:root:[Epoch 168] train=0.860136 val=0.907500 loss=0.403040 time: 8.055384
INFO:root:[Epoch 169] train=0.860917 val=0.906900 loss=0.398387 time: 8.084990
INFO:root:[Epoch 170] train=0.858213 val=0.906400 loss=0.407424 time: 8.108118
INFO:root:[Epoch 171] train=0.859315 val=0.907600 loss=0.403742 time: 8.098446
INFO:root:[Epoch 172] train=0.857592 val=0.907500 loss=0.404969 time: 8.117725
INFO:root:[Epoch 173] train=0.860938 val=0.906200 loss=0.396974 time: 8.184347
INFO:root:[Epoch 174] train=0.859716 val=0.907000 loss=0.401702 time: 8.133035
INFO:root:[Epoch 175] train=0.859796 val=0.906200 loss=0.404269 time: 8.138500
INFO:root:[Epoch 176] train=0.860938 val=0.906300 loss=0.401672 time: 8.085644
INFO:root:[Epoch 177] train=0.860998 val=0.907700 loss=0.401899 time: 8.111196
INFO:root:[Epoch 178] train=0.859716 val=0.906700 loss=0.403175 time: 8.132637
INFO:root:[Epoch 179] train=0.863041 val=0.906300 loss=0.396940 time: 8.021437
INFO:root:[Epoch 180] train=0.860797 val=0.907700 loss=0.400198 time: 8.087919
INFO:root:[Epoch 181] train=0.860196 val=0.906100 loss=0.403229 time: 8.216018
INFO:root:[Epoch 182] train=0.862981 val=0.905400 loss=0.391267 time: 8.327546
INFO:root:[Epoch 183] train=0.861078 val=0.906000 loss=0.400922 time: 8.056773
INFO:root:[Epoch 184] train=0.863542 val=0.907100 loss=0.395428 time: 8.088919
INFO:root:[Epoch 185] train=0.861198 val=0.905000 loss=0.399089 time: 8.216592
INFO:root:[Epoch 186] train=0.860877 val=0.906700 loss=0.400910 time: 8.186397
INFO:root:[Epoch 187] train=0.863462 val=0.906400 loss=0.394619 time: 8.148527
INFO:root:[Epoch 188] train=0.862500 val=0.905500 loss=0.396325 time: 8.174914
INFO:root:[Epoch 189] train=0.861839 val=0.908100 loss=0.398205 time: 8.094591
INFO:root:[Epoch 190] train=0.861599 val=0.906100 loss=0.395157 time: 8.114373
INFO:root:[Epoch 191] train=0.861859 val=0.907100 loss=0.395087 time: 8.314595
INFO:root:[Epoch 192] train=0.863442 val=0.907800 loss=0.393013 time: 8.127216
INFO:root:[Epoch 193] train=0.860597 val=0.906400 loss=0.398043 time: 8.158235
INFO:root:[Epoch 194] train=0.864103 val=0.907900 loss=0.392574 time: 8.139344
INFO:root:[Epoch 195] train=0.864543 val=0.908300 loss=0.389236 time: 8.137318
INFO:root:[Epoch 196] train=0.865264 val=0.907600 loss=0.389443 time: 8.210771
INFO:root:[Epoch 197] train=0.864243 val=0.907400 loss=0.391454 time: 8.084825
INFO:root:[Epoch 198] train=0.864744 val=0.908400 loss=0.389307 time: 8.138490
INFO:root:[Epoch 199] train=0.863522 val=0.908800 loss=0.390575 time: 8.066244
INFO:root:[Epoch 200] train=0.863401 val=0.908100 loss=0.393714 time: 8.326466
INFO:root:[Epoch 201] train=0.863802 val=0.908700 loss=0.390628 time: 8.139861
INFO:root:[Epoch 202] train=0.862760 val=0.908200 loss=0.392351 time: 8.085817
INFO:root:[Epoch 203] train=0.864944 val=0.907800 loss=0.391570 time: 8.093342
INFO:root:[Epoch 204] train=0.861959 val=0.908000 loss=0.395611 time: 8.215554
INFO:root:[Epoch 205] train=0.864964 val=0.906900 loss=0.390106 time: 8.239327
INFO:root:[Epoch 206] train=0.865625 val=0.907600 loss=0.390154 time: 8.136730
INFO:root:[Epoch 207] train=0.861518 val=0.907600 loss=0.395601 time: 8.124753
INFO:root:[Epoch 208] train=0.863502 val=0.906800 loss=0.392469 time: 8.138767
INFO:root:[Epoch 209] train=0.860877 val=0.906000 loss=0.398766 time: 8.387719
INFO:root:[Epoch 210] train=0.862580 val=0.906800 loss=0.391764 time: 8.148556
INFO:root:[Epoch 211] train=0.863301 val=0.907700 loss=0.391064 time: 8.139511
INFO:root:[Epoch 212] train=0.862800 val=0.907400 loss=0.391455 time: 8.135503
INFO:root:[Epoch 213] train=0.863882 val=0.908100 loss=0.393063 time: 8.190237
INFO:root:[Epoch 214] train=0.864864 val=0.907800 loss=0.389824 time: 8.238563
INFO:root:[Epoch 215] train=0.863261 val=0.905900 loss=0.389653 time: 8.119600
INFO:root:[Epoch 216] train=0.864002 val=0.908700 loss=0.390112 time: 8.128394
INFO:root:[Epoch 217] train=0.862680 val=0.908900 loss=0.392590 time: 8.153053
INFO:root:[Epoch 218] train=0.862360 val=0.908100 loss=0.391906 time: 8.378948
INFO:root:[Epoch 219] train=0.865545 val=0.907100 loss=0.390648 time: 8.187547
INFO:root:[Epoch 220] train=0.865485 val=0.908200 loss=0.384955 time: 8.260467
INFO:root:[Epoch 221] train=0.863622 val=0.909500 loss=0.391611 time: 8.169434
INFO:root:[Epoch 222] train=0.863702 val=0.907600 loss=0.392754 time: 8.200221
INFO:root:[Epoch 223] train=0.862280 val=0.907300 loss=0.391019 time: 8.230045
INFO:root:[Epoch 224] train=0.861819 val=0.907700 loss=0.396687 time: 8.173929
INFO:root:[Epoch 225] train=0.865405 val=0.907500 loss=0.391010 time: 8.133190
INFO:root:[Epoch 226] train=0.862159 val=0.906000 loss=0.394966 time: 8.193920
INFO:root:[Epoch 227] train=0.863261 val=0.907000 loss=0.392119 time: 8.375209
INFO:root:[Epoch 228] train=0.865545 val=0.906100 loss=0.389360 time: 8.404116
INFO:root:[Epoch 229] train=0.865865 val=0.907800 loss=0.383159 time: 8.175635
INFO:root:[Epoch 230] train=0.863662 val=0.907400 loss=0.391194 time: 8.248476
INFO:root:[Epoch 231] train=0.866787 val=0.908000 loss=0.386503 time: 8.297860
INFO:root:[Epoch 232] train=0.862520 val=0.908800 loss=0.392948 time: 8.402314
INFO:root:[Epoch 233] train=0.862640 val=0.907900 loss=0.391587 time: 8.247329
INFO:root:[Epoch 234] train=0.865325 val=0.907100 loss=0.386874 time: 8.240982
INFO:root:[Epoch 235] train=0.863782 val=0.907500 loss=0.391106 time: 8.131510
INFO:root:[Epoch 236] train=0.864203 val=0.907200 loss=0.390025 time: 8.157226
INFO:root:[Epoch 237] train=0.865084 val=0.908400 loss=0.387508 time: 8.454403
INFO:root:[Epoch 238] train=0.864724 val=0.907400 loss=0.388049 time: 8.201318
INFO:root:[Epoch 239] train=0.864423 val=0.908700 loss=0.384701 time: 8.079167
