INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.1, lr_decay_epoch='80,160', lr_decay_period=0, mode='hybrid', model='cifar_resnet20_v1', momentum=0.9, num_epochs=240, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0001, width_factor=1)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[04:33:27] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.322055 val=0.371300 loss=1.823863 time: 7.920264
INFO:root:[Epoch 1] train=0.442989 val=0.503100 loss=1.527518 time: 7.439942
INFO:root:[Epoch 2] train=0.519391 val=0.561800 loss=1.335437 time: 7.500008
INFO:root:[Epoch 3] train=0.564143 val=0.654400 loss=1.218934 time: 7.463746
INFO:root:[Epoch 4] train=0.601302 val=0.682000 loss=1.130063 time: 7.457499
INFO:root:[Epoch 5] train=0.621675 val=0.676500 loss=1.071006 time: 7.462202
INFO:root:[Epoch 6] train=0.640785 val=0.710800 loss=1.019808 time: 7.487969
INFO:root:[Epoch 7] train=0.654087 val=0.746000 loss=0.985384 time: 7.377650
INFO:root:[Epoch 8] train=0.667027 val=0.744400 loss=0.952489 time: 7.323250
INFO:root:[Epoch 9] train=0.677304 val=0.733400 loss=0.923001 time: 7.626212
INFO:root:[Epoch 10] train=0.680168 val=0.749000 loss=0.911212 time: 7.387089
INFO:root:[Epoch 11] train=0.688882 val=0.755700 loss=0.887969 time: 7.483101
INFO:root:[Epoch 12] train=0.695152 val=0.730600 loss=0.870390 time: 7.480091
INFO:root:[Epoch 13] train=0.700000 val=0.785500 loss=0.855978 time: 7.557668
INFO:root:[Epoch 14] train=0.705288 val=0.750600 loss=0.845082 time: 7.589859
INFO:root:[Epoch 15] train=0.708313 val=0.777500 loss=0.829863 time: 7.502375
INFO:root:[Epoch 16] train=0.716046 val=0.745100 loss=0.817234 time: 7.566514
INFO:root:[Epoch 17] train=0.720453 val=0.798500 loss=0.803715 time: 7.363911
INFO:root:[Epoch 18] train=0.719772 val=0.775400 loss=0.799412 time: 7.505844
INFO:root:[Epoch 19] train=0.724259 val=0.801700 loss=0.787594 time: 7.508534
INFO:root:[Epoch 20] train=0.726142 val=0.815800 loss=0.785312 time: 7.555040
INFO:root:[Epoch 21] train=0.732632 val=0.789500 loss=0.771155 time: 7.526445
INFO:root:[Epoch 22] train=0.729507 val=0.785900 loss=0.769581 time: 7.365987
INFO:root:[Epoch 23] train=0.735577 val=0.812900 loss=0.759292 time: 7.526021
INFO:root:[Epoch 24] train=0.736899 val=0.809700 loss=0.754421 time: 7.932847
INFO:root:[Epoch 25] train=0.737079 val=0.794200 loss=0.747771 time: 7.827785
INFO:root:[Epoch 26] train=0.740905 val=0.808800 loss=0.739216 time: 7.951707
INFO:root:[Epoch 27] train=0.743409 val=0.807100 loss=0.735749 time: 7.807917
INFO:root:[Epoch 28] train=0.742087 val=0.782800 loss=0.739131 time: 7.998756
INFO:root:[Epoch 29] train=0.747336 val=0.799300 loss=0.732007 time: 7.936314
INFO:root:[Epoch 30] train=0.745913 val=0.802100 loss=0.726880 time: 7.969453
INFO:root:[Epoch 31] train=0.746234 val=0.819300 loss=0.723777 time: 7.893560
INFO:root:[Epoch 32] train=0.748978 val=0.803500 loss=0.717759 time: 8.090175
INFO:root:[Epoch 33] train=0.750280 val=0.823500 loss=0.714599 time: 7.955720
INFO:root:[Epoch 34] train=0.751082 val=0.812500 loss=0.710069 time: 7.814449
INFO:root:[Epoch 35] train=0.752063 val=0.817700 loss=0.712720 time: 7.987868
INFO:root:[Epoch 36] train=0.754227 val=0.816500 loss=0.706631 time: 7.878355
INFO:root:[Epoch 37] train=0.756110 val=0.830400 loss=0.699339 time: 7.892891
INFO:root:[Epoch 38] train=0.757352 val=0.788300 loss=0.699283 time: 7.896431
INFO:root:[Epoch 39] train=0.754147 val=0.817500 loss=0.706562 time: 7.955838
INFO:root:[Epoch 40] train=0.756270 val=0.812700 loss=0.696125 time: 7.890122
INFO:root:[Epoch 41] train=0.757432 val=0.799600 loss=0.695135 time: 7.966289
INFO:root:[Epoch 42] train=0.758794 val=0.831100 loss=0.689896 time: 7.890325
INFO:root:[Epoch 43] train=0.758393 val=0.831200 loss=0.687789 time: 7.930202
INFO:root:[Epoch 44] train=0.761779 val=0.820300 loss=0.684847 time: 7.966990
INFO:root:[Epoch 45] train=0.760657 val=0.798700 loss=0.685388 time: 7.795576
INFO:root:[Epoch 46] train=0.760357 val=0.782700 loss=0.688141 time: 7.958016
INFO:root:[Epoch 47] train=0.761078 val=0.776800 loss=0.682814 time: 7.930534
INFO:root:[Epoch 48] train=0.758814 val=0.832800 loss=0.694493 time: 7.959230
INFO:root:[Epoch 49] train=0.762340 val=0.792000 loss=0.680381 time: 8.025168
INFO:root:[Epoch 50] train=0.764483 val=0.833600 loss=0.676870 time: 7.797148
INFO:root:[Epoch 51] train=0.763181 val=0.800900 loss=0.674574 time: 7.890066
INFO:root:[Epoch 52] train=0.767348 val=0.835100 loss=0.673250 time: 7.960036
INFO:root:[Epoch 53] train=0.766506 val=0.812500 loss=0.669433 time: 7.993581
INFO:root:[Epoch 54] train=0.768750 val=0.823900 loss=0.667615 time: 7.869412
INFO:root:[Epoch 55] train=0.766226 val=0.824500 loss=0.670585 time: 7.902666
INFO:root:[Epoch 56] train=0.766486 val=0.818200 loss=0.673352 time: 7.942406
INFO:root:[Epoch 57] train=0.765585 val=0.840200 loss=0.673060 time: 7.984270
INFO:root:[Epoch 58] train=0.768990 val=0.838700 loss=0.668168 time: 7.883277
INFO:root:[Epoch 59] train=0.770012 val=0.829200 loss=0.662198 time: 7.934844
INFO:root:[Epoch 60] train=0.769491 val=0.841800 loss=0.667644 time: 7.935505
INFO:root:[Epoch 61] train=0.770473 val=0.830600 loss=0.660619 time: 7.988847
INFO:root:[Epoch 62] train=0.767087 val=0.830300 loss=0.666716 time: 7.833909
INFO:root:[Epoch 63] train=0.769351 val=0.840800 loss=0.665831 time: 7.959475
INFO:root:[Epoch 64] train=0.773798 val=0.840600 loss=0.652202 time: 7.973786
INFO:root:[Epoch 65] train=0.771655 val=0.835400 loss=0.654358 time: 7.857319
INFO:root:[Epoch 66] train=0.769471 val=0.837600 loss=0.660923 time: 7.880347
INFO:root:[Epoch 67] train=0.769651 val=0.848000 loss=0.661658 time: 8.001072
INFO:root:[Epoch 68] train=0.770713 val=0.839200 loss=0.656877 time: 8.093617
INFO:root:[Epoch 69] train=0.771955 val=0.835700 loss=0.649719 time: 8.038666
INFO:root:[Epoch 70] train=0.772396 val=0.834700 loss=0.651764 time: 7.935750
INFO:root:[Epoch 71] train=0.774800 val=0.820500 loss=0.644043 time: 8.074867
INFO:root:[Epoch 72] train=0.772696 val=0.814900 loss=0.651825 time: 8.003019
INFO:root:[Epoch 73] train=0.773077 val=0.831500 loss=0.652652 time: 7.977146
INFO:root:[Epoch 74] train=0.774760 val=0.846400 loss=0.649811 time: 7.898551
INFO:root:[Epoch 75] train=0.774820 val=0.844400 loss=0.648615 time: 7.993804
INFO:root:[Epoch 76] train=0.774960 val=0.821000 loss=0.648349 time: 8.095820
INFO:root:[Epoch 77] train=0.773197 val=0.845800 loss=0.649087 time: 7.930435
INFO:root:[Epoch 78] train=0.776943 val=0.826600 loss=0.646195 time: 7.944333
INFO:root:[Epoch 79] train=0.774900 val=0.830800 loss=0.646335 time: 8.013122
INFO:root:[Epoch 80] train=0.802845 val=0.882400 loss=0.566891 time: 7.990289
INFO:root:[Epoch 81] train=0.815865 val=0.888800 loss=0.528372 time: 7.893996
INFO:root:[Epoch 82] train=0.819411 val=0.890200 loss=0.516308 time: 8.012348
INFO:root:[Epoch 83] train=0.824379 val=0.889000 loss=0.505939 time: 8.036312
INFO:root:[Epoch 84] train=0.828145 val=0.890800 loss=0.497603 time: 7.955531
INFO:root:[Epoch 85] train=0.829447 val=0.892700 loss=0.489971 time: 8.034492
INFO:root:[Epoch 86] train=0.829427 val=0.892900 loss=0.489322 time: 8.109403
INFO:root:[Epoch 87] train=0.831170 val=0.892400 loss=0.485842 time: 8.003718
INFO:root:[Epoch 88] train=0.829768 val=0.891800 loss=0.488151 time: 8.128500
INFO:root:[Epoch 89] train=0.834555 val=0.892300 loss=0.479397 time: 8.013503
INFO:root:[Epoch 90] train=0.832833 val=0.893900 loss=0.479620 time: 7.931926
INFO:root:[Epoch 91] train=0.834635 val=0.891400 loss=0.476294 time: 8.011291
INFO:root:[Epoch 92] train=0.835317 val=0.894900 loss=0.477202 time: 7.982271
INFO:root:[Epoch 93] train=0.835777 val=0.893400 loss=0.472423 time: 7.994637
INFO:root:[Epoch 94] train=0.835036 val=0.892600 loss=0.476282 time: 7.896935
INFO:root:[Epoch 95] train=0.838041 val=0.894900 loss=0.467505 time: 8.087751
INFO:root:[Epoch 96] train=0.837059 val=0.894500 loss=0.468199 time: 8.063789
INFO:root:[Epoch 97] train=0.838562 val=0.895700 loss=0.464316 time: 8.100274
INFO:root:[Epoch 98] train=0.839463 val=0.892400 loss=0.464759 time: 8.012020
INFO:root:[Epoch 99] train=0.839403 val=0.895200 loss=0.461853 time: 8.078530
INFO:root:[Epoch 100] train=0.837720 val=0.896200 loss=0.468286 time: 8.096738
INFO:root:[Epoch 101] train=0.839864 val=0.894700 loss=0.460948 time: 8.106335
INFO:root:[Epoch 102] train=0.840946 val=0.892700 loss=0.462710 time: 7.979885
INFO:root:[Epoch 103] train=0.838061 val=0.895700 loss=0.462846 time: 7.951780
INFO:root:[Epoch 104] train=0.840405 val=0.893900 loss=0.454481 time: 8.040605
INFO:root:[Epoch 105] train=0.837039 val=0.893600 loss=0.462451 time: 8.031848
INFO:root:[Epoch 106] train=0.839103 val=0.892600 loss=0.460378 time: 8.105028
INFO:root:[Epoch 107] train=0.842228 val=0.896200 loss=0.457944 time: 8.137161
INFO:root:[Epoch 108] train=0.841326 val=0.895200 loss=0.455943 time: 8.005795
INFO:root:[Epoch 109] train=0.840625 val=0.896700 loss=0.457451 time: 8.020142
INFO:root:[Epoch 110] train=0.839603 val=0.894100 loss=0.454669 time: 8.058129
INFO:root:[Epoch 111] train=0.839002 val=0.895900 loss=0.460358 time: 8.067897
INFO:root:[Epoch 112] train=0.838742 val=0.897300 loss=0.462718 time: 7.999791
INFO:root:[Epoch 113] train=0.840004 val=0.892500 loss=0.456757 time: 7.948642
INFO:root:[Epoch 114] train=0.843309 val=0.897200 loss=0.452582 time: 8.131241
INFO:root:[Epoch 115] train=0.842989 val=0.893000 loss=0.449955 time: 8.090676
INFO:root:[Epoch 116] train=0.843790 val=0.899000 loss=0.449379 time: 8.117126
INFO:root:[Epoch 117] train=0.843630 val=0.894400 loss=0.447950 time: 8.047397
INFO:root:[Epoch 118] train=0.843970 val=0.899100 loss=0.446736 time: 8.090359
INFO:root:[Epoch 119] train=0.842268 val=0.894500 loss=0.453138 time: 7.962500
INFO:root:[Epoch 120] train=0.842648 val=0.899600 loss=0.450125 time: 8.058330
INFO:root:[Epoch 121] train=0.844050 val=0.895900 loss=0.444810 time: 8.169255
INFO:root:[Epoch 122] train=0.843369 val=0.896700 loss=0.449031 time: 8.125471
INFO:root:[Epoch 123] train=0.842428 val=0.897500 loss=0.450196 time: 8.110602
INFO:root:[Epoch 124] train=0.842147 val=0.896200 loss=0.448809 time: 8.022297
INFO:root:[Epoch 125] train=0.844351 val=0.895100 loss=0.444844 time: 8.102943
INFO:root:[Epoch 126] train=0.844932 val=0.900200 loss=0.445738 time: 8.020776
INFO:root:[Epoch 127] train=0.843009 val=0.895000 loss=0.452907 time: 8.035745
INFO:root:[Epoch 128] train=0.843470 val=0.893700 loss=0.443284 time: 8.130944
INFO:root:[Epoch 129] train=0.845753 val=0.893500 loss=0.442472 time: 8.194688
INFO:root:[Epoch 130] train=0.844812 val=0.896300 loss=0.439836 time: 8.025187
INFO:root:[Epoch 131] train=0.843830 val=0.897100 loss=0.445769 time: 8.015940
INFO:root:[Epoch 132] train=0.847616 val=0.896600 loss=0.437723 time: 8.007790
INFO:root:[Epoch 133] train=0.847516 val=0.896100 loss=0.441261 time: 8.072666
INFO:root:[Epoch 134] train=0.846434 val=0.897500 loss=0.439935 time: 7.993798
INFO:root:[Epoch 135] train=0.846534 val=0.897300 loss=0.435335 time: 8.050481
INFO:root:[Epoch 136] train=0.847216 val=0.897900 loss=0.437009 time: 8.083564
INFO:root:[Epoch 137] train=0.846655 val=0.898000 loss=0.439337 time: 8.037199
INFO:root:[Epoch 138] train=0.847055 val=0.894200 loss=0.437511 time: 8.195093
INFO:root:[Epoch 139] train=0.845613 val=0.896900 loss=0.438472 time: 8.127162
INFO:root:[Epoch 140] train=0.849079 val=0.895600 loss=0.438027 time: 8.224909
INFO:root:[Epoch 141] train=0.845933 val=0.896400 loss=0.439936 time: 8.112730
INFO:root:[Epoch 142] train=0.849179 val=0.894800 loss=0.432833 time: 8.104004
INFO:root:[Epoch 143] train=0.848458 val=0.896800 loss=0.436415 time: 8.030406
INFO:root:[Epoch 144] train=0.845573 val=0.896000 loss=0.439246 time: 8.262931
INFO:root:[Epoch 145] train=0.847296 val=0.895700 loss=0.437916 time: 8.253850
INFO:root:[Epoch 146] train=0.845733 val=0.897500 loss=0.440851 time: 8.270656
INFO:root:[Epoch 147] train=0.847416 val=0.895000 loss=0.437487 time: 8.262093
INFO:root:[Epoch 148] train=0.850200 val=0.898400 loss=0.432449 time: 8.203134
INFO:root:[Epoch 149] train=0.847937 val=0.895000 loss=0.436035 time: 8.260693
INFO:root:[Epoch 150] train=0.849299 val=0.895700 loss=0.433892 time: 8.278859
INFO:root:[Epoch 151] train=0.850341 val=0.891700 loss=0.431129 time: 8.203896
INFO:root:[Epoch 152] train=0.849219 val=0.892100 loss=0.434956 time: 8.284520
INFO:root:[Epoch 153] train=0.847496 val=0.895600 loss=0.438348 time: 8.306546
INFO:root:[Epoch 154] train=0.845653 val=0.895600 loss=0.440954 time: 8.362754
INFO:root:[Epoch 155] train=0.848738 val=0.895300 loss=0.434954 time: 8.338750
INFO:root:[Epoch 156] train=0.848077 val=0.896800 loss=0.436168 time: 8.236647
INFO:root:[Epoch 157] train=0.847075 val=0.895900 loss=0.438120 time: 8.195620
INFO:root:[Epoch 158] train=0.849519 val=0.897100 loss=0.432072 time: 8.272076
INFO:root:[Epoch 159] train=0.846815 val=0.896700 loss=0.435693 time: 8.226701
INFO:root:[Epoch 160] train=0.855689 val=0.903500 loss=0.416338 time: 8.309980
INFO:root:[Epoch 161] train=0.858433 val=0.905400 loss=0.410003 time: 8.305697
INFO:root:[Epoch 162] train=0.862119 val=0.905200 loss=0.399155 time: 8.186534
INFO:root:[Epoch 163] train=0.859095 val=0.905200 loss=0.409028 time: 8.281293
INFO:root:[Epoch 164] train=0.861799 val=0.905100 loss=0.399184 time: 8.272015
INFO:root:[Epoch 165] train=0.860517 val=0.904800 loss=0.398955 time: 8.271290
INFO:root:[Epoch 166] train=0.861178 val=0.905700 loss=0.402647 time: 8.254465
INFO:root:[Epoch 167] train=0.861959 val=0.903700 loss=0.394869 time: 8.350318
INFO:root:[Epoch 168] train=0.863341 val=0.904400 loss=0.394920 time: 8.487696
INFO:root:[Epoch 169] train=0.864042 val=0.903400 loss=0.390363 time: 8.295242
INFO:root:[Epoch 170] train=0.861278 val=0.904800 loss=0.396597 time: 8.204466
INFO:root:[Epoch 171] train=0.860517 val=0.903900 loss=0.399146 time: 8.249615
INFO:root:[Epoch 172] train=0.859635 val=0.904400 loss=0.401954 time: 8.274183
INFO:root:[Epoch 173] train=0.862981 val=0.904100 loss=0.392844 time: 8.309458
INFO:root:[Epoch 174] train=0.861318 val=0.904300 loss=0.396290 time: 8.293947
INFO:root:[Epoch 175] train=0.864483 val=0.904500 loss=0.397222 time: 8.256699
INFO:root:[Epoch 176] train=0.861158 val=0.906000 loss=0.399052 time: 8.462455
INFO:root:[Epoch 177] train=0.863862 val=0.903900 loss=0.390934 time: 8.335345
INFO:root:[Epoch 178] train=0.863141 val=0.903900 loss=0.396819 time: 8.370840
INFO:root:[Epoch 179] train=0.863962 val=0.906100 loss=0.393457 time: 8.374175
INFO:root:[Epoch 180] train=0.863401 val=0.905500 loss=0.389634 time: 8.380406
INFO:root:[Epoch 181] train=0.862760 val=0.907300 loss=0.391275 time: 8.334729
INFO:root:[Epoch 182] train=0.863061 val=0.906700 loss=0.393910 time: 8.295675
INFO:root:[Epoch 183] train=0.864583 val=0.907100 loss=0.389879 time: 8.396914
INFO:root:[Epoch 184] train=0.866146 val=0.907400 loss=0.387697 time: 8.521943
INFO:root:[Epoch 185] train=0.863301 val=0.905200 loss=0.394192 time: 8.281224
INFO:root:[Epoch 186] train=0.864563 val=0.903800 loss=0.392615 time: 8.296189
INFO:root:[Epoch 187] train=0.864784 val=0.905900 loss=0.389787 time: 8.529707
INFO:root:[Epoch 188] train=0.865825 val=0.905200 loss=0.386438 time: 8.370022
INFO:root:[Epoch 189] train=0.864784 val=0.906100 loss=0.391297 time: 8.277340
INFO:root:[Epoch 190] train=0.866607 val=0.904800 loss=0.386847 time: 8.345284
INFO:root:[Epoch 191] train=0.863381 val=0.907200 loss=0.390454 time: 8.270835
INFO:root:[Epoch 192] train=0.863782 val=0.906800 loss=0.392800 time: 8.263334
INFO:root:[Epoch 193] train=0.864062 val=0.905300 loss=0.389474 time: 8.446479
INFO:root:[Epoch 194] train=0.864403 val=0.906000 loss=0.390121 time: 8.313019
INFO:root:[Epoch 195] train=0.866426 val=0.906000 loss=0.381932 time: 8.444299
INFO:root:[Epoch 196] train=0.866386 val=0.906600 loss=0.383519 time: 8.303333
INFO:root:[Epoch 197] train=0.864123 val=0.906200 loss=0.388814 time: 8.339522
INFO:root:[Epoch 198] train=0.865264 val=0.907400 loss=0.385918 time: 8.332425
INFO:root:[Epoch 199] train=0.865224 val=0.905500 loss=0.385860 time: 8.297409
INFO:root:[Epoch 200] train=0.862240 val=0.905600 loss=0.390933 time: 8.358518
INFO:root:[Epoch 201] train=0.865244 val=0.906300 loss=0.387856 time: 8.364652
INFO:root:[Epoch 202] train=0.864523 val=0.907300 loss=0.387361 time: 8.472373
INFO:root:[Epoch 203] train=0.863001 val=0.905600 loss=0.392161 time: 8.259631
INFO:root:[Epoch 204] train=0.865545 val=0.907300 loss=0.387129 time: 8.312528
INFO:root:[Epoch 205] train=0.863522 val=0.907900 loss=0.391134 time: 8.302348
INFO:root:[Epoch 206] train=0.864083 val=0.908200 loss=0.390361 time: 8.213894
INFO:root:[Epoch 207] train=0.864663 val=0.904300 loss=0.388354 time: 8.300201
INFO:root:[Epoch 208] train=0.864443 val=0.906000 loss=0.384979 time: 8.311546
INFO:root:[Epoch 209] train=0.865665 val=0.905400 loss=0.384667 time: 8.575686
INFO:root:[Epoch 210] train=0.864123 val=0.906800 loss=0.391121 time: 8.562121
INFO:root:[Epoch 211] train=0.863542 val=0.906200 loss=0.388044 time: 8.403291
INFO:root:[Epoch 212] train=0.865244 val=0.908000 loss=0.387064 time: 8.489354
INFO:root:[Epoch 213] train=0.868189 val=0.905800 loss=0.383174 time: 8.552567
INFO:root:[Epoch 214] train=0.865645 val=0.908200 loss=0.386004 time: 8.632209
INFO:root:[Epoch 215] train=0.865705 val=0.907700 loss=0.383017 time: 8.541097
INFO:root:[Epoch 216] train=0.865264 val=0.906800 loss=0.389978 time: 8.545701
INFO:root:[Epoch 217] train=0.865004 val=0.905500 loss=0.386808 time: 8.485343
INFO:root:[Epoch 218] train=0.864503 val=0.906800 loss=0.385204 time: 8.429551
INFO:root:[Epoch 219] train=0.865705 val=0.906000 loss=0.383686 time: 8.536059
INFO:root:[Epoch 220] train=0.865685 val=0.907200 loss=0.384571 time: 8.512394
INFO:root:[Epoch 221] train=0.866186 val=0.907500 loss=0.387131 time: 8.606600
INFO:root:[Epoch 222] train=0.866446 val=0.906800 loss=0.382446 time: 8.599695
INFO:root:[Epoch 223] train=0.863982 val=0.906700 loss=0.386277 time: 8.584516
INFO:root:[Epoch 224] train=0.865986 val=0.905700 loss=0.383134 time: 8.671984
INFO:root:[Epoch 225] train=0.866546 val=0.905700 loss=0.385107 time: 8.589125
INFO:root:[Epoch 226] train=0.865325 val=0.907100 loss=0.388661 time: 8.672942
INFO:root:[Epoch 227] train=0.863562 val=0.905600 loss=0.391156 time: 8.624688
INFO:root:[Epoch 228] train=0.866186 val=0.905500 loss=0.387483 time: 8.521706
INFO:root:[Epoch 229] train=0.866466 val=0.905000 loss=0.384645 time: 8.574468
INFO:root:[Epoch 230] train=0.867027 val=0.906200 loss=0.386853 time: 8.601385
INFO:root:[Epoch 231] train=0.866847 val=0.907600 loss=0.381490 time: 8.563987
INFO:root:[Epoch 232] train=0.867448 val=0.907600 loss=0.377511 time: 8.536279
INFO:root:[Epoch 233] train=0.865825 val=0.907900 loss=0.380910 time: 8.660149
INFO:root:[Epoch 234] train=0.863482 val=0.907000 loss=0.386308 time: 8.633993
INFO:root:[Epoch 235] train=0.866567 val=0.905100 loss=0.383859 time: 8.738143
INFO:root:[Epoch 236] train=0.864704 val=0.906600 loss=0.386472 time: 8.468642
INFO:root:[Epoch 237] train=0.867688 val=0.907000 loss=0.380141 time: 8.622669
INFO:root:[Epoch 238] train=0.868490 val=0.906300 loss=0.379433 time: 8.642154
INFO:root:[Epoch 239] train=0.866426 val=0.906000 loss=0.381559 time: 8.607116
