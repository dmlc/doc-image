INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.1, lr_decay_epoch='80,160', lr_decay_period=0, mode='hybrid', model='cifar_resnet110_v2', momentum=0.9, num_epochs=240, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0001)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[10:27:57] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.340565 val=0.425700 loss=1.771704 time: 34.908937
INFO:root:[Epoch 1] train=0.474499 val=0.498300 loss=1.450700 time: 34.006616
INFO:root:[Epoch 2] train=0.538121 val=0.518900 loss=1.288918 time: 33.664733
INFO:root:[Epoch 3] train=0.578245 val=0.613400 loss=1.187196 time: 33.833852
INFO:root:[Epoch 4] train=0.610056 val=0.700900 loss=1.100587 time: 33.738069
INFO:root:[Epoch 5] train=0.636398 val=0.671900 loss=1.035816 time: 33.861423
INFO:root:[Epoch 6] train=0.655148 val=0.734800 loss=0.981554 time: 33.443159
INFO:root:[Epoch 7] train=0.670393 val=0.760600 loss=0.940147 time: 33.778775
INFO:root:[Epoch 8] train=0.683293 val=0.706200 loss=0.903866 time: 33.609897
INFO:root:[Epoch 9] train=0.695853 val=0.729800 loss=0.875857 time: 33.535890
INFO:root:[Epoch 10] train=0.699359 val=0.763800 loss=0.858788 time: 34.010781
INFO:root:[Epoch 11] train=0.707412 val=0.749200 loss=0.836873 time: 33.450650
INFO:root:[Epoch 12] train=0.716567 val=0.777700 loss=0.807613 time: 33.707268
INFO:root:[Epoch 13] train=0.722837 val=0.813600 loss=0.794969 time: 33.422977
INFO:root:[Epoch 14] train=0.723638 val=0.806100 loss=0.786962 time: 33.680559
INFO:root:[Epoch 15] train=0.730689 val=0.803300 loss=0.770178 time: 33.579843
INFO:root:[Epoch 16] train=0.739163 val=0.802100 loss=0.749780 time: 33.531598
INFO:root:[Epoch 17] train=0.741787 val=0.808900 loss=0.745552 time: 33.524692
INFO:root:[Epoch 18] train=0.747015 val=0.825400 loss=0.730527 time: 33.429057
INFO:root:[Epoch 19] train=0.747796 val=0.809000 loss=0.725338 time: 33.779593
INFO:root:[Epoch 20] train=0.748938 val=0.819900 loss=0.719419 time: 33.511829
INFO:root:[Epoch 21] train=0.753826 val=0.835500 loss=0.710098 time: 33.750583
INFO:root:[Epoch 22] train=0.755789 val=0.840800 loss=0.698911 time: 33.489311
INFO:root:[Epoch 23] train=0.760437 val=0.835700 loss=0.689244 time: 33.840162
INFO:root:[Epoch 24] train=0.760096 val=0.830800 loss=0.693431 time: 33.448575
INFO:root:[Epoch 25] train=0.760337 val=0.832700 loss=0.681816 time: 33.590252
INFO:root:[Epoch 26] train=0.766186 val=0.838400 loss=0.674731 time: 33.940480
INFO:root:[Epoch 27] train=0.765685 val=0.827000 loss=0.668364 time: 33.479056
INFO:root:[Epoch 28] train=0.765425 val=0.824100 loss=0.668109 time: 33.815533
INFO:root:[Epoch 29] train=0.769191 val=0.831600 loss=0.667636 time: 33.946616
INFO:root:[Epoch 30] train=0.769511 val=0.847900 loss=0.659400 time: 33.889351
INFO:root:[Epoch 31] train=0.773277 val=0.844100 loss=0.648587 time: 33.561012
INFO:root:[Epoch 32] train=0.772336 val=0.842200 loss=0.653116 time: 33.931379
INFO:root:[Epoch 33] train=0.774659 val=0.850100 loss=0.649805 time: 33.569509
INFO:root:[Epoch 34] train=0.779167 val=0.852000 loss=0.638172 time: 33.542478
INFO:root:[Epoch 35] train=0.777704 val=0.818200 loss=0.640946 time: 33.551215
INFO:root:[Epoch 36] train=0.778986 val=0.851600 loss=0.633453 time: 33.590057
INFO:root:[Epoch 37] train=0.781270 val=0.850800 loss=0.627712 time: 33.990720
INFO:root:[Epoch 38] train=0.778926 val=0.844600 loss=0.631350 time: 33.735889
INFO:root:[Epoch 39] train=0.781150 val=0.842000 loss=0.630124 time: 33.856100
INFO:root:[Epoch 40] train=0.783033 val=0.857900 loss=0.620819 time: 34.465803
INFO:root:[Epoch 41] train=0.782612 val=0.851800 loss=0.625437 time: 34.855632
INFO:root:[Epoch 42] train=0.779487 val=0.838500 loss=0.624683 time: 34.828079
INFO:root:[Epoch 43] train=0.785777 val=0.860200 loss=0.612684 time: 34.823337
INFO:root:[Epoch 44] train=0.786999 val=0.835500 loss=0.612344 time: 34.931784
INFO:root:[Epoch 45] train=0.787240 val=0.847300 loss=0.612187 time: 34.885548
INFO:root:[Epoch 46] train=0.787861 val=0.848900 loss=0.606357 time: 34.946925
INFO:root:[Epoch 47] train=0.789022 val=0.863500 loss=0.605539 time: 34.730177
INFO:root:[Epoch 48] train=0.789984 val=0.857800 loss=0.607890 time: 34.914740
INFO:root:[Epoch 49] train=0.791967 val=0.864800 loss=0.598274 time: 34.865366
INFO:root:[Epoch 50] train=0.790925 val=0.820500 loss=0.605220 time: 35.032486
INFO:root:[Epoch 51] train=0.790485 val=0.844000 loss=0.603210 time: 34.780731
INFO:root:[Epoch 52] train=0.789924 val=0.858700 loss=0.603529 time: 34.823152
INFO:root:[Epoch 53] train=0.790505 val=0.850500 loss=0.600980 time: 34.957391
INFO:root:[Epoch 54] train=0.791787 val=0.859800 loss=0.595821 time: 35.029827
INFO:root:[Epoch 55] train=0.793890 val=0.849300 loss=0.592163 time: 34.947410
INFO:root:[Epoch 56] train=0.794191 val=0.867300 loss=0.589543 time: 34.876483
INFO:root:[Epoch 57] train=0.795513 val=0.848200 loss=0.584488 time: 35.141965
INFO:root:[Epoch 58] train=0.798718 val=0.866700 loss=0.579566 time: 34.898827
INFO:root:[Epoch 59] train=0.794491 val=0.858400 loss=0.589584 time: 34.895289
INFO:root:[Epoch 60] train=0.795913 val=0.867700 loss=0.581365 time: 34.825150
INFO:root:[Epoch 61] train=0.799219 val=0.851300 loss=0.581096 time: 34.819377
INFO:root:[Epoch 62] train=0.796494 val=0.856900 loss=0.583167 time: 34.759133
INFO:root:[Epoch 63] train=0.796615 val=0.863800 loss=0.585635 time: 35.089259
INFO:root:[Epoch 64] train=0.799639 val=0.863100 loss=0.578223 time: 35.040315
INFO:root:[Epoch 65] train=0.799259 val=0.851200 loss=0.575078 time: 34.949832
INFO:root:[Epoch 66] train=0.798938 val=0.871500 loss=0.577907 time: 35.021365
INFO:root:[Epoch 67] train=0.796174 val=0.841600 loss=0.581295 time: 34.872049
INFO:root:[Epoch 68] train=0.803906 val=0.853800 loss=0.565269 time: 35.008341
INFO:root:[Epoch 69] train=0.797496 val=0.865200 loss=0.580894 time: 34.961242
INFO:root:[Epoch 70] train=0.802424 val=0.865300 loss=0.570150 time: 35.027555
INFO:root:[Epoch 71] train=0.800341 val=0.855100 loss=0.570275 time: 34.938716
INFO:root:[Epoch 72] train=0.802424 val=0.860500 loss=0.568416 time: 34.911006
INFO:root:[Epoch 73] train=0.801603 val=0.867100 loss=0.571570 time: 34.945817
INFO:root:[Epoch 74] train=0.802043 val=0.856400 loss=0.568020 time: 34.940758
INFO:root:[Epoch 75] train=0.802204 val=0.875700 loss=0.569755 time: 34.852641
INFO:root:[Epoch 76] train=0.803466 val=0.868400 loss=0.566443 time: 34.857324
INFO:root:[Epoch 77] train=0.800641 val=0.873400 loss=0.569872 time: 34.936035
INFO:root:[Epoch 78] train=0.807232 val=0.858600 loss=0.550997 time: 34.887955
INFO:root:[Epoch 79] train=0.801783 val=0.870200 loss=0.567100 time: 34.830565
INFO:root:[Epoch 80] train=0.835236 val=0.911900 loss=0.479830 time: 35.030565
INFO:root:[Epoch 81] train=0.857011 val=0.916000 loss=0.414478 time: 34.994081
INFO:root:[Epoch 82] train=0.861238 val=0.917100 loss=0.402685 time: 34.923033
INFO:root:[Epoch 83] train=0.865705 val=0.923400 loss=0.391231 time: 34.592640
INFO:root:[Epoch 84] train=0.866567 val=0.922000 loss=0.383883 time: 35.003830
INFO:root:[Epoch 85] train=0.866226 val=0.920700 loss=0.383971 time: 34.901230
INFO:root:[Epoch 86] train=0.867829 val=0.921000 loss=0.378154 time: 35.087392
INFO:root:[Epoch 87] train=0.870753 val=0.922000 loss=0.370312 time: 34.515844
INFO:root:[Epoch 88] train=0.870152 val=0.923100 loss=0.371673 time: 34.466759
INFO:root:[Epoch 89] train=0.874639 val=0.921500 loss=0.363988 time: 34.437295
INFO:root:[Epoch 90] train=0.874780 val=0.924300 loss=0.360694 time: 34.411677
INFO:root:[Epoch 91] train=0.876923 val=0.926500 loss=0.355126 time: 34.416052
INFO:root:[Epoch 92] train=0.876683 val=0.926200 loss=0.355861 time: 34.473379
INFO:root:[Epoch 93] train=0.876623 val=0.925000 loss=0.351310 time: 34.583024
INFO:root:[Epoch 94] train=0.878826 val=0.923300 loss=0.348997 time: 34.303984
INFO:root:[Epoch 95] train=0.876983 val=0.924000 loss=0.350473 time: 34.565269
INFO:root:[Epoch 96] train=0.877925 val=0.922800 loss=0.351145 time: 34.497411
INFO:root:[Epoch 97] train=0.877564 val=0.924700 loss=0.350404 time: 34.408053
INFO:root:[Epoch 98] train=0.883173 val=0.923800 loss=0.341592 time: 34.277750
INFO:root:[Epoch 99] train=0.881530 val=0.926900 loss=0.341230 time: 34.306785
INFO:root:[Epoch 100] train=0.879287 val=0.924000 loss=0.344814 time: 34.477473
INFO:root:[Epoch 101] train=0.881370 val=0.923600 loss=0.339908 time: 34.582100
INFO:root:[Epoch 102] train=0.884034 val=0.925700 loss=0.335026 time: 34.540486
INFO:root:[Epoch 103] train=0.884075 val=0.924200 loss=0.331710 time: 34.487736
INFO:root:[Epoch 104] train=0.883333 val=0.924600 loss=0.336197 time: 34.653696
INFO:root:[Epoch 105] train=0.882752 val=0.927400 loss=0.336736 time: 34.388694
INFO:root:[Epoch 106] train=0.883814 val=0.926600 loss=0.333121 time: 34.559158
INFO:root:[Epoch 107] train=0.883674 val=0.926900 loss=0.336206 time: 34.472808
INFO:root:[Epoch 108] train=0.884876 val=0.924500 loss=0.328659 time: 34.576656
INFO:root:[Epoch 109] train=0.884475 val=0.926000 loss=0.330478 time: 34.550789
INFO:root:[Epoch 110] train=0.884555 val=0.926100 loss=0.330475 time: 34.493784
INFO:root:[Epoch 111] train=0.886659 val=0.924700 loss=0.328694 time: 34.470574
INFO:root:[Epoch 112] train=0.887700 val=0.925700 loss=0.324250 time: 34.462719
INFO:root:[Epoch 113] train=0.885777 val=0.926700 loss=0.329127 time: 34.676025
INFO:root:[Epoch 114] train=0.886138 val=0.924800 loss=0.321291 time: 34.399135
INFO:root:[Epoch 115] train=0.889243 val=0.926300 loss=0.320557 time: 34.597986
INFO:root:[Epoch 116] train=0.887019 val=0.929600 loss=0.324340 time: 34.467881
INFO:root:[Epoch 117] train=0.886639 val=0.923500 loss=0.325551 time: 34.735390
INFO:root:[Epoch 118] train=0.889123 val=0.926100 loss=0.318853 time: 34.531334
INFO:root:[Epoch 119] train=0.889683 val=0.926200 loss=0.318550 time: 34.362776
INFO:root:[Epoch 120] train=0.890425 val=0.928000 loss=0.313798 time: 34.468041
INFO:root:[Epoch 121] train=0.888622 val=0.925600 loss=0.320924 time: 34.535823
INFO:root:[Epoch 122] train=0.890084 val=0.923900 loss=0.313592 time: 34.723757
INFO:root:[Epoch 123] train=0.891747 val=0.923600 loss=0.310077 time: 34.470987
INFO:root:[Epoch 124] train=0.887540 val=0.925200 loss=0.318171 time: 34.740903
INFO:root:[Epoch 125] train=0.892007 val=0.925600 loss=0.312729 time: 34.566696
INFO:root:[Epoch 126] train=0.891687 val=0.927400 loss=0.313461 time: 34.605486
INFO:root:[Epoch 127] train=0.890084 val=0.928000 loss=0.317062 time: 34.720462
INFO:root:[Epoch 128] train=0.888201 val=0.927400 loss=0.318928 time: 34.610762
INFO:root:[Epoch 129] train=0.894231 val=0.925400 loss=0.308480 time: 34.500413
INFO:root:[Epoch 130] train=0.892668 val=0.920600 loss=0.309667 time: 34.637450
INFO:root:[Epoch 131] train=0.891286 val=0.924300 loss=0.311618 time: 34.543011
INFO:root:[Epoch 132] train=0.890785 val=0.926300 loss=0.311437 time: 34.261976
INFO:root:[Epoch 133] train=0.892969 val=0.924100 loss=0.305533 time: 33.886748
INFO:root:[Epoch 134] train=0.891967 val=0.929900 loss=0.307169 time: 33.739957
INFO:root:[Epoch 135] train=0.890925 val=0.924600 loss=0.309863 time: 33.747294
INFO:root:[Epoch 136] train=0.892188 val=0.916300 loss=0.310407 time: 33.751618
INFO:root:[Epoch 137] train=0.890625 val=0.926100 loss=0.312198 time: 33.986972
INFO:root:[Epoch 138] train=0.893329 val=0.928500 loss=0.308239 time: 33.452724
INFO:root:[Epoch 139] train=0.893550 val=0.925500 loss=0.308608 time: 33.878191
INFO:root:[Epoch 140] train=0.893149 val=0.926100 loss=0.306770 time: 33.763675
INFO:root:[Epoch 141] train=0.892588 val=0.926100 loss=0.307632 time: 33.659910
INFO:root:[Epoch 142] train=0.892949 val=0.924200 loss=0.307682 time: 33.917105
INFO:root:[Epoch 143] train=0.894671 val=0.925800 loss=0.303131 time: 33.646071
INFO:root:[Epoch 144] train=0.892688 val=0.926300 loss=0.307806 time: 33.566751
INFO:root:[Epoch 145] train=0.893510 val=0.924800 loss=0.309184 time: 34.117910
INFO:root:[Epoch 146] train=0.894972 val=0.923200 loss=0.301516 time: 34.040504
INFO:root:[Epoch 147] train=0.895893 val=0.925200 loss=0.301964 time: 33.790695
INFO:root:[Epoch 148] train=0.892788 val=0.928500 loss=0.309156 time: 33.685205
INFO:root:[Epoch 149] train=0.894050 val=0.926000 loss=0.305478 time: 33.850985
INFO:root:[Epoch 150] train=0.893710 val=0.925300 loss=0.304653 time: 33.742836
INFO:root:[Epoch 151] train=0.895974 val=0.919200 loss=0.299983 time: 33.843165
INFO:root:[Epoch 152] train=0.896815 val=0.920900 loss=0.297551 time: 33.752691
INFO:root:[Epoch 153] train=0.892628 val=0.925000 loss=0.305657 time: 33.561262
INFO:root:[Epoch 154] train=0.894992 val=0.925300 loss=0.302088 time: 33.533846
INFO:root:[Epoch 155] train=0.896875 val=0.924100 loss=0.300454 time: 34.173888
INFO:root:[Epoch 156] train=0.894030 val=0.924800 loss=0.304275 time: 33.938366
INFO:root:[Epoch 157] train=0.895252 val=0.922800 loss=0.298537 time: 33.706838
INFO:root:[Epoch 158] train=0.893950 val=0.925900 loss=0.301719 time: 33.973248
INFO:root:[Epoch 159] train=0.895813 val=0.924100 loss=0.299481 time: 33.671419
INFO:root:[Epoch 160] train=0.900601 val=0.931700 loss=0.287992 time: 33.964355
INFO:root:[Epoch 161] train=0.907412 val=0.933300 loss=0.267320 time: 33.739994
INFO:root:[Epoch 162] train=0.907111 val=0.933800 loss=0.267815 time: 33.740411
INFO:root:[Epoch 163] train=0.909395 val=0.934700 loss=0.262783 time: 33.951515
INFO:root:[Epoch 164] train=0.909615 val=0.934100 loss=0.262053 time: 33.593035
INFO:root:[Epoch 165] train=0.908574 val=0.934300 loss=0.264964 time: 34.015510
INFO:root:[Epoch 166] train=0.910737 val=0.935200 loss=0.257668 time: 33.661818
INFO:root:[Epoch 167] train=0.911639 val=0.934200 loss=0.259872 time: 33.891547
INFO:root:[Epoch 168] train=0.912921 val=0.934500 loss=0.256670 time: 33.793088
INFO:root:[Epoch 169] train=0.908994 val=0.934400 loss=0.261248 time: 33.990830
INFO:root:[Epoch 170] train=0.912179 val=0.934700 loss=0.255106 time: 33.821216
INFO:root:[Epoch 171] train=0.909736 val=0.934500 loss=0.257059 time: 34.031143
INFO:root:[Epoch 172] train=0.912861 val=0.934100 loss=0.254140 time: 33.966801
INFO:root:[Epoch 173] train=0.912139 val=0.934500 loss=0.254159 time: 33.841982
INFO:root:[Epoch 174] train=0.912861 val=0.935200 loss=0.252823 time: 33.930122
INFO:root:[Epoch 175] train=0.912800 val=0.935300 loss=0.251546 time: 34.103915
INFO:root:[Epoch 176] train=0.912600 val=0.933800 loss=0.252900 time: 34.125942
INFO:root:[Epoch 177] train=0.913081 val=0.932900 loss=0.249574 time: 33.735720
INFO:root:[Epoch 178] train=0.913121 val=0.934800 loss=0.251216 time: 33.852762
INFO:root:[Epoch 179] train=0.914884 val=0.935200 loss=0.248128 time: 33.794734
INFO:root:[Epoch 180] train=0.912861 val=0.933400 loss=0.253879 time: 34.171430
INFO:root:[Epoch 181] train=0.911538 val=0.934700 loss=0.254779 time: 33.907340
INFO:root:[Epoch 182] train=0.914804 val=0.933200 loss=0.248979 time: 33.836640
INFO:root:[Epoch 183] train=0.914944 val=0.934500 loss=0.248462 time: 33.817888
INFO:root:[Epoch 184] train=0.915345 val=0.934700 loss=0.247587 time: 33.662582
INFO:root:[Epoch 185] train=0.913982 val=0.933600 loss=0.246044 time: 34.138682
INFO:root:[Epoch 186] train=0.912079 val=0.934100 loss=0.255845 time: 33.838426
INFO:root:[Epoch 187] train=0.915244 val=0.934000 loss=0.242628 time: 33.772350
INFO:root:[Epoch 188] train=0.913822 val=0.933100 loss=0.249994 time: 33.909817
INFO:root:[Epoch 189] train=0.911739 val=0.933300 loss=0.251308 time: 33.767738
INFO:root:[Epoch 190] train=0.913962 val=0.934600 loss=0.249482 time: 34.314935
INFO:root:[Epoch 191] train=0.914744 val=0.934000 loss=0.249027 time: 33.871849
INFO:root:[Epoch 192] train=0.915665 val=0.934800 loss=0.242639 time: 34.024697
INFO:root:[Epoch 193] train=0.915264 val=0.934400 loss=0.245471 time: 33.916493
INFO:root:[Epoch 194] train=0.914403 val=0.933700 loss=0.246627 time: 33.983801
INFO:root:[Epoch 195] train=0.915545 val=0.933600 loss=0.246047 time: 33.853697
INFO:root:[Epoch 196] train=0.917027 val=0.936600 loss=0.244456 time: 33.897910
INFO:root:[Epoch 197] train=0.915885 val=0.934900 loss=0.246146 time: 34.012515
INFO:root:[Epoch 198] train=0.916466 val=0.933400 loss=0.241862 time: 33.786346
INFO:root:[Epoch 199] train=0.916727 val=0.933500 loss=0.244411 time: 33.885850
INFO:root:[Epoch 200] train=0.917188 val=0.933100 loss=0.241592 time: 33.868997
INFO:root:[Epoch 201] train=0.919331 val=0.934800 loss=0.235589 time: 34.101380
INFO:root:[Epoch 202] train=0.916526 val=0.933000 loss=0.239999 time: 33.898944
INFO:root:[Epoch 203] train=0.916446 val=0.934500 loss=0.240863 time: 33.913343
INFO:root:[Epoch 204] train=0.917127 val=0.933700 loss=0.239486 time: 33.734531
INFO:root:[Epoch 205] train=0.917308 val=0.935000 loss=0.240061 time: 33.887957
INFO:root:[Epoch 206] train=0.918590 val=0.934600 loss=0.238153 time: 33.945628
INFO:root:[Epoch 207] train=0.916787 val=0.934700 loss=0.243979 time: 33.918089
INFO:root:[Epoch 208] train=0.917428 val=0.935300 loss=0.241009 time: 34.323706
INFO:root:[Epoch 209] train=0.916266 val=0.935500 loss=0.243171 time: 33.794432
INFO:root:[Epoch 210] train=0.916346 val=0.935200 loss=0.241640 time: 34.036930
INFO:root:[Epoch 211] train=0.917508 val=0.935100 loss=0.240035 time: 34.087434
INFO:root:[Epoch 212] train=0.917909 val=0.934400 loss=0.235724 time: 33.754141
INFO:root:[Epoch 213] train=0.917788 val=0.934700 loss=0.241596 time: 33.906590
INFO:root:[Epoch 214] train=0.916787 val=0.934300 loss=0.242372 time: 33.838720
INFO:root:[Epoch 215] train=0.916166 val=0.935200 loss=0.241315 time: 34.016700
INFO:root:[Epoch 216] train=0.919511 val=0.932700 loss=0.234900 time: 33.759461
INFO:root:[Epoch 217] train=0.917608 val=0.933800 loss=0.240866 time: 34.088241
INFO:root:[Epoch 218] train=0.916326 val=0.933300 loss=0.240699 time: 34.002894
INFO:root:[Epoch 219] train=0.916747 val=0.934100 loss=0.241969 time: 34.196356
INFO:root:[Epoch 220] train=0.919050 val=0.935100 loss=0.236882 time: 33.880681
INFO:root:[Epoch 221] train=0.919291 val=0.934500 loss=0.235155 time: 33.765985
INFO:root:[Epoch 222] train=0.917909 val=0.934900 loss=0.241232 time: 33.985220
INFO:root:[Epoch 223] train=0.918550 val=0.935500 loss=0.236321 time: 33.880808
INFO:root:[Epoch 224] train=0.916707 val=0.937300 loss=0.239101 time: 34.101978
INFO:root:[Epoch 225] train=0.917588 val=0.935100 loss=0.237743 time: 33.932220
INFO:root:[Epoch 226] train=0.918630 val=0.936200 loss=0.234382 time: 34.000473
INFO:root:[Epoch 227] train=0.917648 val=0.935300 loss=0.238927 time: 34.235052
INFO:root:[Epoch 228] train=0.916967 val=0.936600 loss=0.238721 time: 34.333904
INFO:root:[Epoch 229] train=0.916667 val=0.936000 loss=0.240019 time: 33.835193
INFO:root:[Epoch 230] train=0.916006 val=0.936300 loss=0.238619 time: 33.793958
INFO:root:[Epoch 231] train=0.918830 val=0.935100 loss=0.236270 time: 33.961850
INFO:root:[Epoch 232] train=0.918790 val=0.934900 loss=0.237359 time: 33.915000
INFO:root:[Epoch 233] train=0.919091 val=0.937200 loss=0.234448 time: 34.097869
INFO:root:[Epoch 234] train=0.920573 val=0.936200 loss=0.232386 time: 33.959895
INFO:root:[Epoch 235] train=0.920753 val=0.934800 loss=0.230845 time: 34.319845
INFO:root:[Epoch 236] train=0.918690 val=0.935400 loss=0.234480 time: 33.880740
INFO:root:[Epoch 237] train=0.918790 val=0.934000 loss=0.235306 time: 34.024923
INFO:root:[Epoch 238] train=0.919351 val=0.934300 loss=0.235901 time: 33.908291
INFO:root:[Epoch 239] train=0.918790 val=0.934700 loss=0.233255 time: 34.095759
