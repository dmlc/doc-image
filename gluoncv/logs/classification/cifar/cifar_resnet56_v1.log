INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.1, lr_decay_epoch='80,160', lr_decay_period=0, mode='hybrid', model='cifar_resnet56_v1', momentum=0.9, num_epochs=240, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0001)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[05:05:57] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.128145 val=0.220800 loss=2.339506 time: 19.877571
INFO:root:[Epoch 1] train=0.272055 val=0.352500 loss=1.922794 time: 19.161546
INFO:root:[Epoch 2] train=0.349279 val=0.414100 loss=1.753709 time: 18.954729
INFO:root:[Epoch 3] train=0.400982 val=0.468600 loss=1.640816 time: 19.107941
INFO:root:[Epoch 4] train=0.446595 val=0.499100 loss=1.524479 time: 19.100084
INFO:root:[Epoch 5] train=0.485236 val=0.565100 loss=1.422987 time: 19.092655
INFO:root:[Epoch 6] train=0.525381 val=0.604200 loss=1.325016 time: 19.094551
INFO:root:[Epoch 7] train=0.556631 val=0.612400 loss=1.251907 time: 19.134227
INFO:root:[Epoch 8] train=0.583714 val=0.665800 loss=1.173482 time: 19.124043
INFO:root:[Epoch 9] train=0.605529 val=0.657700 loss=1.122502 time: 19.060608
INFO:root:[Epoch 10] train=0.627404 val=0.659900 loss=1.056989 time: 19.228550
INFO:root:[Epoch 11] train=0.642708 val=0.694100 loss=1.013453 time: 18.993813
INFO:root:[Epoch 12] train=0.654667 val=0.737000 loss=0.983575 time: 19.224825
INFO:root:[Epoch 13] train=0.666887 val=0.733500 loss=0.957043 time: 19.010138
INFO:root:[Epoch 14] train=0.672536 val=0.742500 loss=0.930452 time: 19.107706
INFO:root:[Epoch 15] train=0.684135 val=0.761300 loss=0.904507 time: 19.167572
INFO:root:[Epoch 16] train=0.688321 val=0.774300 loss=0.888299 time: 19.161426
INFO:root:[Epoch 17] train=0.698798 val=0.769500 loss=0.865008 time: 19.058731
INFO:root:[Epoch 18] train=0.702083 val=0.729900 loss=0.852540 time: 19.151216
INFO:root:[Epoch 19] train=0.705369 val=0.763000 loss=0.840102 time: 18.934355
INFO:root:[Epoch 20] train=0.713702 val=0.760600 loss=0.820360 time: 19.187911
INFO:root:[Epoch 21] train=0.714203 val=0.781900 loss=0.815424 time: 19.100897
INFO:root:[Epoch 22] train=0.724018 val=0.801800 loss=0.789801 time: 19.067067
INFO:root:[Epoch 23] train=0.729187 val=0.800600 loss=0.784290 time: 19.192482
INFO:root:[Epoch 24] train=0.726482 val=0.798100 loss=0.783837 time: 19.170161
INFO:root:[Epoch 25] train=0.730228 val=0.801000 loss=0.770936 time: 19.256763
INFO:root:[Epoch 26] train=0.732993 val=0.782200 loss=0.762477 time: 19.060203
INFO:root:[Epoch 27] train=0.736278 val=0.818000 loss=0.751970 time: 19.191650
INFO:root:[Epoch 28] train=0.741466 val=0.821400 loss=0.744290 time: 19.000392
INFO:root:[Epoch 29] train=0.744351 val=0.824700 loss=0.734509 time: 19.077416
INFO:root:[Epoch 30] train=0.745873 val=0.832100 loss=0.728506 time: 19.003131
INFO:root:[Epoch 31] train=0.745853 val=0.827000 loss=0.724707 time: 19.192249
INFO:root:[Epoch 32] train=0.753185 val=0.798700 loss=0.712867 time: 19.023998
INFO:root:[Epoch 33] train=0.750381 val=0.817200 loss=0.717915 time: 19.130022
INFO:root:[Epoch 34] train=0.757212 val=0.837500 loss=0.697223 time: 19.049244
INFO:root:[Epoch 35] train=0.758273 val=0.806000 loss=0.694974 time: 19.171173
INFO:root:[Epoch 36] train=0.758293 val=0.815200 loss=0.695113 time: 19.104887
INFO:root:[Epoch 37] train=0.758954 val=0.806800 loss=0.689074 time: 19.132113
INFO:root:[Epoch 38] train=0.760877 val=0.831700 loss=0.686025 time: 18.988292
INFO:root:[Epoch 39] train=0.762981 val=0.832500 loss=0.681062 time: 19.306791
INFO:root:[Epoch 40] train=0.763722 val=0.833300 loss=0.679803 time: 19.082249
INFO:root:[Epoch 41] train=0.766947 val=0.828800 loss=0.667708 time: 19.086945
INFO:root:[Epoch 42] train=0.767167 val=0.826000 loss=0.666144 time: 19.166824
INFO:root:[Epoch 43] train=0.769071 val=0.802800 loss=0.660464 time: 19.202544
INFO:root:[Epoch 44] train=0.770032 val=0.845200 loss=0.658215 time: 19.207034
INFO:root:[Epoch 45] train=0.772155 val=0.834500 loss=0.652026 time: 19.115579
INFO:root:[Epoch 46] train=0.772015 val=0.839600 loss=0.659638 time: 19.152904
INFO:root:[Epoch 47] train=0.774319 val=0.854400 loss=0.655268 time: 19.068694
INFO:root:[Epoch 48] train=0.770753 val=0.836000 loss=0.649015 time: 19.026707
INFO:root:[Epoch 49] train=0.776322 val=0.857500 loss=0.643527 time: 19.083500
INFO:root:[Epoch 50] train=0.775180 val=0.835500 loss=0.645839 time: 19.203898
INFO:root:[Epoch 51] train=0.777704 val=0.843300 loss=0.638755 time: 19.218656
INFO:root:[Epoch 52] train=0.776002 val=0.851600 loss=0.644438 time: 19.194978
INFO:root:[Epoch 53] train=0.777103 val=0.837800 loss=0.636904 time: 19.349099
INFO:root:[Epoch 54] train=0.778025 val=0.827800 loss=0.638862 time: 19.213602
INFO:root:[Epoch 55] train=0.778846 val=0.838400 loss=0.634983 time: 19.083146
INFO:root:[Epoch 56] train=0.776963 val=0.845100 loss=0.639981 time: 19.093791
INFO:root:[Epoch 57] train=0.784435 val=0.846000 loss=0.622141 time: 19.209323
INFO:root:[Epoch 58] train=0.781510 val=0.863300 loss=0.626746 time: 19.115517
INFO:root:[Epoch 59] train=0.782111 val=0.864400 loss=0.621761 time: 19.063132
INFO:root:[Epoch 60] train=0.782572 val=0.861600 loss=0.623319 time: 19.107846
INFO:root:[Epoch 61] train=0.783954 val=0.837600 loss=0.620709 time: 19.245967
INFO:root:[Epoch 62] train=0.785176 val=0.867000 loss=0.615299 time: 19.237638
INFO:root:[Epoch 63] train=0.788021 val=0.826200 loss=0.615214 time: 19.181510
INFO:root:[Epoch 64] train=0.785958 val=0.819900 loss=0.611501 time: 19.142328
INFO:root:[Epoch 65] train=0.784956 val=0.864400 loss=0.616786 time: 19.148814
INFO:root:[Epoch 66] train=0.790264 val=0.849000 loss=0.602042 time: 19.157464
INFO:root:[Epoch 67] train=0.786358 val=0.865700 loss=0.611338 time: 19.219986
INFO:root:[Epoch 68] train=0.790685 val=0.865200 loss=0.606021 time: 19.102268
INFO:root:[Epoch 69] train=0.789683 val=0.859700 loss=0.604126 time: 19.180438
INFO:root:[Epoch 70] train=0.789904 val=0.849600 loss=0.605503 time: 19.232506
INFO:root:[Epoch 71] train=0.789163 val=0.836000 loss=0.606692 time: 19.070881
INFO:root:[Epoch 72] train=0.789443 val=0.848000 loss=0.605122 time: 19.235921
INFO:root:[Epoch 73] train=0.791106 val=0.842000 loss=0.601019 time: 19.169453
INFO:root:[Epoch 74] train=0.790405 val=0.862400 loss=0.596801 time: 18.656177
INFO:root:[Epoch 75] train=0.791687 val=0.862000 loss=0.599343 time: 18.696613
INFO:root:[Epoch 76] train=0.795172 val=0.860000 loss=0.590884 time: 18.621623
INFO:root:[Epoch 77] train=0.792728 val=0.850000 loss=0.596622 time: 18.853784
INFO:root:[Epoch 78] train=0.793369 val=0.855200 loss=0.592963 time: 18.748144
INFO:root:[Epoch 79] train=0.794551 val=0.850100 loss=0.587465 time: 18.693689
INFO:root:[Epoch 80] train=0.822676 val=0.903300 loss=0.506667 time: 18.558496
INFO:root:[Epoch 81] train=0.841907 val=0.908600 loss=0.457388 time: 18.787569
INFO:root:[Epoch 82] train=0.848297 val=0.909700 loss=0.438572 time: 18.658420
INFO:root:[Epoch 83] train=0.847656 val=0.911400 loss=0.438480 time: 18.897504
INFO:root:[Epoch 84] train=0.851963 val=0.912800 loss=0.428663 time: 18.854198
INFO:root:[Epoch 85] train=0.854928 val=0.913600 loss=0.418612 time: 18.686392
INFO:root:[Epoch 86] train=0.853766 val=0.913500 loss=0.420751 time: 18.496957
INFO:root:[Epoch 87] train=0.855689 val=0.913800 loss=0.415153 time: 18.678125
INFO:root:[Epoch 88] train=0.857692 val=0.914800 loss=0.409874 time: 18.793254
INFO:root:[Epoch 89] train=0.857833 val=0.914900 loss=0.407665 time: 18.571207
INFO:root:[Epoch 90] train=0.860777 val=0.916500 loss=0.403236 time: 18.848272
INFO:root:[Epoch 91] train=0.863161 val=0.915600 loss=0.395382 time: 18.650628
INFO:root:[Epoch 92] train=0.862620 val=0.918500 loss=0.392810 time: 18.777607
INFO:root:[Epoch 93] train=0.864343 val=0.915600 loss=0.390387 time: 18.784535
INFO:root:[Epoch 94] train=0.863201 val=0.917200 loss=0.391347 time: 18.809058
INFO:root:[Epoch 95] train=0.863061 val=0.917100 loss=0.392251 time: 18.652751
INFO:root:[Epoch 96] train=0.866526 val=0.915700 loss=0.384899 time: 18.634223
INFO:root:[Epoch 97] train=0.864243 val=0.919300 loss=0.389496 time: 18.698554
INFO:root:[Epoch 98] train=0.865805 val=0.918800 loss=0.385560 time: 18.666372
INFO:root:[Epoch 99] train=0.867067 val=0.920100 loss=0.381509 time: 18.655001
INFO:root:[Epoch 100] train=0.867748 val=0.914700 loss=0.377729 time: 18.717823
INFO:root:[Epoch 101] train=0.865986 val=0.919700 loss=0.382951 time: 18.812169
INFO:root:[Epoch 102] train=0.867788 val=0.919100 loss=0.378926 time: 18.697642
INFO:root:[Epoch 103] train=0.869211 val=0.918200 loss=0.376904 time: 18.681642
INFO:root:[Epoch 104] train=0.869191 val=0.917100 loss=0.376102 time: 18.595231
INFO:root:[Epoch 105] train=0.869050 val=0.915500 loss=0.374271 time: 18.851523
INFO:root:[Epoch 106] train=0.870393 val=0.917800 loss=0.374926 time: 18.583520
INFO:root:[Epoch 107] train=0.872796 val=0.915700 loss=0.368135 time: 18.808076
INFO:root:[Epoch 108] train=0.868269 val=0.916400 loss=0.375004 time: 18.683232
INFO:root:[Epoch 109] train=0.869912 val=0.916100 loss=0.369964 time: 18.705726
INFO:root:[Epoch 110] train=0.871334 val=0.919300 loss=0.367842 time: 18.712030
INFO:root:[Epoch 111] train=0.874800 val=0.918600 loss=0.363698 time: 18.812861
INFO:root:[Epoch 112] train=0.872175 val=0.918600 loss=0.368584 time: 18.850613
INFO:root:[Epoch 113] train=0.871935 val=0.920600 loss=0.368306 time: 18.717462
INFO:root:[Epoch 114] train=0.874319 val=0.919200 loss=0.359710 time: 18.742225
INFO:root:[Epoch 115] train=0.873618 val=0.915300 loss=0.364202 time: 18.874314
INFO:root:[Epoch 116] train=0.874179 val=0.914100 loss=0.361836 time: 18.995258
INFO:root:[Epoch 117] train=0.874619 val=0.914800 loss=0.357161 time: 18.625491
INFO:root:[Epoch 118] train=0.877143 val=0.919600 loss=0.353336 time: 18.724805
INFO:root:[Epoch 119] train=0.872696 val=0.917000 loss=0.363938 time: 18.716594
INFO:root:[Epoch 120] train=0.874800 val=0.919900 loss=0.358724 time: 18.640671
INFO:root:[Epoch 121] train=0.876583 val=0.919400 loss=0.358670 time: 18.782857
INFO:root:[Epoch 122] train=0.875521 val=0.917300 loss=0.357153 time: 18.787332
INFO:root:[Epoch 123] train=0.878305 val=0.918400 loss=0.352410 time: 18.804637
INFO:root:[Epoch 124] train=0.879527 val=0.918400 loss=0.344649 time: 18.695993
INFO:root:[Epoch 125] train=0.874740 val=0.919500 loss=0.360453 time: 18.687385
INFO:root:[Epoch 126] train=0.877204 val=0.918300 loss=0.353791 time: 18.954621
INFO:root:[Epoch 127] train=0.878446 val=0.919800 loss=0.351231 time: 18.816937
INFO:root:[Epoch 128] train=0.876102 val=0.916200 loss=0.357945 time: 18.699651
INFO:root:[Epoch 129] train=0.876342 val=0.917500 loss=0.354623 time: 18.762961
INFO:root:[Epoch 130] train=0.878866 val=0.918800 loss=0.348139 time: 18.955682
INFO:root:[Epoch 131] train=0.877544 val=0.916600 loss=0.352550 time: 18.678241
INFO:root:[Epoch 132] train=0.876603 val=0.916400 loss=0.355092 time: 18.902059
INFO:root:[Epoch 133] train=0.879287 val=0.916300 loss=0.346703 time: 18.803606
INFO:root:[Epoch 134] train=0.877404 val=0.917700 loss=0.350922 time: 18.932167
INFO:root:[Epoch 135] train=0.877284 val=0.917800 loss=0.350586 time: 18.760901
INFO:root:[Epoch 136] train=0.878726 val=0.919900 loss=0.348499 time: 18.913808
INFO:root:[Epoch 137] train=0.879908 val=0.918300 loss=0.346287 time: 18.764608
INFO:root:[Epoch 138] train=0.878846 val=0.917400 loss=0.352925 time: 18.879540
INFO:root:[Epoch 139] train=0.880188 val=0.918000 loss=0.344769 time: 18.781191
INFO:root:[Epoch 140] train=0.877384 val=0.911500 loss=0.349436 time: 18.732125
INFO:root:[Epoch 141] train=0.878145 val=0.918300 loss=0.354404 time: 18.801866
INFO:root:[Epoch 142] train=0.880769 val=0.916400 loss=0.344800 time: 18.642836
INFO:root:[Epoch 143] train=0.880028 val=0.918600 loss=0.347922 time: 18.850962
INFO:root:[Epoch 144] train=0.878646 val=0.920200 loss=0.346650 time: 18.675521
INFO:root:[Epoch 145] train=0.880308 val=0.916200 loss=0.344243 time: 18.936114
INFO:root:[Epoch 146] train=0.881490 val=0.918600 loss=0.339133 time: 18.701649
INFO:root:[Epoch 147] train=0.882312 val=0.919400 loss=0.342102 time: 18.952194
INFO:root:[Epoch 148] train=0.879708 val=0.918000 loss=0.346165 time: 18.742986
INFO:root:[Epoch 149] train=0.881270 val=0.918100 loss=0.335340 time: 18.852467
INFO:root:[Epoch 150] train=0.880208 val=0.919600 loss=0.345465 time: 18.822921
INFO:root:[Epoch 151] train=0.882953 val=0.922300 loss=0.339816 time: 18.943882
INFO:root:[Epoch 152] train=0.880849 val=0.917200 loss=0.343794 time: 18.755233
INFO:root:[Epoch 153] train=0.880649 val=0.918100 loss=0.342003 time: 18.857979
INFO:root:[Epoch 154] train=0.881671 val=0.921000 loss=0.339760 time: 18.842455
INFO:root:[Epoch 155] train=0.881711 val=0.921900 loss=0.335599 time: 18.836234
INFO:root:[Epoch 156] train=0.880829 val=0.919600 loss=0.340431 time: 18.846407
INFO:root:[Epoch 157] train=0.882051 val=0.915200 loss=0.338219 time: 18.831976
INFO:root:[Epoch 158] train=0.880869 val=0.919600 loss=0.342202 time: 18.961582
INFO:root:[Epoch 159] train=0.883654 val=0.916000 loss=0.334638 time: 18.899614
INFO:root:[Epoch 160] train=0.886619 val=0.922700 loss=0.324663 time: 18.940399
INFO:root:[Epoch 161] train=0.893429 val=0.925200 loss=0.306041 time: 18.804710
INFO:root:[Epoch 162] train=0.894211 val=0.925700 loss=0.308034 time: 19.080431
INFO:root:[Epoch 163] train=0.895453 val=0.926100 loss=0.307325 time: 18.689744
INFO:root:[Epoch 164] train=0.896615 val=0.925700 loss=0.302262 time: 18.797671
INFO:root:[Epoch 165] train=0.895493 val=0.926100 loss=0.302658 time: 18.814929
INFO:root:[Epoch 166] train=0.895933 val=0.926300 loss=0.299890 time: 18.910751
INFO:root:[Epoch 167] train=0.893510 val=0.928100 loss=0.306407 time: 18.879174
INFO:root:[Epoch 168] train=0.895713 val=0.926900 loss=0.300899 time: 18.939642
INFO:root:[Epoch 169] train=0.897496 val=0.926700 loss=0.296956 time: 18.851133
INFO:root:[Epoch 170] train=0.897736 val=0.927100 loss=0.296778 time: 18.990358
INFO:root:[Epoch 171] train=0.898217 val=0.927400 loss=0.293990 time: 18.871989
INFO:root:[Epoch 172] train=0.899900 val=0.926200 loss=0.290692 time: 18.957322
INFO:root:[Epoch 173] train=0.898077 val=0.928300 loss=0.292841 time: 18.868413
INFO:root:[Epoch 174] train=0.899840 val=0.926800 loss=0.292978 time: 18.899054
INFO:root:[Epoch 175] train=0.897736 val=0.927900 loss=0.296451 time: 18.800293
INFO:root:[Epoch 176] train=0.900421 val=0.928000 loss=0.291406 time: 18.902412
INFO:root:[Epoch 177] train=0.897937 val=0.927600 loss=0.292670 time: 18.808912
INFO:root:[Epoch 178] train=0.899539 val=0.927000 loss=0.291411 time: 18.817971
INFO:root:[Epoch 179] train=0.899920 val=0.927200 loss=0.291211 time: 18.881332
INFO:root:[Epoch 180] train=0.900921 val=0.927300 loss=0.288290 time: 18.833169
INFO:root:[Epoch 181] train=0.897516 val=0.925500 loss=0.295215 time: 19.024719
INFO:root:[Epoch 182] train=0.901643 val=0.927300 loss=0.286905 time: 19.050549
INFO:root:[Epoch 183] train=0.897336 val=0.927400 loss=0.294143 time: 18.924369
INFO:root:[Epoch 184] train=0.899920 val=0.926500 loss=0.291130 time: 18.840976
INFO:root:[Epoch 185] train=0.900401 val=0.928600 loss=0.288855 time: 18.952570
INFO:root:[Epoch 186] train=0.897776 val=0.926800 loss=0.293455 time: 19.040817
INFO:root:[Epoch 187] train=0.900521 val=0.925600 loss=0.290507 time: 18.785098
INFO:root:[Epoch 188] train=0.900601 val=0.927500 loss=0.289624 time: 18.831844
INFO:root:[Epoch 189] train=0.900321 val=0.927200 loss=0.286513 time: 18.917926
INFO:root:[Epoch 190] train=0.899539 val=0.927100 loss=0.291353 time: 18.700294
INFO:root:[Epoch 191] train=0.900521 val=0.927000 loss=0.291712 time: 19.040143
INFO:root:[Epoch 192] train=0.901983 val=0.926600 loss=0.286100 time: 18.827507
INFO:root:[Epoch 193] train=0.901142 val=0.926900 loss=0.285967 time: 19.088249
INFO:root:[Epoch 194] train=0.901583 val=0.924300 loss=0.286713 time: 18.858439
INFO:root:[Epoch 195] train=0.901182 val=0.925300 loss=0.284542 time: 18.987043
INFO:root:[Epoch 196] train=0.901663 val=0.925300 loss=0.283799 time: 18.852344
INFO:root:[Epoch 197] train=0.899359 val=0.926500 loss=0.288214 time: 18.925727
INFO:root:[Epoch 198] train=0.901823 val=0.927200 loss=0.284907 time: 19.001231
INFO:root:[Epoch 199] train=0.902043 val=0.926600 loss=0.284809 time: 18.993710
INFO:root:[Epoch 200] train=0.898778 val=0.925600 loss=0.288949 time: 18.977408
INFO:root:[Epoch 201] train=0.902404 val=0.925000 loss=0.283957 time: 18.769091
INFO:root:[Epoch 202] train=0.899399 val=0.926900 loss=0.286078 time: 18.895390
INFO:root:[Epoch 203] train=0.901002 val=0.927800 loss=0.285950 time: 18.802330
INFO:root:[Epoch 204] train=0.902103 val=0.926100 loss=0.280874 time: 19.041150
INFO:root:[Epoch 205] train=0.903165 val=0.927100 loss=0.279117 time: 18.927863
INFO:root:[Epoch 206] train=0.902744 val=0.926000 loss=0.281138 time: 18.980735
INFO:root:[Epoch 207] train=0.901823 val=0.926900 loss=0.283977 time: 18.944197
INFO:root:[Epoch 208] train=0.904387 val=0.926300 loss=0.275880 time: 19.108128
INFO:root:[Epoch 209] train=0.903345 val=0.926900 loss=0.277917 time: 18.884953
INFO:root:[Epoch 210] train=0.902444 val=0.925900 loss=0.282265 time: 19.009659
INFO:root:[Epoch 211] train=0.901262 val=0.926500 loss=0.282128 time: 18.716475
INFO:root:[Epoch 212] train=0.901362 val=0.926200 loss=0.283933 time: 18.928041
INFO:root:[Epoch 213] train=0.902204 val=0.927000 loss=0.281984 time: 18.910470
INFO:root:[Epoch 214] train=0.902003 val=0.925900 loss=0.282258 time: 19.037348
INFO:root:[Epoch 215] train=0.901042 val=0.927100 loss=0.287025 time: 19.008156
INFO:root:[Epoch 216] train=0.902364 val=0.927100 loss=0.279646 time: 18.838615
INFO:root:[Epoch 217] train=0.902584 val=0.925600 loss=0.281324 time: 19.062934
INFO:root:[Epoch 218] train=0.901923 val=0.926500 loss=0.280781 time: 18.990876
INFO:root:[Epoch 219] train=0.903125 val=0.926100 loss=0.280606 time: 19.149102
INFO:root:[Epoch 220] train=0.902284 val=0.927500 loss=0.283799 time: 18.762045
INFO:root:[Epoch 221] train=0.903345 val=0.927700 loss=0.282104 time: 19.096057
INFO:root:[Epoch 222] train=0.902825 val=0.926700 loss=0.275168 time: 18.917768
INFO:root:[Epoch 223] train=0.903305 val=0.927700 loss=0.280942 time: 19.018552
INFO:root:[Epoch 224] train=0.904307 val=0.926600 loss=0.278301 time: 18.885858
INFO:root:[Epoch 225] train=0.905529 val=0.925900 loss=0.274752 time: 18.972005
INFO:root:[Epoch 226] train=0.903626 val=0.927500 loss=0.280540 time: 18.931103
INFO:root:[Epoch 227] train=0.903225 val=0.927000 loss=0.279802 time: 18.966856
INFO:root:[Epoch 228] train=0.901643 val=0.926400 loss=0.284223 time: 19.067686
INFO:root:[Epoch 229] train=0.904487 val=0.926500 loss=0.279246 time: 18.880624
INFO:root:[Epoch 230] train=0.903325 val=0.924500 loss=0.278872 time: 19.063386
INFO:root:[Epoch 231] train=0.904748 val=0.928200 loss=0.275513 time: 19.044573
INFO:root:[Epoch 232] train=0.905108 val=0.926900 loss=0.275754 time: 19.027766
INFO:root:[Epoch 233] train=0.902945 val=0.928000 loss=0.280227 time: 19.000999
INFO:root:[Epoch 234] train=0.904407 val=0.926800 loss=0.276797 time: 19.053714
INFO:root:[Epoch 235] train=0.904247 val=0.927400 loss=0.275406 time: 18.963144
INFO:root:[Epoch 236] train=0.904427 val=0.926200 loss=0.274932 time: 18.898041
INFO:root:[Epoch 237] train=0.903425 val=0.927200 loss=0.277944 time: 18.915320
INFO:root:[Epoch 238] train=0.906090 val=0.926800 loss=0.272003 time: 19.111214
INFO:root:[Epoch 239] train=0.903065 val=0.928400 loss=0.279542 time: 18.818620
