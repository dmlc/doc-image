INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.2, lr_decay_epoch='60,120,160', lr_decay_period=0, mode='hybrid', model='cifar_wideresnet28_10', momentum=0.9, num_epochs=200, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0005)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[07:07:10] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.296494 val=0.387500 loss=1.929401 time: 76.660952
INFO:root:[Epoch 1] train=0.423317 val=0.538600 loss=1.591190 time: 74.939483
INFO:root:[Epoch 2] train=0.512300 val=0.580200 loss=1.357149 time: 75.062156
INFO:root:[Epoch 3] train=0.571094 val=0.664000 loss=1.200765 time: 75.041283
INFO:root:[Epoch 4] train=0.614143 val=0.613300 loss=1.098820 time: 74.981761
INFO:root:[Epoch 5] train=0.641587 val=0.707700 loss=1.022043 time: 75.065226
INFO:root:[Epoch 6] train=0.656991 val=0.698800 loss=0.974698 time: 74.901923
INFO:root:[Epoch 7] train=0.672676 val=0.747100 loss=0.940114 time: 75.089756
INFO:root:[Epoch 8] train=0.681450 val=0.702800 loss=0.911890 time: 74.859767
INFO:root:[Epoch 9] train=0.691226 val=0.722300 loss=0.884016 time: 74.977264
INFO:root:[Epoch 10] train=0.695833 val=0.718000 loss=0.870311 time: 75.014253
INFO:root:[Epoch 11] train=0.701663 val=0.763100 loss=0.856277 time: 74.980005
INFO:root:[Epoch 12] train=0.708053 val=0.771800 loss=0.838402 time: 74.913323
INFO:root:[Epoch 13] train=0.713361 val=0.745600 loss=0.824924 time: 74.910983
INFO:root:[Epoch 14] train=0.719531 val=0.786100 loss=0.805701 time: 74.888271
INFO:root:[Epoch 15] train=0.724119 val=0.785200 loss=0.800301 time: 74.938156
INFO:root:[Epoch 16] train=0.726783 val=0.764100 loss=0.783203 time: 74.887461
INFO:root:[Epoch 17] train=0.725982 val=0.747300 loss=0.783713 time: 74.996985
INFO:root:[Epoch 18] train=0.732212 val=0.801300 loss=0.771990 time: 74.846168
INFO:root:[Epoch 19] train=0.732111 val=0.789800 loss=0.769420 time: 74.920999
INFO:root:[Epoch 20] train=0.736118 val=0.807900 loss=0.758284 time: 75.002507
INFO:root:[Epoch 21] train=0.738321 val=0.823800 loss=0.748503 time: 74.916692
INFO:root:[Epoch 22] train=0.743990 val=0.775500 loss=0.734749 time: 74.876134
INFO:root:[Epoch 23] train=0.744491 val=0.831100 loss=0.734900 time: 74.930372
INFO:root:[Epoch 24] train=0.744010 val=0.809800 loss=0.737365 time: 74.945831
INFO:root:[Epoch 25] train=0.744772 val=0.807000 loss=0.731721 time: 74.959215
INFO:root:[Epoch 26] train=0.750000 val=0.791600 loss=0.723311 time: 74.906203
INFO:root:[Epoch 27] train=0.752804 val=0.819700 loss=0.715698 time: 74.958732
INFO:root:[Epoch 28] train=0.750881 val=0.807200 loss=0.716842 time: 74.886048
INFO:root:[Epoch 29] train=0.751042 val=0.830200 loss=0.718374 time: 75.009567
INFO:root:[Epoch 30] train=0.752344 val=0.803400 loss=0.713220 time: 74.886278
INFO:root:[Epoch 31] train=0.757632 val=0.829900 loss=0.702213 time: 74.983575
INFO:root:[Epoch 32] train=0.754687 val=0.823800 loss=0.706043 time: 74.962953
INFO:root:[Epoch 33] train=0.756530 val=0.812500 loss=0.699526 time: 74.945470
INFO:root:[Epoch 34] train=0.757472 val=0.839600 loss=0.697677 time: 74.925233
INFO:root:[Epoch 35] train=0.757332 val=0.798600 loss=0.700007 time: 75.040286
INFO:root:[Epoch 36] train=0.756070 val=0.828200 loss=0.703345 time: 74.884787
INFO:root:[Epoch 37] train=0.757913 val=0.816200 loss=0.698020 time: 74.889691
INFO:root:[Epoch 38] train=0.756971 val=0.827000 loss=0.698962 time: 74.904343
INFO:root:[Epoch 39] train=0.760276 val=0.833800 loss=0.691133 time: 74.924420
INFO:root:[Epoch 40] train=0.760296 val=0.834500 loss=0.691663 time: 74.870751
INFO:root:[Epoch 41] train=0.760497 val=0.833300 loss=0.691655 time: 74.978649
INFO:root:[Epoch 42] train=0.759856 val=0.825100 loss=0.692788 time: 74.889524
INFO:root:[Epoch 43] train=0.760637 val=0.797500 loss=0.682964 time: 74.950544
INFO:root:[Epoch 44] train=0.760677 val=0.843600 loss=0.689801 time: 74.989126
INFO:root:[Epoch 45] train=0.763341 val=0.830900 loss=0.684326 time: 75.045213
INFO:root:[Epoch 46] train=0.762420 val=0.825500 loss=0.685998 time: 75.029658
INFO:root:[Epoch 47] train=0.764083 val=0.825800 loss=0.683150 time: 74.954111
INFO:root:[Epoch 48] train=0.762740 val=0.829900 loss=0.682546 time: 75.017185
INFO:root:[Epoch 49] train=0.762420 val=0.819500 loss=0.683845 time: 74.952657
INFO:root:[Epoch 50] train=0.766246 val=0.859300 loss=0.674060 time: 74.990016
INFO:root:[Epoch 51] train=0.764924 val=0.848900 loss=0.678142 time: 75.021750
INFO:root:[Epoch 52] train=0.766587 val=0.831900 loss=0.681521 time: 74.969300
INFO:root:[Epoch 53] train=0.766747 val=0.812400 loss=0.668715 time: 74.851226
INFO:root:[Epoch 54] train=0.762981 val=0.820400 loss=0.682384 time: 74.876264
INFO:root:[Epoch 55] train=0.763181 val=0.848500 loss=0.681498 time: 74.981157
INFO:root:[Epoch 56] train=0.766787 val=0.827900 loss=0.673487 time: 74.977869
INFO:root:[Epoch 57] train=0.762440 val=0.801100 loss=0.679547 time: 74.953337
INFO:root:[Epoch 58] train=0.766627 val=0.820300 loss=0.671821 time: 75.004634
INFO:root:[Epoch 59] train=0.765024 val=0.795600 loss=0.674654 time: 75.063200
INFO:root:[Epoch 60] train=0.823618 val=0.913600 loss=0.504935 time: 75.088777
INFO:root:[Epoch 61] train=0.847817 val=0.920100 loss=0.440881 time: 75.033801
INFO:root:[Epoch 62] train=0.851242 val=0.922500 loss=0.429466 time: 75.057065
INFO:root:[Epoch 63] train=0.856350 val=0.923800 loss=0.418305 time: 75.022367
INFO:root:[Epoch 64] train=0.856811 val=0.921400 loss=0.410607 time: 75.053071
INFO:root:[Epoch 65] train=0.859235 val=0.919400 loss=0.409302 time: 74.990724
INFO:root:[Epoch 66] train=0.860397 val=0.921500 loss=0.406259 time: 75.014083
INFO:root:[Epoch 67] train=0.861218 val=0.915500 loss=0.400819 time: 75.123148
INFO:root:[Epoch 68] train=0.859916 val=0.917100 loss=0.406017 time: 75.031441
INFO:root:[Epoch 69] train=0.859976 val=0.916900 loss=0.409637 time: 75.041900
INFO:root:[Epoch 70] train=0.861198 val=0.915100 loss=0.405286 time: 75.022626
INFO:root:[Epoch 71] train=0.862961 val=0.915600 loss=0.401031 time: 74.952289
INFO:root:[Epoch 72] train=0.860437 val=0.919500 loss=0.403168 time: 74.962620
INFO:root:[Epoch 73] train=0.862340 val=0.906900 loss=0.398428 time: 75.060717
INFO:root:[Epoch 74] train=0.857352 val=0.914900 loss=0.410747 time: 74.968216
INFO:root:[Epoch 75] train=0.859515 val=0.910900 loss=0.409833 time: 75.170926
INFO:root:[Epoch 76] train=0.858874 val=0.910800 loss=0.408744 time: 75.473765
INFO:root:[Epoch 77] train=0.858934 val=0.916600 loss=0.404612 time: 75.424385
INFO:root:[Epoch 78] train=0.859916 val=0.921600 loss=0.406103 time: 75.387733
INFO:root:[Epoch 79] train=0.858634 val=0.909900 loss=0.406921 time: 75.445532
INFO:root:[Epoch 80] train=0.860056 val=0.914900 loss=0.404815 time: 75.402355
INFO:root:[Epoch 81] train=0.861138 val=0.909900 loss=0.398585 time: 75.446573
INFO:root:[Epoch 82] train=0.859355 val=0.907900 loss=0.409147 time: 75.535448
INFO:root:[Epoch 83] train=0.861558 val=0.919100 loss=0.397005 time: 75.372196
INFO:root:[Epoch 84] train=0.862119 val=0.911400 loss=0.397680 time: 75.507206
INFO:root:[Epoch 85] train=0.862841 val=0.919200 loss=0.398708 time: 75.409774
INFO:root:[Epoch 86] train=0.859796 val=0.913200 loss=0.406262 time: 75.591807
INFO:root:[Epoch 87] train=0.862600 val=0.920600 loss=0.397321 time: 75.629324
INFO:root:[Epoch 88] train=0.861979 val=0.914600 loss=0.397613 time: 75.496668
INFO:root:[Epoch 89] train=0.860817 val=0.920600 loss=0.399415 time: 75.671038
INFO:root:[Epoch 90] train=0.858293 val=0.926600 loss=0.404675 time: 75.466872
INFO:root:[Epoch 91] train=0.863241 val=0.920200 loss=0.398173 time: 75.478368
INFO:root:[Epoch 92] train=0.862380 val=0.922700 loss=0.397644 time: 75.442832
INFO:root:[Epoch 93] train=0.861819 val=0.906200 loss=0.397119 time: 75.427595
INFO:root:[Epoch 94] train=0.866326 val=0.907700 loss=0.388388 time: 75.391856
INFO:root:[Epoch 95] train=0.862300 val=0.908100 loss=0.397046 time: 75.491029
INFO:root:[Epoch 96] train=0.865164 val=0.915300 loss=0.391165 time: 75.432798
INFO:root:[Epoch 97] train=0.865665 val=0.920300 loss=0.388021 time: 75.442076
INFO:root:[Epoch 98] train=0.864103 val=0.922400 loss=0.391304 time: 75.495600
INFO:root:[Epoch 99] train=0.865244 val=0.906700 loss=0.391675 time: 75.480854
INFO:root:[Epoch 100] train=0.867548 val=0.913100 loss=0.386674 time: 75.515570
INFO:root:[Epoch 101] train=0.865865 val=0.919600 loss=0.389509 time: 75.243239
INFO:root:[Epoch 102] train=0.865946 val=0.912300 loss=0.387327 time: 75.110285
INFO:root:[Epoch 103] train=0.866667 val=0.915500 loss=0.382488 time: 75.116611
INFO:root:[Epoch 104] train=0.866146 val=0.912000 loss=0.386820 time: 75.064339
INFO:root:[Epoch 105] train=0.869952 val=0.916000 loss=0.381531 time: 75.132422
INFO:root:[Epoch 106] train=0.866066 val=0.927100 loss=0.390509 time: 75.074157
INFO:root:[Epoch 107] train=0.871074 val=0.908800 loss=0.377038 time: 75.097780
INFO:root:[Epoch 108] train=0.867488 val=0.915900 loss=0.379423 time: 75.082338
INFO:root:[Epoch 109] train=0.870553 val=0.900800 loss=0.376747 time: 75.111746
INFO:root:[Epoch 110] train=0.870933 val=0.917100 loss=0.376327 time: 75.119845
INFO:root:[Epoch 111] train=0.867748 val=0.918900 loss=0.383901 time: 75.079542
INFO:root:[Epoch 112] train=0.869010 val=0.915100 loss=0.376472 time: 75.194613
INFO:root:[Epoch 113] train=0.864423 val=0.920700 loss=0.390181 time: 75.250930
INFO:root:[Epoch 114] train=0.867829 val=0.900600 loss=0.379559 time: 75.166556
INFO:root:[Epoch 115] train=0.871615 val=0.916100 loss=0.373828 time: 75.198440
INFO:root:[Epoch 116] train=0.867989 val=0.923200 loss=0.380566 time: 75.068755
INFO:root:[Epoch 117] train=0.870893 val=0.912100 loss=0.373545 time: 75.170335
INFO:root:[Epoch 118] train=0.868730 val=0.914600 loss=0.379815 time: 75.258010
INFO:root:[Epoch 119] train=0.868890 val=0.907200 loss=0.381871 time: 75.140146
INFO:root:[Epoch 120] train=0.898878 val=0.947400 loss=0.295187 time: 75.088584
INFO:root:[Epoch 121] train=0.911518 val=0.951400 loss=0.259383 time: 75.143577
INFO:root:[Epoch 122] train=0.914623 val=0.948700 loss=0.247351 time: 75.106361
INFO:root:[Epoch 123] train=0.919010 val=0.952200 loss=0.238621 time: 75.222200
INFO:root:[Epoch 124] train=0.920072 val=0.952700 loss=0.236258 time: 75.170074
INFO:root:[Epoch 125] train=0.918810 val=0.951600 loss=0.234002 time: 75.119081
INFO:root:[Epoch 126] train=0.923538 val=0.954600 loss=0.224771 time: 75.184150
INFO:root:[Epoch 127] train=0.924720 val=0.951600 loss=0.222680 time: 75.268018
INFO:root:[Epoch 128] train=0.923498 val=0.952700 loss=0.228096 time: 75.226187
INFO:root:[Epoch 129] train=0.922476 val=0.950000 loss=0.224999 time: 75.263134
INFO:root:[Epoch 130] train=0.926102 val=0.947800 loss=0.218893 time: 75.190295
INFO:root:[Epoch 131] train=0.923417 val=0.951200 loss=0.220715 time: 75.186169
INFO:root:[Epoch 132] train=0.925381 val=0.947600 loss=0.217275 time: 75.172487
INFO:root:[Epoch 133] train=0.926502 val=0.952400 loss=0.215820 time: 75.169107
INFO:root:[Epoch 134] train=0.925581 val=0.950800 loss=0.218077 time: 75.082674
INFO:root:[Epoch 135] train=0.925060 val=0.950800 loss=0.218307 time: 75.213550
INFO:root:[Epoch 136] train=0.924880 val=0.948300 loss=0.219073 time: 75.080882
INFO:root:[Epoch 137] train=0.928846 val=0.950900 loss=0.209444 time: 75.237156
INFO:root:[Epoch 138] train=0.927985 val=0.949500 loss=0.214157 time: 75.106250
INFO:root:[Epoch 139] train=0.927885 val=0.951100 loss=0.211009 time: 75.209171
INFO:root:[Epoch 140] train=0.927284 val=0.948700 loss=0.213491 time: 75.253943
INFO:root:[Epoch 141] train=0.927825 val=0.950100 loss=0.211131 time: 75.329861
INFO:root:[Epoch 142] train=0.929227 val=0.948000 loss=0.207040 time: 75.216930
INFO:root:[Epoch 143] train=0.929107 val=0.949500 loss=0.210066 time: 75.248231
INFO:root:[Epoch 144] train=0.928446 val=0.951000 loss=0.211022 time: 75.200882
INFO:root:[Epoch 145] train=0.926663 val=0.946700 loss=0.212306 time: 75.114311
INFO:root:[Epoch 146] train=0.929928 val=0.946500 loss=0.203809 time: 75.296632
INFO:root:[Epoch 147] train=0.929908 val=0.946200 loss=0.207183 time: 75.159583
INFO:root:[Epoch 148] train=0.926703 val=0.946200 loss=0.215071 time: 75.321393
INFO:root:[Epoch 149] train=0.926362 val=0.951000 loss=0.212334 time: 75.084197
INFO:root:[Epoch 150] train=0.928926 val=0.950900 loss=0.211709 time: 75.201710
INFO:root:[Epoch 151] train=0.930108 val=0.945600 loss=0.208240 time: 75.202208
INFO:root:[Epoch 152] train=0.929227 val=0.949600 loss=0.208111 time: 75.136674
INFO:root:[Epoch 153] train=0.927544 val=0.949300 loss=0.212608 time: 75.126389
INFO:root:[Epoch 154] train=0.929067 val=0.948400 loss=0.209093 time: 75.272415
INFO:root:[Epoch 155] train=0.929708 val=0.948500 loss=0.208021 time: 75.254167
INFO:root:[Epoch 156] train=0.927744 val=0.949800 loss=0.210221 time: 75.180758
INFO:root:[Epoch 157] train=0.928165 val=0.947600 loss=0.211740 time: 75.212110
INFO:root:[Epoch 158] train=0.929167 val=0.944800 loss=0.208588 time: 75.298301
INFO:root:[Epoch 159] train=0.926763 val=0.947300 loss=0.213674 time: 75.200173
INFO:root:[Epoch 160] train=0.937119 val=0.952500 loss=0.187759 time: 75.089303
INFO:root:[Epoch 161] train=0.941867 val=0.952300 loss=0.173525 time: 75.140422
INFO:root:[Epoch 162] train=0.941747 val=0.951800 loss=0.173399 time: 75.109179
INFO:root:[Epoch 163] train=0.943049 val=0.953400 loss=0.168733 time: 75.013257
INFO:root:[Epoch 164] train=0.946534 val=0.953300 loss=0.161519 time: 75.066290
INFO:root:[Epoch 165] train=0.943770 val=0.952700 loss=0.168962 time: 75.147627
INFO:root:[Epoch 166] train=0.946254 val=0.953400 loss=0.161037 time: 75.125734
INFO:root:[Epoch 167] train=0.945152 val=0.953300 loss=0.163468 time: 75.102726
INFO:root:[Epoch 168] train=0.944551 val=0.954300 loss=0.164240 time: 75.085791
INFO:root:[Epoch 169] train=0.947236 val=0.954000 loss=0.156638 time: 75.137572
INFO:root:[Epoch 170] train=0.945533 val=0.953100 loss=0.162920 time: 75.126217
INFO:root:[Epoch 171] train=0.944712 val=0.955700 loss=0.159719 time: 75.196805
INFO:root:[Epoch 172] train=0.946935 val=0.952700 loss=0.154524 time: 75.073789
INFO:root:[Epoch 173] train=0.946575 val=0.954500 loss=0.158938 time: 75.170804
INFO:root:[Epoch 174] train=0.948397 val=0.954500 loss=0.154476 time: 75.095379
INFO:root:[Epoch 175] train=0.947736 val=0.954700 loss=0.156773 time: 75.209959
INFO:root:[Epoch 176] train=0.947716 val=0.953500 loss=0.157858 time: 75.167081
INFO:root:[Epoch 177] train=0.946354 val=0.954700 loss=0.156604 time: 75.159008
INFO:root:[Epoch 178] train=0.947095 val=0.953300 loss=0.158561 time: 75.383122
INFO:root:[Epoch 179] train=0.946735 val=0.955700 loss=0.156747 time: 75.620323
INFO:root:[Epoch 180] train=0.948518 val=0.954400 loss=0.154243 time: 75.550544
INFO:root:[Epoch 181] train=0.948397 val=0.956200 loss=0.153117 time: 75.601643
INFO:root:[Epoch 182] train=0.948277 val=0.953400 loss=0.155054 time: 75.560523
INFO:root:[Epoch 183] train=0.948057 val=0.954700 loss=0.154775 time: 75.532587
INFO:root:[Epoch 184] train=0.947015 val=0.953700 loss=0.154826 time: 75.547197
INFO:root:[Epoch 185] train=0.948377 val=0.955500 loss=0.153660 time: 75.712936
INFO:root:[Epoch 186] train=0.949519 val=0.955500 loss=0.149248 time: 75.633212
INFO:root:[Epoch 187] train=0.948658 val=0.956000 loss=0.153725 time: 75.696770
INFO:root:[Epoch 188] train=0.948438 val=0.954200 loss=0.151096 time: 75.706288
INFO:root:[Epoch 189] train=0.949700 val=0.955200 loss=0.148686 time: 75.583288
INFO:root:[Epoch 190] train=0.950240 val=0.953600 loss=0.151067 time: 75.690322
INFO:root:[Epoch 191] train=0.948157 val=0.953700 loss=0.150697 time: 75.618038
INFO:root:[Epoch 192] train=0.948438 val=0.955600 loss=0.154280 time: 75.801127
INFO:root:[Epoch 193] train=0.949599 val=0.954300 loss=0.148602 time: 75.507594
INFO:root:[Epoch 194] train=0.947276 val=0.955000 loss=0.152775 time: 75.703815
INFO:root:[Epoch 195] train=0.947977 val=0.955100 loss=0.154036 time: 75.540616
INFO:root:[Epoch 196] train=0.949659 val=0.955900 loss=0.148187 time: 75.494125
INFO:root:[Epoch 197] train=0.948978 val=0.956900 loss=0.152143 time: 75.655856
INFO:root:[Epoch 198] train=0.948958 val=0.954200 loss=0.149987 time: 75.623361
INFO:root:[Epoch 199] train=0.949519 val=0.954200 loss=0.150851 time: 75.562507
