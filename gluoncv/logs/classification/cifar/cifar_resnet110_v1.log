INFO:root:Namespace(batch_size=128, drop_rate=0.0, logging_dir='logs', lr=0.1, lr_decay=0.1, lr_decay_epoch='80,160', lr_decay_period=0, mode='hybrid', model='cifar_resnet110_v1', momentum=0.9, num_epochs=240, num_gpus=1, num_workers=8, resume_from=None, save_dir='params', save_period=10, save_plot_dir='.', wd=0.0001)
/usr/local/lib/python2.7/dist-packages/mxnet/gluon/data/vision/datasets.py:193: DeprecationWarning: The binary mode of fromstring is deprecated, as it behaves surprisingly on unicode inputs. Use frombuffer instead
  data = np.fromstring(fin.read(), dtype=np.uint8).reshape(-1, 3072+1)
[06:21:47] src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:107: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)
INFO:root:[Epoch 0] train=0.151082 val=0.190600 loss=2.307382 time: 36.467496
INFO:root:[Epoch 1] train=0.279647 val=0.346400 loss=1.901220 time: 35.121689
INFO:root:[Epoch 2] train=0.348658 val=0.417400 loss=1.750185 time: 35.065088
INFO:root:[Epoch 3] train=0.396294 val=0.456900 loss=1.649017 time: 35.062371
INFO:root:[Epoch 4] train=0.438942 val=0.464600 loss=1.543069 time: 35.032524
INFO:root:[Epoch 5] train=0.483253 val=0.564100 loss=1.431566 time: 34.988239
INFO:root:[Epoch 6] train=0.521735 val=0.558300 loss=1.332571 time: 34.961938
INFO:root:[Epoch 7] train=0.556170 val=0.644600 loss=1.249161 time: 35.109965
INFO:root:[Epoch 8] train=0.577985 val=0.631300 loss=1.180604 time: 34.792330
INFO:root:[Epoch 9] train=0.607232 val=0.678700 loss=1.111975 time: 35.032877
INFO:root:[Epoch 10] train=0.622015 val=0.714200 loss=1.071107 time: 34.827987
INFO:root:[Epoch 11] train=0.641066 val=0.705300 loss=1.021278 time: 34.861194
INFO:root:[Epoch 12] train=0.652825 val=0.696900 loss=0.991081 time: 35.103962
INFO:root:[Epoch 13] train=0.662720 val=0.704200 loss=0.960445 time: 35.045677
INFO:root:[Epoch 14] train=0.672696 val=0.736800 loss=0.937865 time: 34.939811
INFO:root:[Epoch 15] train=0.679868 val=0.716100 loss=0.912001 time: 35.145356
INFO:root:[Epoch 16] train=0.683734 val=0.763100 loss=0.897961 time: 35.186350
INFO:root:[Epoch 17] train=0.692468 val=0.744700 loss=0.884215 time: 35.024583
INFO:root:[Epoch 18] train=0.699639 val=0.761400 loss=0.855320 time: 35.052183
INFO:root:[Epoch 19] train=0.708754 val=0.769800 loss=0.837375 time: 35.072952
INFO:root:[Epoch 20] train=0.710016 val=0.745800 loss=0.829983 time: 35.122646
INFO:root:[Epoch 21] train=0.713482 val=0.775200 loss=0.822382 time: 35.235065
INFO:root:[Epoch 22] train=0.722336 val=0.764600 loss=0.800459 time: 34.889052
INFO:root:[Epoch 23] train=0.724659 val=0.776100 loss=0.789362 time: 34.951711
INFO:root:[Epoch 24] train=0.726663 val=0.792500 loss=0.780948 time: 35.040893
INFO:root:[Epoch 25] train=0.726282 val=0.823400 loss=0.778862 time: 35.094368
INFO:root:[Epoch 26] train=0.731731 val=0.788300 loss=0.771334 time: 35.241989
INFO:root:[Epoch 27] train=0.738001 val=0.810600 loss=0.753630 time: 35.057331
INFO:root:[Epoch 28] train=0.737420 val=0.798000 loss=0.756274 time: 35.132457
INFO:root:[Epoch 29] train=0.740325 val=0.784700 loss=0.743365 time: 35.120984
INFO:root:[Epoch 30] train=0.745753 val=0.797800 loss=0.727567 time: 34.958186
INFO:root:[Epoch 31] train=0.745974 val=0.810400 loss=0.727771 time: 35.010535
INFO:root:[Epoch 32] train=0.750942 val=0.815900 loss=0.716150 time: 35.171830
INFO:root:[Epoch 33] train=0.753045 val=0.809300 loss=0.714105 time: 34.987458
INFO:root:[Epoch 34] train=0.753786 val=0.818200 loss=0.702284 time: 35.118313
INFO:root:[Epoch 35] train=0.754046 val=0.820700 loss=0.702109 time: 34.963027
INFO:root:[Epoch 36] train=0.759635 val=0.793000 loss=0.693135 time: 35.088984
INFO:root:[Epoch 37] train=0.764022 val=0.841300 loss=0.675716 time: 35.133128
INFO:root:[Epoch 38] train=0.761939 val=0.785900 loss=0.684418 time: 35.022016
INFO:root:[Epoch 39] train=0.759395 val=0.835600 loss=0.692049 time: 35.025614
INFO:root:[Epoch 40] train=0.764263 val=0.827600 loss=0.670851 time: 35.264970
INFO:root:[Epoch 41] train=0.764223 val=0.817400 loss=0.674462 time: 35.176828
INFO:root:[Epoch 42] train=0.769732 val=0.823900 loss=0.666226 time: 35.206163
INFO:root:[Epoch 43] train=0.766947 val=0.838000 loss=0.664832 time: 35.054774
INFO:root:[Epoch 44] train=0.769611 val=0.848300 loss=0.658355 time: 34.954467
INFO:root:[Epoch 45] train=0.769411 val=0.833200 loss=0.659676 time: 35.038241
INFO:root:[Epoch 46] train=0.770413 val=0.828200 loss=0.651829 time: 35.207457
INFO:root:[Epoch 47] train=0.775801 val=0.825000 loss=0.638473 time: 34.983286
INFO:root:[Epoch 48] train=0.776943 val=0.840800 loss=0.638949 time: 35.234176
INFO:root:[Epoch 49] train=0.777404 val=0.842700 loss=0.640867 time: 34.928275
INFO:root:[Epoch 50] train=0.778846 val=0.859500 loss=0.632942 time: 34.906538
INFO:root:[Epoch 51] train=0.781811 val=0.857200 loss=0.630741 time: 35.064340
INFO:root:[Epoch 52] train=0.780168 val=0.837000 loss=0.629153 time: 35.139781
INFO:root:[Epoch 53] train=0.778646 val=0.813800 loss=0.633027 time: 35.131825
INFO:root:[Epoch 54] train=0.783934 val=0.844100 loss=0.620149 time: 35.099186
INFO:root:[Epoch 55] train=0.781390 val=0.857900 loss=0.626122 time: 34.977621
INFO:root:[Epoch 56] train=0.783213 val=0.846200 loss=0.624403 time: 35.249988
INFO:root:[Epoch 57] train=0.783313 val=0.847200 loss=0.619719 time: 35.120566
INFO:root:[Epoch 58] train=0.785837 val=0.787600 loss=0.614688 time: 35.272472
INFO:root:[Epoch 59] train=0.786619 val=0.857300 loss=0.611910 time: 35.078412
INFO:root:[Epoch 60] train=0.787300 val=0.855800 loss=0.612914 time: 35.037279
INFO:root:[Epoch 61] train=0.788462 val=0.871300 loss=0.612234 time: 35.295876
INFO:root:[Epoch 62] train=0.789824 val=0.820000 loss=0.605149 time: 35.093075
INFO:root:[Epoch 63] train=0.788602 val=0.863500 loss=0.608113 time: 35.154535
INFO:root:[Epoch 64] train=0.791907 val=0.846100 loss=0.598859 time: 34.954068
INFO:root:[Epoch 65] train=0.789824 val=0.867100 loss=0.603308 time: 35.170962
INFO:root:[Epoch 66] train=0.788762 val=0.865000 loss=0.606211 time: 35.009681
INFO:root:[Epoch 67] train=0.795533 val=0.844700 loss=0.589036 time: 35.204326
INFO:root:[Epoch 68] train=0.793750 val=0.871800 loss=0.594844 time: 35.239087
INFO:root:[Epoch 69] train=0.790124 val=0.863300 loss=0.598878 time: 35.254648
INFO:root:[Epoch 70] train=0.793790 val=0.865200 loss=0.590746 time: 34.899261
INFO:root:[Epoch 71] train=0.795393 val=0.854600 loss=0.586852 time: 35.142240
INFO:root:[Epoch 72] train=0.797055 val=0.835500 loss=0.586026 time: 35.336768
INFO:root:[Epoch 73] train=0.793389 val=0.848000 loss=0.590372 time: 35.267585
INFO:root:[Epoch 74] train=0.794631 val=0.861400 loss=0.592308 time: 35.161207
INFO:root:[Epoch 75] train=0.796915 val=0.856400 loss=0.584901 time: 35.284791
INFO:root:[Epoch 76] train=0.795913 val=0.859600 loss=0.581418 time: 35.012010
INFO:root:[Epoch 77] train=0.797035 val=0.841600 loss=0.581954 time: 35.030066
INFO:root:[Epoch 78] train=0.797576 val=0.857700 loss=0.581069 time: 34.801919
INFO:root:[Epoch 79] train=0.801262 val=0.859200 loss=0.574943 time: 34.974655
INFO:root:[Epoch 80] train=0.830489 val=0.906000 loss=0.487912 time: 34.978515
INFO:root:[Epoch 81] train=0.849419 val=0.909000 loss=0.436119 time: 34.877036
INFO:root:[Epoch 82] train=0.853526 val=0.913100 loss=0.422247 time: 35.219806
INFO:root:[Epoch 83] train=0.857472 val=0.914800 loss=0.408411 time: 35.231858
INFO:root:[Epoch 84] train=0.859295 val=0.912500 loss=0.401070 time: 34.921510
INFO:root:[Epoch 85] train=0.861078 val=0.917100 loss=0.398157 time: 35.122968
INFO:root:[Epoch 86] train=0.864663 val=0.914000 loss=0.392475 time: 35.133064
INFO:root:[Epoch 87] train=0.866587 val=0.917300 loss=0.384358 time: 34.942253
INFO:root:[Epoch 88] train=0.868730 val=0.914300 loss=0.383480 time: 34.925310
INFO:root:[Epoch 89] train=0.870292 val=0.915900 loss=0.372634 time: 34.895386
INFO:root:[Epoch 90] train=0.868189 val=0.917600 loss=0.379880 time: 35.193420
INFO:root:[Epoch 91] train=0.868650 val=0.913200 loss=0.374532 time: 34.791585
INFO:root:[Epoch 92] train=0.872196 val=0.915200 loss=0.371822 time: 35.112576
INFO:root:[Epoch 93] train=0.872436 val=0.917100 loss=0.366843 time: 35.134094
INFO:root:[Epoch 94] train=0.871755 val=0.918100 loss=0.369239 time: 35.126903
INFO:root:[Epoch 95] train=0.872736 val=0.917000 loss=0.365267 time: 35.121064
INFO:root:[Epoch 96] train=0.878626 val=0.920900 loss=0.353468 time: 35.029174
INFO:root:[Epoch 97] train=0.873998 val=0.918100 loss=0.360624 time: 34.989391
INFO:root:[Epoch 98] train=0.873478 val=0.921000 loss=0.361798 time: 34.827688
INFO:root:[Epoch 99] train=0.878245 val=0.921400 loss=0.351006 time: 35.010627
INFO:root:[Epoch 100] train=0.877584 val=0.919700 loss=0.349549 time: 34.837768
INFO:root:[Epoch 101] train=0.878225 val=0.918900 loss=0.348643 time: 35.008833
INFO:root:[Epoch 102] train=0.877684 val=0.921400 loss=0.349874 time: 34.910014
INFO:root:[Epoch 103] train=0.882031 val=0.919200 loss=0.339628 time: 34.942329
INFO:root:[Epoch 104] train=0.879527 val=0.917200 loss=0.347575 time: 34.637444
INFO:root:[Epoch 105] train=0.879828 val=0.922300 loss=0.344126 time: 34.884557
INFO:root:[Epoch 106] train=0.879788 val=0.918300 loss=0.343277 time: 34.793132
INFO:root:[Epoch 107] train=0.882572 val=0.922800 loss=0.339484 time: 34.950775
INFO:root:[Epoch 108] train=0.883814 val=0.922200 loss=0.336239 time: 34.872803
INFO:root:[Epoch 109] train=0.881731 val=0.925300 loss=0.344147 time: 34.827716
INFO:root:[Epoch 110] train=0.884014 val=0.925100 loss=0.335506 time: 34.557368
INFO:root:[Epoch 111] train=0.884595 val=0.918600 loss=0.334804 time: 34.683075
INFO:root:[Epoch 112] train=0.880188 val=0.920900 loss=0.343159 time: 34.762831
INFO:root:[Epoch 113] train=0.883233 val=0.925200 loss=0.335841 time: 34.762325
INFO:root:[Epoch 114] train=0.882893 val=0.918700 loss=0.337771 time: 34.749233
INFO:root:[Epoch 115] train=0.882893 val=0.923600 loss=0.339063 time: 34.834042
INFO:root:[Epoch 116] train=0.885457 val=0.924700 loss=0.330536 time: 34.723123
INFO:root:[Epoch 117] train=0.885036 val=0.926400 loss=0.331142 time: 34.587013
INFO:root:[Epoch 118] train=0.883614 val=0.923600 loss=0.334711 time: 34.928321
INFO:root:[Epoch 119] train=0.884916 val=0.921900 loss=0.329809 time: 34.656428
INFO:root:[Epoch 120] train=0.885276 val=0.922500 loss=0.332531 time: 34.783020
INFO:root:[Epoch 121] train=0.886298 val=0.917500 loss=0.327849 time: 34.707609
INFO:root:[Epoch 122] train=0.887119 val=0.922000 loss=0.324964 time: 34.691840
INFO:root:[Epoch 123] train=0.886018 val=0.924400 loss=0.325726 time: 34.800781
INFO:root:[Epoch 124] train=0.884856 val=0.925900 loss=0.329458 time: 34.913515
INFO:root:[Epoch 125] train=0.885517 val=0.922000 loss=0.324788 time: 34.731862
INFO:root:[Epoch 126] train=0.886759 val=0.924000 loss=0.325561 time: 34.786990
INFO:root:[Epoch 127] train=0.887921 val=0.927200 loss=0.322942 time: 34.813351
INFO:root:[Epoch 128] train=0.888682 val=0.922500 loss=0.323597 time: 34.636138
INFO:root:[Epoch 129] train=0.887280 val=0.920600 loss=0.322039 time: 34.757087
INFO:root:[Epoch 130] train=0.886959 val=0.920000 loss=0.326978 time: 34.493804
INFO:root:[Epoch 131] train=0.886238 val=0.919800 loss=0.325997 time: 34.791173
INFO:root:[Epoch 132] train=0.887660 val=0.924100 loss=0.322529 time: 34.734538
INFO:root:[Epoch 133] train=0.890264 val=0.924800 loss=0.317093 time: 34.720332
INFO:root:[Epoch 134] train=0.887360 val=0.924800 loss=0.321081 time: 34.564286
INFO:root:[Epoch 135] train=0.887099 val=0.923800 loss=0.319904 time: 34.785537
INFO:root:[Epoch 136] train=0.889163 val=0.922200 loss=0.318426 time: 34.949174
INFO:root:[Epoch 137] train=0.889243 val=0.921900 loss=0.314829 time: 34.703697
INFO:root:[Epoch 138] train=0.889243 val=0.919800 loss=0.320671 time: 34.868565
INFO:root:[Epoch 139] train=0.891106 val=0.921700 loss=0.313580 time: 34.882777
INFO:root:[Epoch 140] train=0.891767 val=0.920000 loss=0.317257 time: 34.640129
INFO:root:[Epoch 141] train=0.891326 val=0.923900 loss=0.313383 time: 34.642356
INFO:root:[Epoch 142] train=0.890545 val=0.921900 loss=0.311370 time: 34.522100
INFO:root:[Epoch 143] train=0.887360 val=0.924000 loss=0.320291 time: 34.642345
INFO:root:[Epoch 144] train=0.889924 val=0.921200 loss=0.317562 time: 34.767987
INFO:root:[Epoch 145] train=0.890485 val=0.919500 loss=0.313900 time: 34.800250
INFO:root:[Epoch 146] train=0.888962 val=0.918200 loss=0.321347 time: 35.030420
INFO:root:[Epoch 147] train=0.889303 val=0.925100 loss=0.317207 time: 34.711540
INFO:root:[Epoch 148] train=0.893369 val=0.923000 loss=0.310923 time: 34.841975
INFO:root:[Epoch 149] train=0.892208 val=0.925100 loss=0.308697 time: 34.524442
INFO:root:[Epoch 150] train=0.890505 val=0.922100 loss=0.310544 time: 34.926631
INFO:root:[Epoch 151] train=0.892007 val=0.919100 loss=0.311872 time: 34.791604
INFO:root:[Epoch 152] train=0.893810 val=0.923800 loss=0.309634 time: 34.844193
INFO:root:[Epoch 153] train=0.892248 val=0.917500 loss=0.308874 time: 34.766614
INFO:root:[Epoch 154] train=0.894030 val=0.921500 loss=0.306139 time: 34.878954
INFO:root:[Epoch 155] train=0.890184 val=0.924900 loss=0.312866 time: 34.552272
INFO:root:[Epoch 156] train=0.891306 val=0.926300 loss=0.309607 time: 34.742983
INFO:root:[Epoch 157] train=0.892127 val=0.921600 loss=0.306229 time: 34.700485
INFO:root:[Epoch 158] train=0.891426 val=0.921200 loss=0.312622 time: 34.738429
INFO:root:[Epoch 159] train=0.892528 val=0.923500 loss=0.314081 time: 34.751604
INFO:root:[Epoch 160] train=0.900461 val=0.928900 loss=0.289302 time: 34.548336
INFO:root:[Epoch 161] train=0.903045 val=0.930000 loss=0.279254 time: 34.855703
INFO:root:[Epoch 162] train=0.906250 val=0.931600 loss=0.271831 time: 34.686838
INFO:root:[Epoch 163] train=0.905629 val=0.930100 loss=0.274976 time: 34.800560
INFO:root:[Epoch 164] train=0.907632 val=0.929800 loss=0.267251 time: 34.801602
INFO:root:[Epoch 165] train=0.907312 val=0.931100 loss=0.269397 time: 34.844616
INFO:root:[Epoch 166] train=0.908674 val=0.930400 loss=0.267226 time: 34.772395
INFO:root:[Epoch 167] train=0.909175 val=0.932500 loss=0.263270 time: 34.632506
INFO:root:[Epoch 168] train=0.910677 val=0.931400 loss=0.260944 time: 34.638031
INFO:root:[Epoch 169] train=0.909215 val=0.930900 loss=0.264406 time: 34.846473
INFO:root:[Epoch 170] train=0.908874 val=0.931500 loss=0.264481 time: 34.932777
INFO:root:[Epoch 171] train=0.911238 val=0.931600 loss=0.258691 time: 34.928696
INFO:root:[Epoch 172] train=0.908614 val=0.931500 loss=0.264195 time: 35.155561
INFO:root:[Epoch 173] train=0.910116 val=0.932400 loss=0.263211 time: 34.725248
INFO:root:[Epoch 174] train=0.908033 val=0.933600 loss=0.262870 time: 34.965757
INFO:root:[Epoch 175] train=0.909555 val=0.931900 loss=0.265062 time: 34.770391
INFO:root:[Epoch 176] train=0.911398 val=0.932300 loss=0.258513 time: 35.114199
INFO:root:[Epoch 177] train=0.909034 val=0.932400 loss=0.261867 time: 34.838585
INFO:root:[Epoch 178] train=0.909054 val=0.933500 loss=0.261257 time: 35.030327
INFO:root:[Epoch 179] train=0.912500 val=0.932100 loss=0.257157 time: 34.796310
INFO:root:[Epoch 180] train=0.909595 val=0.932600 loss=0.260079 time: 34.844174
INFO:root:[Epoch 181] train=0.912059 val=0.933200 loss=0.259069 time: 34.728011
INFO:root:[Epoch 182] train=0.911118 val=0.934000 loss=0.258683 time: 34.886028
INFO:root:[Epoch 183] train=0.911198 val=0.933300 loss=0.255412 time: 34.751350
INFO:root:[Epoch 184] train=0.912039 val=0.933800 loss=0.256119 time: 34.945729
INFO:root:[Epoch 185] train=0.912440 val=0.934200 loss=0.253505 time: 34.912195
INFO:root:[Epoch 186] train=0.912740 val=0.933600 loss=0.255595 time: 34.826798
INFO:root:[Epoch 187] train=0.912360 val=0.933800 loss=0.254685 time: 34.962890
INFO:root:[Epoch 188] train=0.911498 val=0.932800 loss=0.255611 time: 34.954807
INFO:root:[Epoch 189] train=0.910978 val=0.932700 loss=0.257332 time: 35.034749
INFO:root:[Epoch 190] train=0.914203 val=0.933700 loss=0.248979 time: 34.816232
INFO:root:[Epoch 191] train=0.913141 val=0.934200 loss=0.252008 time: 34.931926
INFO:root:[Epoch 192] train=0.912961 val=0.934500 loss=0.252418 time: 34.810689
INFO:root:[Epoch 193] train=0.912200 val=0.932500 loss=0.254383 time: 34.849150
INFO:root:[Epoch 194] train=0.915184 val=0.933800 loss=0.248609 time: 34.807817
INFO:root:[Epoch 195] train=0.912079 val=0.932900 loss=0.255025 time: 34.968760
INFO:root:[Epoch 196] train=0.913762 val=0.932500 loss=0.253055 time: 34.939213
INFO:root:[Epoch 197] train=0.913221 val=0.932400 loss=0.250769 time: 34.892115
INFO:root:[Epoch 198] train=0.912861 val=0.931500 loss=0.249585 time: 34.985359
INFO:root:[Epoch 199] train=0.913121 val=0.931300 loss=0.252883 time: 34.870106
INFO:root:[Epoch 200] train=0.913221 val=0.931900 loss=0.248355 time: 34.906867
INFO:root:[Epoch 201] train=0.916526 val=0.933400 loss=0.243107 time: 34.746886
INFO:root:[Epoch 202] train=0.914844 val=0.931900 loss=0.246533 time: 35.014919
INFO:root:[Epoch 203] train=0.914223 val=0.933600 loss=0.249793 time: 34.903241
INFO:root:[Epoch 204] train=0.914663 val=0.934600 loss=0.247482 time: 35.120690
INFO:root:[Epoch 205] train=0.914784 val=0.934500 loss=0.247341 time: 34.828576
INFO:root:[Epoch 206] train=0.914303 val=0.934000 loss=0.248423 time: 35.031684
INFO:root:[Epoch 207] train=0.915705 val=0.933600 loss=0.243785 time: 34.743665
INFO:root:[Epoch 208] train=0.914123 val=0.933000 loss=0.248631 time: 34.863354
INFO:root:[Epoch 209] train=0.913321 val=0.934000 loss=0.248153 time: 34.844415
INFO:root:[Epoch 210] train=0.914463 val=0.934300 loss=0.247992 time: 34.990786
INFO:root:[Epoch 211] train=0.914704 val=0.933600 loss=0.248060 time: 35.083338
INFO:root:[Epoch 212] train=0.913802 val=0.932900 loss=0.249570 time: 34.858987
INFO:root:[Epoch 213] train=0.914022 val=0.931700 loss=0.252188 time: 34.676408
INFO:root:[Epoch 214] train=0.914623 val=0.932700 loss=0.249092 time: 34.971139
INFO:root:[Epoch 215] train=0.914543 val=0.934600 loss=0.251281 time: 34.890872
INFO:root:[Epoch 216] train=0.915925 val=0.932000 loss=0.244897 time: 34.900518
INFO:root:[Epoch 217] train=0.915204 val=0.933100 loss=0.245773 time: 34.844274
INFO:root:[Epoch 218] train=0.915805 val=0.931900 loss=0.243310 time: 34.787135
INFO:root:[Epoch 219] train=0.914443 val=0.933800 loss=0.249703 time: 34.859733
INFO:root:[Epoch 220] train=0.914443 val=0.932900 loss=0.247268 time: 34.969934
INFO:root:[Epoch 221] train=0.915845 val=0.935000 loss=0.243897 time: 35.016548
INFO:root:[Epoch 222] train=0.916326 val=0.932300 loss=0.243535 time: 34.865277
INFO:root:[Epoch 223] train=0.915946 val=0.933400 loss=0.241905 time: 34.968344
INFO:root:[Epoch 224] train=0.913542 val=0.933400 loss=0.249412 time: 34.931672
INFO:root:[Epoch 225] train=0.914363 val=0.932600 loss=0.247683 time: 34.891047
INFO:root:[Epoch 226] train=0.914623 val=0.933000 loss=0.250498 time: 34.742639
INFO:root:[Epoch 227] train=0.917949 val=0.932300 loss=0.242146 time: 34.914749
INFO:root:[Epoch 228] train=0.915505 val=0.931900 loss=0.247382 time: 34.986577
INFO:root:[Epoch 229] train=0.914263 val=0.933300 loss=0.245786 time: 34.833516
INFO:root:[Epoch 230] train=0.914283 val=0.933900 loss=0.246895 time: 35.077077
INFO:root:[Epoch 231] train=0.915825 val=0.933200 loss=0.241943 time: 34.933728
INFO:root:[Epoch 232] train=0.913842 val=0.933200 loss=0.246922 time: 34.992325
INFO:root:[Epoch 233] train=0.917167 val=0.933800 loss=0.239443 time: 34.695162
INFO:root:[Epoch 234] train=0.916687 val=0.932800 loss=0.243533 time: 35.118967
INFO:root:[Epoch 235] train=0.915785 val=0.933900 loss=0.243491 time: 34.862535
INFO:root:[Epoch 236] train=0.915745 val=0.932900 loss=0.246035 time: 34.995026
INFO:root:[Epoch 237] train=0.917849 val=0.932900 loss=0.241607 time: 34.825507
INFO:root:[Epoch 238] train=0.915905 val=0.932600 loss=0.245174 time: 34.960187
INFO:root:[Epoch 239] train=0.917528 val=0.932600 loss=0.239405 time: 34.803581
